[2025-05-02T02:21:14.034+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-02T02:21:14.053+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: medical_dag_v17.dim_group.creating_dim_allergies manual__2025-05-02T02:18:00.042814+00:00 [queued]>
[2025-05-02T02:21:14.065+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: medical_dag_v17.dim_group.creating_dim_allergies manual__2025-05-02T02:18:00.042814+00:00 [queued]>
[2025-05-02T02:21:14.066+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-05-02T02:21:14.086+0000] {taskinstance.py:2890} INFO - Executing <Task(SparkSubmitOperator): dim_group.creating_dim_allergies> on 2025-05-02 02:18:00.042814+00:00
[2025-05-02T02:21:14.094+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'medical_dag_v17', 'dim_group.creating_dim_allergies', 'manual__2025-05-02T02:18:00.042814+00:00', '--job-id', '170', '--raw', '--subdir', 'DAGS_FOLDER/raw_enriched_dag.py', '--cfg-path', '/tmp/tmpv2p3zmri']
[2025-05-02T02:21:14.097+0000] {standard_task_runner.py:105} INFO - Job 170: Subtask dim_group.creating_dim_allergies
[2025-05-02T02:21:14.100+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=6851) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-05-02T02:21:14.101+0000] {standard_task_runner.py:72} INFO - Started process 6855 to run task
[2025-05-02T02:21:14.150+0000] {task_command.py:467} INFO - Running <TaskInstance: medical_dag_v17.dim_group.creating_dim_allergies manual__2025-05-02T02:18:00.042814+00:00 [running]> on host airflow-scheduler
[2025-05-02T02:21:14.248+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='medical_dag_v17' AIRFLOW_CTX_TASK_ID='dim_group.creating_dim_allergies' AIRFLOW_CTX_EXECUTION_DATE='2025-05-02T02:18:00.042814+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-02T02:18:00.042814+00:00'
[2025-05-02T02:21:14.249+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-05-02T02:21:14.289+0000] {base.py:84} INFO - Retrieving connection 'spark_conn'
[2025-05-02T02:21:14.291+0000] {spark_submit.py:473} INFO - Spark-Submit cmd: spark-submit --master local --packages io.delta:delta-spark_2.12:3.3.0,org.apache.hadoop:hadoop-aws:3.3.4 --name arrow-spark --deploy-mode client /opt/etl/enriched_curated/creating_dim_allergies.py
[2025-05-02T02:21:17.015+0000] {spark_submit.py:649} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-02T02:21:17.158+0000] {spark_submit.py:649} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2025-05-02T02:21:17.160+0000] {spark_submit.py:649} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2025-05-02T02:21:17.164+0000] {spark_submit.py:649} INFO - io.delta#delta-spark_2.12 added as a dependency
[2025-05-02T02:21:17.165+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2025-05-02T02:21:17.166+0000] {spark_submit.py:649} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-4dc38823-8005-4340-8ca1-dbc3e81931f3;1.0
[2025-05-02T02:21:17.167+0000] {spark_submit.py:649} INFO - confs: [default]
[2025-05-02T02:21:17.381+0000] {spark_submit.py:649} INFO - found io.delta#delta-spark_2.12;3.3.0 in central
[2025-05-02T02:21:17.420+0000] {spark_submit.py:649} INFO - found io.delta#delta-storage;3.3.0 in central
[2025-05-02T02:21:17.461+0000] {spark_submit.py:649} INFO - found org.antlr#antlr4-runtime;4.9.3 in central
[2025-05-02T02:21:17.545+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-aws;3.3.4 in central
[2025-05-02T02:21:17.581+0000] {spark_submit.py:649} INFO - found com.amazonaws#aws-java-sdk-bundle;1.12.262 in central
[2025-05-02T02:21:17.609+0000] {spark_submit.py:649} INFO - found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
[2025-05-02T02:21:17.644+0000] {spark_submit.py:649} INFO - :: resolution report :: resolve 456ms :: artifacts dl 21ms
[2025-05-02T02:21:17.645+0000] {spark_submit.py:649} INFO - :: modules in use:
[2025-05-02T02:21:17.646+0000] {spark_submit.py:649} INFO - com.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]
[2025-05-02T02:21:17.647+0000] {spark_submit.py:649} INFO - io.delta#delta-spark_2.12;3.3.0 from central in [default]
[2025-05-02T02:21:17.648+0000] {spark_submit.py:649} INFO - io.delta#delta-storage;3.3.0 from central in [default]
[2025-05-02T02:21:17.649+0000] {spark_submit.py:649} INFO - org.antlr#antlr4-runtime;4.9.3 from central in [default]
[2025-05-02T02:21:17.650+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]
[2025-05-02T02:21:17.651+0000] {spark_submit.py:649} INFO - org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
[2025-05-02T02:21:17.652+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2025-05-02T02:21:17.652+0000] {spark_submit.py:649} INFO - |                  |            modules            ||   artifacts   |
[2025-05-02T02:21:17.653+0000] {spark_submit.py:649} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-02T02:21:17.654+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2025-05-02T02:21:17.655+0000] {spark_submit.py:649} INFO - |      default     |   6   |   0   |   0   |   0   ||   6   |   0   |
[2025-05-02T02:21:17.655+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2025-05-02T02:21:17.656+0000] {spark_submit.py:649} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-4dc38823-8005-4340-8ca1-dbc3e81931f3
[2025-05-02T02:21:17.657+0000] {spark_submit.py:649} INFO - confs: [default]
[2025-05-02T02:21:17.665+0000] {spark_submit.py:649} INFO - 0 artifacts copied, 6 already retrieved (0kB/9ms)
[2025-05-02T02:21:18.055+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-02T02:21:23.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO SparkContext: Running Spark version 3.5.3
[2025-05-02T02:21:23.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO SparkContext: OS info Linux, 5.15.153.1-microsoft-standard-WSL2, amd64
[2025-05-02T02:21:23.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO SparkContext: Java version 17.0.14
[2025-05-02T02:21:23.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO ResourceUtils: ==============================================================
[2025-05-02T02:21:23.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-02T02:21:23.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO ResourceUtils: ==============================================================
[2025-05-02T02:21:23.963+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO SparkContext: Submitted application: MyETLPipeline
[2025-05-02T02:21:23.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-02T02:21:24.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO ResourceProfile: Limiting resource is cpu
[2025-05-02T02:21:24.001+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-02T02:21:24.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SecurityManager: Changing view acls to: ***
[2025-05-02T02:21:24.088+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SecurityManager: Changing modify acls to: ***
[2025-05-02T02:21:24.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SecurityManager: Changing view acls groups to:
[2025-05-02T02:21:24.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SecurityManager: Changing modify acls groups to:
[2025-05-02T02:21:24.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-05-02T02:21:24.397+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO Utils: Successfully started service 'sparkDriver' on port 43567.
[2025-05-02T02:21:24.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkEnv: Registering MapOutputTracker
[2025-05-02T02:21:24.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-02T02:21:24.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-02T02:21:24.521+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-02T02:21:24.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-02T02:21:24.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5d35b24b-479f-4dd0-87b4-b18157fb3e81
[2025-05-02T02:21:24.595+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-02T02:21:24.616+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-02T02:21:24.830+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-05-02T02:21:24.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-02T02:21:24.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/io.delta_delta-spark_2.12-3.3.0.jar at spark://***-scheduler:43567/jars/io.delta_delta-spark_2.12-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:24.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://***-scheduler:43567/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1746152483926
[2025-05-02T02:21:24.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/io.delta_delta-storage-3.3.0.jar at spark://***-scheduler:43567/jars/io.delta_delta-storage-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:24.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://***-scheduler:43567/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1746152483926
[2025-05-02T02:21:24.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://***-scheduler:43567/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1746152483926
[2025-05-02T02:21:24.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://***-scheduler:43567/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1746152483926
[2025-05-02T02:21:24.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO SparkContext: Added file file:///home/***/.ivy2/jars/io.delta_delta-spark_2.12-3.3.0.jar at file:///home/***/.ivy2/jars/io.delta_delta-spark_2.12-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:24.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:24 INFO Utils: Copying /home/***/.ivy2/jars/io.delta_delta-spark_2.12-3.3.0.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-spark_2.12-3.3.0.jar
[2025-05-02T02:21:25.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1746152483926
[2025-05-02T02:21:25.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-05-02T02:21:25.030+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO SparkContext: Added file file:///home/***/.ivy2/jars/io.delta_delta-storage-3.3.0.jar at file:///home/***/.ivy2/jars/io.delta_delta-storage-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:25.031+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: Copying /home/***/.ivy2/jars/io.delta_delta-storage-3.3.0.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-storage-3.3.0.jar
[2025-05-02T02:21:25.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at file:///home/***/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1746152483926
[2025-05-02T02:21:25.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: Copying /home/***/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.antlr_antlr4-runtime-4.9.3.jar
[2025-05-02T02:21:25.046+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1746152483926
[2025-05-02T02:21:25.047+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: Copying /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-05-02T02:21:25.740+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1746152483926
[2025-05-02T02:21:25.741+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: Copying /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-05-02T02:21:25.847+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Starting executor ID driver on host ***-scheduler
[2025-05-02T02:21:25.848+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: OS info Linux, 5.15.153.1-microsoft-standard-WSL2, amd64
[2025-05-02T02:21:25.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Java version 17.0.14
[2025-05-02T02:21:25.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-05-02T02:21:25.857+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@15cbe5f6 for default.
[2025-05-02T02:21:25.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Fetching file:///home/***/.ivy2/jars/io.delta_delta-storage-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:25.901+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: /home/***/.ivy2/jars/io.delta_delta-storage-3.3.0.jar has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-storage-3.3.0.jar
[2025-05-02T02:21:25.906+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1746152483926
[2025-05-02T02:21:25.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Utils: /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-05-02T02:21:25.921+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:25 INFO Executor: Fetching file:///home/***/.ivy2/jars/io.delta_delta-spark_2.12-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:18.615+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 INFO Utils: /home/***/.ivy2/jars/io.delta_delta-spark_2.12-3.3.0.jar has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-spark_2.12-3.3.0.jar
[2025-05-02T02:21:18.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1746152483926
[2025-05-02T02:21:18.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 INFO Utils: /home/***/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.antlr_antlr4-runtime-4.9.3.jar
[2025-05-02T02:21:18.628+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1746152483926
[2025-05-02T02:21:18.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 INFO Utils: /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-05-02T02:21:18.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:18 INFO Executor: Fetching file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1746152483926
[2025-05-02T02:21:29.106+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-05-02T02:21:29.114+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Fetching spark://***-scheduler:43567/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1746152483926
[2025-05-02T02:21:29.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO TransportClientFactory: Successfully created connection to ***-scheduler/172.18.0.3:43567 after 46 ms (0 ms spent in bootstraps)
[2025-05-02T02:21:29.191+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: Fetching spark://***-scheduler:43567/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp16514573657293260887.tmp
[2025-05-02T02:21:29.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp16514573657293260887.tmp has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2025-05-02T02:21:29.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Adding file:/tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to class loader default
[2025-05-02T02:21:29.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Fetching spark://***-scheduler:43567/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1746152483926
[2025-05-02T02:21:29.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: Fetching spark://***-scheduler:43567/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp6424954108369873580.tmp
[2025-05-02T02:21:29.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp6424954108369873580.tmp has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.antlr_antlr4-runtime-4.9.3.jar
[2025-05-02T02:21:29.236+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Adding file:/tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.antlr_antlr4-runtime-4.9.3.jar to class loader default
[2025-05-02T02:21:29.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Fetching spark://***-scheduler:43567/jars/io.delta_delta-storage-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:29.238+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: Fetching spark://***-scheduler:43567/jars/io.delta_delta-storage-3.3.0.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp6136355037901813172.tmp
[2025-05-02T02:21:29.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp6136355037901813172.tmp has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-storage-3.3.0.jar
[2025-05-02T02:21:29.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Adding file:/tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-storage-3.3.0.jar to class loader default
[2025-05-02T02:21:29.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Executor: Fetching spark://***-scheduler:43567/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1746152483926
[2025-05-02T02:21:29.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:29 INFO Utils: Fetching spark://***-scheduler:43567/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp11358468862031787434.tmp
[2025-05-02T02:21:31.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Utils: /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp11358468862031787434.tmp has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2025-05-02T02:21:31.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Executor: Adding file:/tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to class loader default
[2025-05-02T02:21:31.081+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Executor: Fetching spark://***-scheduler:43567/jars/io.delta_delta-spark_2.12-3.3.0.jar with timestamp 1746152483926
[2025-05-02T02:21:31.082+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Utils: Fetching spark://***-scheduler:43567/jars/io.delta_delta-spark_2.12-3.3.0.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp7046119230698161729.tmp
[2025-05-02T02:21:31.149+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Utils: /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp7046119230698161729.tmp has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-spark_2.12-3.3.0.jar
[2025-05-02T02:21:31.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Executor: Adding file:/tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/io.delta_delta-spark_2.12-3.3.0.jar to class loader default
[2025-05-02T02:21:31.159+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Executor: Fetching spark://***-scheduler:43567/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1746152483926
[2025-05-02T02:21:31.160+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Utils: Fetching spark://***-scheduler:43567/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp10051607061253351928.tmp
[2025-05-02T02:21:31.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Utils: /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/fetchFileTemp10051607061253351928.tmp has been previously copied to /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2025-05-02T02:21:31.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Executor: Adding file:/tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/userFiles-59ec225d-6b59-409f-bbe8-a91a50520b55/org.apache.hadoop_hadoop-aws-3.3.4.jar to class loader default
[2025-05-02T02:21:31.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33063.
[2025-05-02T02:21:31.208+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO NettyBlockTransferService: Server created on ***-scheduler:33063
[2025-05-02T02:21:31.212+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-02T02:21:31.236+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ***-scheduler, 33063, None)
[2025-05-02T02:21:31.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO BlockManagerMasterEndpoint: Registering block manager ***-scheduler:33063 with 434.4 MiB RAM, BlockManagerId(driver, ***-scheduler, 33063, None)
[2025-05-02T02:21:31.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ***-scheduler, 33063, None)
[2025-05-02T02:21:31.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ***-scheduler, 33063, None)
[2025-05-02T02:21:32.401+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-02T02:21:32.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:32 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2025-05-02T02:21:34.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:34 INFO HiveConf: Found configuration file null
[2025-05-02T02:21:34.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 3.1.3 using maven.
[2025-05-02T02:21:34.384+0000] {spark_submit.py:649} INFO - https://maven-central.storage-download.googleapis.com/maven2/ added as a remote repository with the name: repo-1
[2025-05-02T02:21:34.387+0000] {spark_submit.py:649} INFO - https://maven-central.storage-download.googleapis.com/maven2/ added as a remote repository with the name: repo-1
[2025-05-02T02:21:34.423+0000] {spark_submit.py:649} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2025-05-02T02:21:34.424+0000] {spark_submit.py:649} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2025-05-02T02:21:34.425+0000] {spark_submit.py:649} INFO - org.apache.logging.log4j#log4j-api added as a dependency
[2025-05-02T02:21:34.426+0000] {spark_submit.py:649} INFO - org.apache.derby#derby added as a dependency
[2025-05-02T02:21:34.427+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-metastore added as a dependency
[2025-05-02T02:21:34.427+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-exec added as a dependency
[2025-05-02T02:21:34.428+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-common added as a dependency
[2025-05-02T02:21:34.429+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-serde added as a dependency
[2025-05-02T02:21:34.430+0000] {spark_submit.py:649} INFO - com.google.guava#guava added as a dependency
[2025-05-02T02:21:34.430+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-client-api added as a dependency
[2025-05-02T02:21:34.431+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-client-runtime added as a dependency
[2025-05-02T02:21:34.432+0000] {spark_submit.py:649} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-d7530b0b-f2df-4130-b953-348ddac67177;1.0
[2025-05-02T02:21:34.432+0000] {spark_submit.py:649} INFO - confs: [default]
[2025-05-02T02:21:34.462+0000] {spark_submit.py:649} INFO - found org.apache.logging.log4j#log4j-api;2.10.0 in central
[2025-05-02T02:21:34.480+0000] {spark_submit.py:649} INFO - found org.apache.derby#derby;10.14.1.0 in central
[2025-05-02T02:21:34.511+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-metastore;3.1.3 in central
[2025-05-02T02:21:34.558+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-serde;3.1.3 in central
[2025-05-02T02:21:34.602+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-common;3.1.3 in central
[2025-05-02T02:21:34.647+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-classification;3.1.3 in central
[2025-05-02T02:21:34.681+0000] {spark_submit.py:649} INFO - found org.slf4j#slf4j-api;1.7.10 in central
[2025-05-02T02:21:34.724+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-upgrade-acid;3.1.3 in central
[2025-05-02T02:21:34.784+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-shims;3.1.3 in central
[2025-05-02T02:21:34.845+0000] {spark_submit.py:649} INFO - found org.apache.hive.shims#hive-shims-common;3.1.3 in central
[2025-05-02T02:21:34.903+0000] {spark_submit.py:649} INFO - found org.apache.logging.log4j#log4j-slf4j-impl;2.17.1 in central
[2025-05-02T02:21:34.940+0000] {spark_submit.py:649} INFO - found com.google.guava#guava;19.0 in central
[2025-05-02T02:21:34.979+0000] {spark_submit.py:649} INFO - found commons-lang#commons-lang;2.6 in central
[2025-05-02T02:21:35.021+0000] {spark_submit.py:649} INFO - found org.apache.thrift#libthrift;0.9.3 in central
[2025-05-02T02:21:35.057+0000] {spark_submit.py:649} INFO - found org.apache.httpcomponents#httpclient;4.5.13 in central
[2025-05-02T02:21:35.089+0000] {spark_submit.py:649} INFO - found org.apache.httpcomponents#httpcore;4.4.13 in central
[2025-05-02T02:21:35.120+0000] {spark_submit.py:649} INFO - found commons-logging#commons-logging;1.2 in central
[2025-05-02T02:21:35.154+0000] {spark_submit.py:649} INFO - found commons-codec#commons-codec;1.15 in central
[2025-05-02T02:21:35.191+0000] {spark_submit.py:649} INFO - found org.apache.zookeeper#zookeeper;3.4.6 in central
[2025-05-02T02:21:35.224+0000] {spark_submit.py:649} INFO - found org.slf4j#slf4j-log4j12;1.6.1 in central
[2025-05-02T02:21:35.253+0000] {spark_submit.py:649} INFO - found log4j#log4j;1.2.16 in central
[2025-05-02T02:21:35.280+0000] {spark_submit.py:649} INFO - found jline#jline;2.12 in central
[2025-05-02T02:21:35.309+0000] {spark_submit.py:649} INFO - found io.netty#netty;3.7.0.Final in central
[2025-05-02T02:21:35.371+0000] {spark_submit.py:649} INFO - found org.apache.logging.log4j#log4j-core;2.17.1 in central
[2025-05-02T02:21:35.409+0000] {spark_submit.py:649} INFO - found org.apache.hive.shims#hive-shims-0.23;3.1.3 in central
[2025-05-02T02:21:35.454+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-server-resourcemanager;3.1.0 in central
[2025-05-02T02:21:35.521+0000] {spark_submit.py:649} INFO - found javax.servlet#javax.servlet-api;3.1.0 in central
[2025-05-02T02:21:35.577+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-annotations;3.1.0 in central
[2025-05-02T02:21:35.613+0000] {spark_submit.py:649} INFO - found com.google.inject.extensions#guice-servlet;4.0 in central
[2025-05-02T02:21:35.646+0000] {spark_submit.py:649} INFO - found com.google.inject#guice;4.0 in central
[2025-05-02T02:21:35.691+0000] {spark_submit.py:649} INFO - found javax.inject#javax.inject;1 in central
[2025-05-02T02:21:35.737+0000] {spark_submit.py:649} INFO - found aopalliance#aopalliance;1.0 in central
[2025-05-02T02:21:35.778+0000] {spark_submit.py:649} INFO - found com.google.protobuf#protobuf-java;2.5.0 in central
[2025-05-02T02:21:35.812+0000] {spark_submit.py:649} INFO - found commons-io#commons-io;2.6 in central
[2025-05-02T02:21:35.852+0000] {spark_submit.py:649} INFO - found com.sun.jersey#jersey-json;1.19 in central
[2025-05-02T02:21:35.887+0000] {spark_submit.py:649} INFO - found org.codehaus.jettison#jettison;1.1 in central
[2025-05-02T02:21:35.920+0000] {spark_submit.py:649} INFO - found com.sun.xml.bind#jaxb-impl;2.2.3-1 in central
[2025-05-02T02:21:35.955+0000] {spark_submit.py:649} INFO - found javax.xml.bind#jaxb-api;2.2.11 in central
[2025-05-02T02:21:35.989+0000] {spark_submit.py:649} INFO - found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
[2025-05-02T02:21:36.054+0000] {spark_submit.py:649} INFO - found org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central
[2025-05-02T02:21:36.110+0000] {spark_submit.py:649} INFO - found org.codehaus.jackson#jackson-jaxrs;1.9.13 in central
[2025-05-02T02:21:36.154+0000] {spark_submit.py:649} INFO - found org.codehaus.jackson#jackson-xc;1.9.13 in central
[2025-05-02T02:21:36.200+0000] {spark_submit.py:649} INFO - found com.sun.jersey#jersey-core;1.19 in central
[2025-05-02T02:21:36.235+0000] {spark_submit.py:649} INFO - found javax.ws.rs#jsr311-api;1.1.1 in central
[2025-05-02T02:21:36.267+0000] {spark_submit.py:649} INFO - found com.sun.jersey.contribs#jersey-guice;1.19 in central
[2025-05-02T02:21:36.306+0000] {spark_submit.py:649} INFO - found com.sun.jersey#jersey-servlet;1.19 in central
[2025-05-02T02:21:36.347+0000] {spark_submit.py:649} INFO - found com.sun.jersey#jersey-server;1.19 in central
[2025-05-02T02:21:36.393+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-common;3.1.0 in central
[2025-05-02T02:21:36.447+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-api;3.1.0 in central
[2025-05-02T02:21:36.549+0000] {spark_submit.py:649} INFO - found com.fasterxml.jackson.core#jackson-annotations;2.12.0 in central
[2025-05-02T02:21:36.599+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-auth;3.1.0 in central
[2025-05-02T02:21:36.720+0000] {spark_submit.py:649} INFO - found com.nimbusds#nimbus-jose-jwt;4.41.1 in central
[2025-05-02T02:21:36.775+0000] {spark_submit.py:649} INFO - found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-05-02T02:21:36.813+0000] {spark_submit.py:649} INFO - found net.minidev#json-smart;2.3 in central
[2025-05-02T02:21:36.859+0000] {spark_submit.py:649} INFO - found net.minidev#accessors-smart;1.2 in central
[2025-05-02T02:21:36.915+0000] {spark_submit.py:649} INFO - found org.ow2.asm#asm;5.0.4 in central
[2025-05-02T02:21:36.966+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-simplekdc;1.0.1 in central
[2025-05-02T02:21:37.005+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-client;1.0.1 in central
[2025-05-02T02:21:37.045+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerby-config;1.0.1 in central
[2025-05-02T02:21:37.087+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-core;1.0.1 in central
[2025-05-02T02:21:37.136+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerby-pkix;1.0.1 in central
[2025-05-02T02:21:37.177+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerby-asn1;1.0.1 in central
[2025-05-02T02:21:37.219+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerby-util;1.0.1 in central
[2025-05-02T02:21:37.258+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-common;1.0.1 in central
[2025-05-02T02:21:37.297+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-crypto;1.0.1 in central
[2025-05-02T02:21:37.348+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-util;1.0.1 in central
[2025-05-02T02:21:37.410+0000] {spark_submit.py:649} INFO - found org.apache.kerby#token-provider;1.0.1 in central
[2025-05-02T02:21:37.453+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-admin;1.0.1 in central
[2025-05-02T02:21:37.492+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-server;1.0.1 in central
[2025-05-02T02:21:37.529+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerb-identity;1.0.1 in central
[2025-05-02T02:21:37.572+0000] {spark_submit.py:649} INFO - found org.apache.kerby#kerby-xdr;1.0.1 in central
[2025-05-02T02:21:37.617+0000] {spark_submit.py:649} INFO - found org.apache.commons#commons-compress;1.19 in central
[2025-05-02T02:21:37.652+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-util;9.3.19.v20170502 in central
[2025-05-02T02:21:37.687+0000] {spark_submit.py:649} INFO - found com.sun.jersey#jersey-client;1.19 in central
[2025-05-02T02:21:37.720+0000] {spark_submit.py:649} INFO - found commons-cli#commons-cli;1.2 in central
[2025-05-02T02:21:37.769+0000] {spark_submit.py:649} INFO - found log4j#log4j;1.2.17 in central
[2025-05-02T02:21:37.814+0000] {spark_submit.py:649} INFO - found com.fasterxml.jackson.core#jackson-core;2.12.0 in central
[2025-05-02T02:21:37.857+0000] {spark_submit.py:649} INFO - found com.fasterxml.jackson.core#jackson-databind;2.12.0 in central
[2025-05-02T02:21:37.902+0000] {spark_submit.py:649} INFO - found com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.12.0 in central
[2025-05-02T02:21:37.944+0000] {spark_submit.py:649} INFO - found jakarta.xml.bind#jakarta.xml.bind-api;2.3.2 in central
[2025-05-02T02:21:37.974+0000] {spark_submit.py:649} INFO - found jakarta.activation#jakarta.activation-api;1.2.1 in central
[2025-05-02T02:21:38.009+0000] {spark_submit.py:649} INFO - found com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.12.0 in central
[2025-05-02T02:21:38.042+0000] {spark_submit.py:649} INFO - found com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.12.0 in central
[2025-05-02T02:21:38.073+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-util-ajax;9.3.19.v20170502 in central
[2025-05-02T02:21:38.107+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-server-common;3.1.0 in central
[2025-05-02T02:21:38.159+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-registry;3.1.0 in central
[2025-05-02T02:21:38.230+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-common;3.1.0 in central
[2025-05-02T02:21:38.318+0000] {spark_submit.py:649} INFO - found org.apache.commons#commons-math3;3.1.1 in central
[2025-05-02T02:21:38.411+0000] {spark_submit.py:649} INFO - found commons-net#commons-net;3.6 in central
[2025-05-02T02:21:38.450+0000] {spark_submit.py:649} INFO - found commons-collections#commons-collections;3.2.2 in central
[2025-05-02T02:21:38.503+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-server;9.3.20.v20170531 in central
[2025-05-02T02:21:38.542+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-http;9.3.20.v20170531 in central
[2025-05-02T02:21:38.594+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-io;9.3.20.v20170531 in central
[2025-05-02T02:21:38.642+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-servlet;9.3.20.v20170531 in central
[2025-05-02T02:21:38.680+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-security;9.3.20.v20170531 in central
[2025-05-02T02:21:38.719+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-webapp;9.3.20.v20170531 in central
[2025-05-02T02:21:38.759+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-xml;9.3.20.v20170531 in central
[2025-05-02T02:21:38.910+0000] {spark_submit.py:649} INFO - found commons-beanutils#commons-beanutils;1.9.3 in central
[2025-05-02T02:21:38.952+0000] {spark_submit.py:649} INFO - found org.apache.commons#commons-configuration2;2.1.1 in central
[2025-05-02T02:21:39.033+0000] {spark_submit.py:649} INFO - found org.apache.avro#avro;1.8.2 in central
[2025-05-02T02:21:39.122+0000] {spark_submit.py:649} INFO - found com.thoughtworks.paranamer#paranamer;2.7 in central
[2025-05-02T02:21:39.183+0000] {spark_submit.py:649} INFO - found org.xerial.snappy#snappy-java;1.1.4 in central
[2025-05-02T02:21:39.245+0000] {spark_submit.py:649} INFO - found org.tukaani#xz;1.5 in central
[2025-05-02T02:21:39.285+0000] {spark_submit.py:649} INFO - found com.google.re2j#re2j;1.1 in central
[2025-05-02T02:21:39.336+0000] {spark_submit.py:649} INFO - found com.google.code.gson#gson;2.2.4 in central
[2025-05-02T02:21:39.385+0000] {spark_submit.py:649} INFO - found com.jcraft#jsch;0.1.54 in central
[2025-05-02T02:21:39.424+0000] {spark_submit.py:649} INFO - found com.google.code.findbugs#jsr305;3.0.0 in central
[2025-05-02T02:21:39.480+0000] {spark_submit.py:649} INFO - found org.apache.htrace#htrace-core4;4.1.0-incubating in central
[2025-05-02T02:21:39.561+0000] {spark_submit.py:649} INFO - found org.codehaus.woodstox#stax2-api;3.1.4 in central
[2025-05-02T02:21:39.598+0000] {spark_submit.py:649} INFO - found com.fasterxml.woodstox#woodstox-core;5.0.3 in central
[2025-05-02T02:21:39.628+0000] {spark_submit.py:649} INFO - found commons-daemon#commons-daemon;1.0.13 in central
[2025-05-02T02:21:39.666+0000] {spark_submit.py:649} INFO - found dnsjava#dnsjava;2.1.7 in central
[2025-05-02T02:21:39.692+0000] {spark_submit.py:649} INFO - found org.fusesource.leveldbjni#leveldbjni-all;1.8 in central
[2025-05-02T02:21:39.717+0000] {spark_submit.py:649} INFO - found org.apache.geronimo.specs#geronimo-jcache_1.0_spec;1.0-alpha-1 in central
[2025-05-02T02:21:39.740+0000] {spark_submit.py:649} INFO - found org.ehcache#ehcache;3.3.1 in central
[2025-05-02T02:21:39.774+0000] {spark_submit.py:649} INFO - found com.zaxxer#HikariCP-java7;2.4.12 in central
[2025-05-02T02:21:39.807+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-server-applicationhistoryservice;3.1.0 in central
[2025-05-02T02:21:39.873+0000] {spark_submit.py:649} INFO - found de.ruedigermoeller#fst;2.50 in central
[2025-05-02T02:21:39.903+0000] {spark_submit.py:649} INFO - found com.cedarsoftware#java-util;1.9.0 in central
[2025-05-02T02:21:39.932+0000] {spark_submit.py:649} INFO - found com.cedarsoftware#json-io;2.5.1 in central
[2025-05-02T02:21:39.963+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-yarn-server-web-proxy;3.1.0 in central
[2025-05-02T02:21:40.108+0000] {spark_submit.py:649} INFO - found javax.servlet.jsp#jsp-api;2.1 in central
[2025-05-02T02:21:40.145+0000] {spark_submit.py:649} INFO - found com.microsoft.sqlserver#mssql-jdbc;6.2.1.jre7 in central
[2025-05-02T02:21:40.178+0000] {spark_submit.py:649} INFO - found org.apache.hive.shims#hive-shims-scheduler;3.1.3 in central
[2025-05-02T02:21:40.198+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-storage-api;2.7.0 in central
[2025-05-02T02:21:40.210+0000] {spark_submit.py:649} INFO - found org.apache.commons#commons-lang3;3.9 in central
[2025-05-02T02:21:40.230+0000] {spark_submit.py:649} INFO - found org.apache.orc#orc-core;1.5.8 in central
[2025-05-02T02:21:40.251+0000] {spark_submit.py:649} INFO - found org.apache.orc#orc-shims;1.5.8 in central
[2025-05-02T02:21:40.274+0000] {spark_submit.py:649} INFO - found io.airlift#aircompressor;0.10 in central
[2025-05-02T02:21:40.292+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-rewrite;9.3.20.v20170531 in central
[2025-05-02T02:21:40.309+0000] {spark_submit.py:649} INFO - found org.eclipse.jetty#jetty-client;9.3.20.v20170531 in central
[2025-05-02T02:21:40.327+0000] {spark_submit.py:649} INFO - found joda-time#joda-time;2.9.9 in central
[2025-05-02T02:21:40.349+0000] {spark_submit.py:649} INFO - found org.apache.logging.log4j#log4j-1.2-api;2.17.1 in central
[2025-05-02T02:21:40.369+0000] {spark_submit.py:649} INFO - found org.apache.logging.log4j#log4j-web;2.17.1 in central
[2025-05-02T02:21:40.385+0000] {spark_submit.py:649} INFO - found org.apache.ant#ant;1.9.1 in central
[2025-05-02T02:21:40.401+0000] {spark_submit.py:649} INFO - found org.apache.ant#ant-launcher;1.9.1 in central
[2025-05-02T02:21:40.417+0000] {spark_submit.py:649} INFO - found net.sf.jpam#jpam;1.1 in central
[2025-05-02T02:21:40.442+0000] {spark_submit.py:649} INFO - found com.tdunning#json;1.8 in central
[2025-05-02T02:21:40.459+0000] {spark_submit.py:649} INFO - found io.dropwizard.metrics#metrics-core;3.1.0 in central
[2025-05-02T02:21:40.477+0000] {spark_submit.py:649} INFO - found io.dropwizard.metrics#metrics-jvm;3.1.0 in central
[2025-05-02T02:21:40.499+0000] {spark_submit.py:649} INFO - found io.dropwizard.metrics#metrics-json;3.1.0 in central
[2025-05-02T02:21:40.518+0000] {spark_submit.py:649} INFO - found com.github.joshelser#dropwizard-metrics-hadoop-metrics2-reporter;0.1.2 in central
[2025-05-02T02:21:40.543+0000] {spark_submit.py:649} INFO - found javolution#javolution;5.5.1 in central
[2025-05-02T02:21:40.580+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-service-rpc;3.1.3 in central
[2025-05-02T02:21:40.596+0000] {spark_submit.py:649} INFO - found org.apache.thrift#libfb303;0.9.3 in central
[2025-05-02T02:21:40.616+0000] {spark_submit.py:649} INFO - found org.apache.arrow#arrow-vector;0.8.0 in central
[2025-05-02T02:21:40.632+0000] {spark_submit.py:649} INFO - found org.apache.arrow#arrow-format;0.8.0 in central
[2025-05-02T02:21:40.648+0000] {spark_submit.py:649} INFO - found com.vlkan#flatbuffers;1.2.0-3f79e055 in central
[2025-05-02T02:21:40.665+0000] {spark_submit.py:649} INFO - found org.apache.arrow#arrow-memory;0.8.0 in central
[2025-05-02T02:21:40.686+0000] {spark_submit.py:649} INFO - found io.netty#netty-buffer;4.1.17.Final in central
[2025-05-02T02:21:40.704+0000] {spark_submit.py:649} INFO - found io.netty#netty-common;4.1.17.Final in central
[2025-05-02T02:21:40.727+0000] {spark_submit.py:649} INFO - found com.carrotsearch#hppc;0.7.2 in central
[2025-05-02T02:21:40.743+0000] {spark_submit.py:649} INFO - found net.sf.opencsv#opencsv;2.3 in central
[2025-05-02T02:21:40.757+0000] {spark_submit.py:649} INFO - found org.apache.parquet#parquet-hadoop-bundle;1.10.0 in central
[2025-05-02T02:21:40.778+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-standalone-metastore;3.1.3 in central
[2025-05-02T02:21:40.807+0000] {spark_submit.py:649} INFO - found com.jolbox#bonecp;0.8.0.RELEASE in central
[2025-05-02T02:21:40.836+0000] {spark_submit.py:649} INFO - found com.zaxxer#HikariCP;2.6.1 in central
[2025-05-02T02:21:40.851+0000] {spark_submit.py:649} INFO - found commons-dbcp#commons-dbcp;1.4 in central
[2025-05-02T02:21:40.866+0000] {spark_submit.py:649} INFO - found commons-pool#commons-pool;1.5.4 in central
[2025-05-02T02:21:40.891+0000] {spark_submit.py:649} INFO - found org.antlr#antlr-runtime;3.5.2 in central
[2025-05-02T02:21:40.926+0000] {spark_submit.py:649} INFO - found org.datanucleus#datanucleus-api-jdo;4.2.4 in central
[2025-05-02T02:21:40.940+0000] {spark_submit.py:649} INFO - found org.datanucleus#datanucleus-core;4.1.17 in central
[2025-05-02T02:21:40.955+0000] {spark_submit.py:649} INFO - found org.datanucleus#datanucleus-rdbms;4.1.19 in central
[2025-05-02T02:21:40.970+0000] {spark_submit.py:649} INFO - found org.datanucleus#javax.jdo;3.2.0-m3 in central
[2025-05-02T02:21:40.985+0000] {spark_submit.py:649} INFO - found javax.transaction#transaction-api;1.1 in central
[2025-05-02T02:21:41.000+0000] {spark_submit.py:649} INFO - found sqlline#sqlline;1.3.0 in central
[2025-05-02T02:21:41.025+0000] {spark_submit.py:649} INFO - found org.apache.hbase#hbase-client;2.0.0-alpha4 in central
[2025-05-02T02:21:41.042+0000] {spark_submit.py:649} INFO - found org.apache.hbase.thirdparty#hbase-shaded-protobuf;1.0.1 in central
[2025-05-02T02:21:41.063+0000] {spark_submit.py:649} INFO - found org.apache.hbase#hbase-protocol-shaded;2.0.0-alpha4 in central
[2025-05-02T02:21:41.079+0000] {spark_submit.py:649} INFO - found org.apache.yetus#audience-annotations;0.5.0 in central
[2025-05-02T02:21:41.093+0000] {spark_submit.py:649} INFO - found junit#junit;4.11 in central
[2025-05-02T02:21:41.109+0000] {spark_submit.py:649} INFO - found org.hamcrest#hamcrest-core;1.3 in central
[2025-05-02T02:21:41.128+0000] {spark_submit.py:649} INFO - found org.apache.hbase#hbase-protocol;2.0.0-alpha4 in central
[2025-05-02T02:21:41.156+0000] {spark_submit.py:649} INFO - found org.apache.hbase.thirdparty#hbase-shaded-miscellaneous;1.0.1 in central
[2025-05-02T02:21:41.170+0000] {spark_submit.py:649} INFO - found org.apache.hbase.thirdparty#hbase-shaded-netty;1.0.1 in central
[2025-05-02T02:21:41.187+0000] {spark_submit.py:649} INFO - found org.apache.htrace#htrace-core;3.2.0-incubating in central
[2025-05-02T02:21:41.212+0000] {spark_submit.py:649} INFO - found org.jruby.jcodings#jcodings;1.0.18 in central
[2025-05-02T02:21:41.228+0000] {spark_submit.py:649} INFO - found org.jruby.joni#joni;2.1.11 in central
[2025-05-02T02:21:41.240+0000] {spark_submit.py:649} INFO - found io.dropwizard.metrics#metrics-core;3.2.1 in central
[2025-05-02T02:21:41.259+0000] {spark_submit.py:649} INFO - found org.apache.commons#commons-crypto;1.0.0 in central
[2025-05-02T02:21:41.283+0000] {spark_submit.py:649} INFO - found javax.jdo#jdo-api;3.0.1 in central
[2025-05-02T02:21:41.296+0000] {spark_submit.py:649} INFO - found javax.transaction#jta;1.1 in central
[2025-05-02T02:21:41.309+0000] {spark_submit.py:649} INFO - found co.cask.tephra#tephra-api;0.6.0 in central
[2025-05-02T02:21:41.323+0000] {spark_submit.py:649} INFO - found co.cask.tephra#tephra-core;0.6.0 in central
[2025-05-02T02:21:41.344+0000] {spark_submit.py:649} INFO - found com.google.inject.extensions#guice-assistedinject;3.0 in central
[2025-05-02T02:21:41.361+0000] {spark_submit.py:649} INFO - found it.unimi.dsi#fastutil;6.5.6 in central
[2025-05-02T02:21:41.377+0000] {spark_submit.py:649} INFO - found org.apache.twill#twill-common;0.6.0-incubating in central
[2025-05-02T02:21:41.395+0000] {spark_submit.py:649} INFO - found org.apache.twill#twill-core;0.6.0-incubating in central
[2025-05-02T02:21:41.412+0000] {spark_submit.py:649} INFO - found org.apache.twill#twill-api;0.6.0-incubating in central
[2025-05-02T02:21:41.430+0000] {spark_submit.py:649} INFO - found org.apache.twill#twill-discovery-api;0.6.0-incubating in central
[2025-05-02T02:21:41.448+0000] {spark_submit.py:649} INFO - found org.apache.twill#twill-zookeeper;0.6.0-incubating in central
[2025-05-02T02:21:41.473+0000] {spark_submit.py:649} INFO - found org.apache.twill#twill-discovery-core;0.6.0-incubating in central
[2025-05-02T02:21:41.497+0000] {spark_submit.py:649} INFO - found co.cask.tephra#tephra-hbase-compat-1.0;0.6.0 in central
[2025-05-02T02:21:41.520+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-exec;3.1.3 in central
[2025-05-02T02:21:41.543+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-llap-tez;3.1.3 in central
[2025-05-02T02:21:41.570+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-llap-client;3.1.3 in central
[2025-05-02T02:21:41.604+0000] {spark_submit.py:649} INFO - found org.apache.hive#hive-llap-common;3.1.3 in central
[2025-05-02T02:21:41.680+0000] {spark_submit.py:649} INFO - found org.antlr#ST4;4.0.4 in central
[2025-05-02T02:21:41.714+0000] {spark_submit.py:649} INFO - found org.apache.ivy#ivy;2.4.0 in central
[2025-05-02T02:21:41.730+0000] {spark_submit.py:649} INFO - found org.codehaus.groovy#groovy-all;2.4.11 in central
[2025-05-02T02:21:41.764+0000] {spark_submit.py:649} INFO - found org.apache.calcite#calcite-core;1.16.0 in central
[2025-05-02T02:21:41.782+0000] {spark_submit.py:649} INFO - found org.apache.calcite#calcite-linq4j;1.16.0 in central
[2025-05-02T02:21:41.809+0000] {spark_submit.py:649} INFO - found com.esri.geometry#esri-geometry-api;2.0.0 in central
[2025-05-02T02:21:41.823+0000] {spark_submit.py:649} INFO - found com.google.code.findbugs#jsr305;3.0.1 in central
[2025-05-02T02:21:41.838+0000] {spark_submit.py:649} INFO - found com.yahoo.datasketches#sketches-core;0.9.0 in central
[2025-05-02T02:21:41.853+0000] {spark_submit.py:649} INFO - found com.yahoo.datasketches#memory;0.9.0 in central
[2025-05-02T02:21:41.868+0000] {spark_submit.py:649} INFO - found org.codehaus.janino#janino;2.7.6 in central
[2025-05-02T02:21:41.895+0000] {spark_submit.py:649} INFO - found org.codehaus.janino#commons-compiler;2.7.6 in central
[2025-05-02T02:21:41.915+0000] {spark_submit.py:649} INFO - found org.apache.calcite.avatica#avatica;1.11.0 in central
[2025-05-02T02:21:41.933+0000] {spark_submit.py:649} INFO - found stax#stax-api;1.0.1 in central
[2025-05-02T02:21:41.958+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2025-05-02T02:21:41.969+0000] {spark_submit.py:649} INFO - found org.xerial.snappy#snappy-java;1.1.8.2 in central
[2025-05-02T02:21:41.988+0000] {spark_submit.py:649} INFO - found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2025-05-02T02:21:41.999+0000] {spark_submit.py:649} INFO - found org.slf4j#slf4j-api;1.7.36 in central
[2025-05-02T02:21:42.348+0000] {spark_submit.py:649} INFO - :: resolution report :: resolve 7626ms :: artifacts dl 298ms
[2025-05-02T02:21:42.350+0000] {spark_submit.py:649} INFO - :: modules in use:
[2025-05-02T02:21:42.351+0000] {spark_submit.py:649} INFO - aopalliance#aopalliance;1.0 from central in [default]
[2025-05-02T02:21:42.352+0000] {spark_submit.py:649} INFO - co.cask.tephra#tephra-api;0.6.0 from central in [default]
[2025-05-02T02:21:42.352+0000] {spark_submit.py:649} INFO - co.cask.tephra#tephra-core;0.6.0 from central in [default]
[2025-05-02T02:21:42.353+0000] {spark_submit.py:649} INFO - co.cask.tephra#tephra-hbase-compat-1.0;0.6.0 from central in [default]
[2025-05-02T02:21:42.354+0000] {spark_submit.py:649} INFO - com.carrotsearch#hppc;0.7.2 from central in [default]
[2025-05-02T02:21:42.355+0000] {spark_submit.py:649} INFO - com.cedarsoftware#java-util;1.9.0 from central in [default]
[2025-05-02T02:21:42.356+0000] {spark_submit.py:649} INFO - com.cedarsoftware#json-io;2.5.1 from central in [default]
[2025-05-02T02:21:42.357+0000] {spark_submit.py:649} INFO - com.esri.geometry#esri-geometry-api;2.0.0 from central in [default]
[2025-05-02T02:21:42.358+0000] {spark_submit.py:649} INFO - com.fasterxml.jackson.core#jackson-annotations;2.12.0 from central in [default]
[2025-05-02T02:21:42.359+0000] {spark_submit.py:649} INFO - com.fasterxml.jackson.core#jackson-core;2.12.0 from central in [default]
[2025-05-02T02:21:42.360+0000] {spark_submit.py:649} INFO - com.fasterxml.jackson.core#jackson-databind;2.12.0 from central in [default]
[2025-05-02T02:21:42.361+0000] {spark_submit.py:649} INFO - com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.12.0 from central in [default]
[2025-05-02T02:21:42.362+0000] {spark_submit.py:649} INFO - com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.12.0 from central in [default]
[2025-05-02T02:21:42.363+0000] {spark_submit.py:649} INFO - com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.12.0 from central in [default]
[2025-05-02T02:21:42.364+0000] {spark_submit.py:649} INFO - com.fasterxml.woodstox#woodstox-core;5.0.3 from central in [default]
[2025-05-02T02:21:42.365+0000] {spark_submit.py:649} INFO - com.github.joshelser#dropwizard-metrics-hadoop-metrics2-reporter;0.1.2 from central in [default]
[2025-05-02T02:21:42.366+0000] {spark_submit.py:649} INFO - com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-05-02T02:21:42.367+0000] {spark_submit.py:649} INFO - com.google.code.findbugs#jsr305;3.0.1 from central in [default]
[2025-05-02T02:21:42.368+0000] {spark_submit.py:649} INFO - com.google.code.gson#gson;2.2.4 from central in [default]
[2025-05-02T02:21:42.369+0000] {spark_submit.py:649} INFO - com.google.guava#guava;19.0 from central in [default]
[2025-05-02T02:21:42.370+0000] {spark_submit.py:649} INFO - com.google.inject#guice;4.0 from central in [default]
[2025-05-02T02:21:42.371+0000] {spark_submit.py:649} INFO - com.google.inject.extensions#guice-assistedinject;3.0 from central in [default]
[2025-05-02T02:21:42.372+0000] {spark_submit.py:649} INFO - com.google.inject.extensions#guice-servlet;4.0 from central in [default]
[2025-05-02T02:21:42.373+0000] {spark_submit.py:649} INFO - com.google.protobuf#protobuf-java;2.5.0 from central in [default]
[2025-05-02T02:21:42.374+0000] {spark_submit.py:649} INFO - com.google.re2j#re2j;1.1 from central in [default]
[2025-05-02T02:21:42.375+0000] {spark_submit.py:649} INFO - com.jcraft#jsch;0.1.54 from central in [default]
[2025-05-02T02:21:42.376+0000] {spark_submit.py:649} INFO - com.jolbox#bonecp;0.8.0.RELEASE from central in [default]
[2025-05-02T02:21:42.377+0000] {spark_submit.py:649} INFO - com.microsoft.sqlserver#mssql-jdbc;6.2.1.jre7 from central in [default]
[2025-05-02T02:21:42.378+0000] {spark_submit.py:649} INFO - com.nimbusds#nimbus-jose-jwt;4.41.1 from central in [default]
[2025-05-02T02:21:42.379+0000] {spark_submit.py:649} INFO - com.sun.jersey#jersey-client;1.19 from central in [default]
[2025-05-02T02:21:42.380+0000] {spark_submit.py:649} INFO - com.sun.jersey#jersey-core;1.19 from central in [default]
[2025-05-02T02:21:42.381+0000] {spark_submit.py:649} INFO - com.sun.jersey#jersey-json;1.19 from central in [default]
[2025-05-02T02:21:42.381+0000] {spark_submit.py:649} INFO - com.sun.jersey#jersey-server;1.19 from central in [default]
[2025-05-02T02:21:42.382+0000] {spark_submit.py:649} INFO - com.sun.jersey#jersey-servlet;1.19 from central in [default]
[2025-05-02T02:21:42.383+0000] {spark_submit.py:649} INFO - com.sun.jersey.contribs#jersey-guice;1.19 from central in [default]
[2025-05-02T02:21:42.384+0000] {spark_submit.py:649} INFO - com.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]
[2025-05-02T02:21:42.386+0000] {spark_submit.py:649} INFO - com.tdunning#json;1.8 from central in [default]
[2025-05-02T02:21:42.388+0000] {spark_submit.py:649} INFO - com.thoughtworks.paranamer#paranamer;2.7 from central in [default]
[2025-05-02T02:21:42.388+0000] {spark_submit.py:649} INFO - com.vlkan#flatbuffers;1.2.0-3f79e055 from central in [default]
[2025-05-02T02:21:42.389+0000] {spark_submit.py:649} INFO - com.yahoo.datasketches#memory;0.9.0 from central in [default]
[2025-05-02T02:21:42.390+0000] {spark_submit.py:649} INFO - com.yahoo.datasketches#sketches-core;0.9.0 from central in [default]
[2025-05-02T02:21:42.391+0000] {spark_submit.py:649} INFO - com.zaxxer#HikariCP;2.6.1 from central in [default]
[2025-05-02T02:21:42.392+0000] {spark_submit.py:649} INFO - com.zaxxer#HikariCP-java7;2.4.12 from central in [default]
[2025-05-02T02:21:42.393+0000] {spark_submit.py:649} INFO - commons-beanutils#commons-beanutils;1.9.3 from central in [default]
[2025-05-02T02:21:42.394+0000] {spark_submit.py:649} INFO - commons-cli#commons-cli;1.2 from central in [default]
[2025-05-02T02:21:42.395+0000] {spark_submit.py:649} INFO - commons-codec#commons-codec;1.15 from central in [default]
[2025-05-02T02:21:42.396+0000] {spark_submit.py:649} INFO - commons-collections#commons-collections;3.2.2 from central in [default]
[2025-05-02T02:21:42.397+0000] {spark_submit.py:649} INFO - commons-daemon#commons-daemon;1.0.13 from central in [default]
[2025-05-02T02:21:42.398+0000] {spark_submit.py:649} INFO - commons-dbcp#commons-dbcp;1.4 from central in [default]
[2025-05-02T02:21:42.399+0000] {spark_submit.py:649} INFO - commons-io#commons-io;2.6 from central in [default]
[2025-05-02T02:21:42.400+0000] {spark_submit.py:649} INFO - commons-lang#commons-lang;2.6 from central in [default]
[2025-05-02T02:21:42.401+0000] {spark_submit.py:649} INFO - commons-logging#commons-logging;1.2 from central in [default]
[2025-05-02T02:21:42.402+0000] {spark_submit.py:649} INFO - commons-net#commons-net;3.6 from central in [default]
[2025-05-02T02:21:42.402+0000] {spark_submit.py:649} INFO - commons-pool#commons-pool;1.5.4 from central in [default]
[2025-05-02T02:21:42.403+0000] {spark_submit.py:649} INFO - de.ruedigermoeller#fst;2.50 from central in [default]
[2025-05-02T02:21:42.404+0000] {spark_submit.py:649} INFO - dnsjava#dnsjava;2.1.7 from central in [default]
[2025-05-02T02:21:42.405+0000] {spark_submit.py:649} INFO - io.airlift#aircompressor;0.10 from central in [default]
[2025-05-02T02:21:42.406+0000] {spark_submit.py:649} INFO - io.dropwizard.metrics#metrics-core;3.2.1 from central in [default]
[2025-05-02T02:21:42.407+0000] {spark_submit.py:649} INFO - io.dropwizard.metrics#metrics-json;3.1.0 from central in [default]
[2025-05-02T02:21:42.408+0000] {spark_submit.py:649} INFO - io.dropwizard.metrics#metrics-jvm;3.1.0 from central in [default]
[2025-05-02T02:21:42.409+0000] {spark_submit.py:649} INFO - io.netty#netty;3.7.0.Final from central in [default]
[2025-05-02T02:21:42.410+0000] {spark_submit.py:649} INFO - io.netty#netty-buffer;4.1.17.Final from central in [default]
[2025-05-02T02:21:42.411+0000] {spark_submit.py:649} INFO - io.netty#netty-common;4.1.17.Final from central in [default]
[2025-05-02T02:21:42.411+0000] {spark_submit.py:649} INFO - it.unimi.dsi#fastutil;6.5.6 from central in [default]
[2025-05-02T02:21:42.412+0000] {spark_submit.py:649} INFO - jakarta.activation#jakarta.activation-api;1.2.1 from central in [default]
[2025-05-02T02:21:42.413+0000] {spark_submit.py:649} INFO - jakarta.xml.bind#jakarta.xml.bind-api;2.3.2 from central in [default]
[2025-05-02T02:21:42.414+0000] {spark_submit.py:649} INFO - javax.inject#javax.inject;1 from central in [default]
[2025-05-02T02:21:42.415+0000] {spark_submit.py:649} INFO - javax.jdo#jdo-api;3.0.1 from central in [default]
[2025-05-02T02:21:42.416+0000] {spark_submit.py:649} INFO - javax.servlet#javax.servlet-api;3.1.0 from central in [default]
[2025-05-02T02:21:42.417+0000] {spark_submit.py:649} INFO - javax.servlet.jsp#jsp-api;2.1 from central in [default]
[2025-05-02T02:21:42.418+0000] {spark_submit.py:649} INFO - javax.transaction#jta;1.1 from central in [default]
[2025-05-02T02:21:42.419+0000] {spark_submit.py:649} INFO - javax.transaction#transaction-api;1.1 from central in [default]
[2025-05-02T02:21:42.419+0000] {spark_submit.py:649} INFO - javax.ws.rs#jsr311-api;1.1.1 from central in [default]
[2025-05-02T02:21:42.420+0000] {spark_submit.py:649} INFO - javax.xml.bind#jaxb-api;2.2.11 from central in [default]
[2025-05-02T02:21:42.421+0000] {spark_submit.py:649} INFO - javolution#javolution;5.5.1 from central in [default]
[2025-05-02T02:21:42.422+0000] {spark_submit.py:649} INFO - jline#jline;2.12 from central in [default]
[2025-05-02T02:21:42.423+0000] {spark_submit.py:649} INFO - joda-time#joda-time;2.9.9 from central in [default]
[2025-05-02T02:21:42.424+0000] {spark_submit.py:649} INFO - junit#junit;4.11 from central in [default]
[2025-05-02T02:21:42.425+0000] {spark_submit.py:649} INFO - log4j#log4j;1.2.17 from central in [default]
[2025-05-02T02:21:42.426+0000] {spark_submit.py:649} INFO - net.minidev#accessors-smart;1.2 from central in [default]
[2025-05-02T02:21:42.427+0000] {spark_submit.py:649} INFO - net.minidev#json-smart;2.3 from central in [default]
[2025-05-02T02:21:42.428+0000] {spark_submit.py:649} INFO - net.sf.jpam#jpam;1.1 from central in [default]
[2025-05-02T02:21:42.429+0000] {spark_submit.py:649} INFO - net.sf.opencsv#opencsv;2.3 from central in [default]
[2025-05-02T02:21:42.430+0000] {spark_submit.py:649} INFO - org.antlr#ST4;4.0.4 from central in [default]
[2025-05-02T02:21:42.430+0000] {spark_submit.py:649} INFO - org.antlr#antlr-runtime;3.5.2 from central in [default]
[2025-05-02T02:21:42.431+0000] {spark_submit.py:649} INFO - org.apache.ant#ant;1.9.1 from central in [default]
[2025-05-02T02:21:42.432+0000] {spark_submit.py:649} INFO - org.apache.ant#ant-launcher;1.9.1 from central in [default]
[2025-05-02T02:21:42.433+0000] {spark_submit.py:649} INFO - org.apache.arrow#arrow-format;0.8.0 from central in [default]
[2025-05-02T02:21:42.434+0000] {spark_submit.py:649} INFO - org.apache.arrow#arrow-memory;0.8.0 from central in [default]
[2025-05-02T02:21:42.435+0000] {spark_submit.py:649} INFO - org.apache.arrow#arrow-vector;0.8.0 from central in [default]
[2025-05-02T02:21:42.436+0000] {spark_submit.py:649} INFO - org.apache.avro#avro;1.8.2 from central in [default]
[2025-05-02T02:21:42.437+0000] {spark_submit.py:649} INFO - org.apache.calcite#calcite-core;1.16.0 from central in [default]
[2025-05-02T02:21:42.438+0000] {spark_submit.py:649} INFO - org.apache.calcite#calcite-linq4j;1.16.0 from central in [default]
[2025-05-02T02:21:42.439+0000] {spark_submit.py:649} INFO - org.apache.calcite.avatica#avatica;1.11.0 from central in [default]
[2025-05-02T02:21:42.440+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-compress;1.19 from central in [default]
[2025-05-02T02:21:42.441+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-configuration2;2.1.1 from central in [default]
[2025-05-02T02:21:42.442+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-crypto;1.0.0 from central in [default]
[2025-05-02T02:21:42.443+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-lang3;3.9 from central in [default]
[2025-05-02T02:21:42.443+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-math3;3.1.1 from central in [default]
[2025-05-02T02:21:42.444+0000] {spark_submit.py:649} INFO - org.apache.derby#derby;10.14.1.0 from central in [default]
[2025-05-02T02:21:42.445+0000] {spark_submit.py:649} INFO - org.apache.geronimo.specs#geronimo-jcache_1.0_spec;1.0-alpha-1 from central in [default]
[2025-05-02T02:21:42.446+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-annotations;3.1.0 from central in [default]
[2025-05-02T02:21:42.447+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-auth;3.1.0 from central in [default]
[2025-05-02T02:21:42.448+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
[2025-05-02T02:21:42.449+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
[2025-05-02T02:21:42.450+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-common;3.1.0 from central in [default]
[2025-05-02T02:21:42.451+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-api;3.1.0 from central in [default]
[2025-05-02T02:21:42.452+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-common;3.1.0 from central in [default]
[2025-05-02T02:21:42.453+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-registry;3.1.0 from central in [default]
[2025-05-02T02:21:42.454+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-server-applicationhistoryservice;3.1.0 from central in [default]
[2025-05-02T02:21:42.455+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-server-common;3.1.0 from central in [default]
[2025-05-02T02:21:42.455+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-server-resourcemanager;3.1.0 from central in [default]
[2025-05-02T02:21:42.456+0000] {spark_submit.py:649} INFO - org.apache.hadoop#hadoop-yarn-server-web-proxy;3.1.0 from central in [default]
[2025-05-02T02:21:42.457+0000] {spark_submit.py:649} INFO - org.apache.hbase#hbase-client;2.0.0-alpha4 from central in [default]
[2025-05-02T02:21:42.458+0000] {spark_submit.py:649} INFO - org.apache.hbase#hbase-protocol;2.0.0-alpha4 from central in [default]
[2025-05-02T02:21:42.459+0000] {spark_submit.py:649} INFO - org.apache.hbase#hbase-protocol-shaded;2.0.0-alpha4 from central in [default]
[2025-05-02T02:21:42.460+0000] {spark_submit.py:649} INFO - org.apache.hbase.thirdparty#hbase-shaded-miscellaneous;1.0.1 from central in [default]
[2025-05-02T02:21:42.461+0000] {spark_submit.py:649} INFO - org.apache.hbase.thirdparty#hbase-shaded-netty;1.0.1 from central in [default]
[2025-05-02T02:21:42.461+0000] {spark_submit.py:649} INFO - org.apache.hbase.thirdparty#hbase-shaded-protobuf;1.0.1 from central in [default]
[2025-05-02T02:21:42.462+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-classification;3.1.3 from central in [default]
[2025-05-02T02:21:42.463+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-common;3.1.3 from central in [default]
[2025-05-02T02:21:42.464+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-exec;3.1.3 from central in [default]
[2025-05-02T02:21:42.465+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-llap-client;3.1.3 from central in [default]
[2025-05-02T02:21:42.466+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-llap-common;3.1.3 from central in [default]
[2025-05-02T02:21:42.467+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-llap-tez;3.1.3 from central in [default]
[2025-05-02T02:21:42.468+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-metastore;3.1.3 from central in [default]
[2025-05-02T02:21:42.469+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-serde;3.1.3 from central in [default]
[2025-05-02T02:21:42.469+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-service-rpc;3.1.3 from central in [default]
[2025-05-02T02:21:42.470+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-shims;3.1.3 from central in [default]
[2025-05-02T02:21:42.471+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-standalone-metastore;3.1.3 from central in [default]
[2025-05-02T02:21:42.472+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-storage-api;2.7.0 from central in [default]
[2025-05-02T02:21:42.473+0000] {spark_submit.py:649} INFO - org.apache.hive#hive-upgrade-acid;3.1.3 from central in [default]
[2025-05-02T02:21:42.474+0000] {spark_submit.py:649} INFO - org.apache.hive.shims#hive-shims-0.23;3.1.3 from central in [default]
[2025-05-02T02:21:42.475+0000] {spark_submit.py:649} INFO - org.apache.hive.shims#hive-shims-common;3.1.3 from central in [default]
[2025-05-02T02:21:42.475+0000] {spark_submit.py:649} INFO - org.apache.hive.shims#hive-shims-scheduler;3.1.3 from central in [default]
[2025-05-02T02:21:42.476+0000] {spark_submit.py:649} INFO - org.apache.htrace#htrace-core;3.2.0-incubating from central in [default]
[2025-05-02T02:21:42.477+0000] {spark_submit.py:649} INFO - org.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]
[2025-05-02T02:21:42.478+0000] {spark_submit.py:649} INFO - org.apache.httpcomponents#httpclient;4.5.13 from central in [default]
[2025-05-02T02:21:42.479+0000] {spark_submit.py:649} INFO - org.apache.httpcomponents#httpcore;4.4.13 from central in [default]
[2025-05-02T02:21:42.480+0000] {spark_submit.py:649} INFO - org.apache.ivy#ivy;2.4.0 from central in [default]
[2025-05-02T02:21:42.481+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-admin;1.0.1 from central in [default]
[2025-05-02T02:21:42.482+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-client;1.0.1 from central in [default]
[2025-05-02T02:21:42.483+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-common;1.0.1 from central in [default]
[2025-05-02T02:21:42.483+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-core;1.0.1 from central in [default]
[2025-05-02T02:21:42.484+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-crypto;1.0.1 from central in [default]
[2025-05-02T02:21:42.485+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-identity;1.0.1 from central in [default]
[2025-05-02T02:21:42.486+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-server;1.0.1 from central in [default]
[2025-05-02T02:21:42.487+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-simplekdc;1.0.1 from central in [default]
[2025-05-02T02:21:42.488+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerb-util;1.0.1 from central in [default]
[2025-05-02T02:21:42.489+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerby-asn1;1.0.1 from central in [default]
[2025-05-02T02:21:42.490+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerby-config;1.0.1 from central in [default]
[2025-05-02T02:21:42.491+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerby-pkix;1.0.1 from central in [default]
[2025-05-02T02:21:42.492+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerby-util;1.0.1 from central in [default]
[2025-05-02T02:21:42.493+0000] {spark_submit.py:649} INFO - org.apache.kerby#kerby-xdr;1.0.1 from central in [default]
[2025-05-02T02:21:42.494+0000] {spark_submit.py:649} INFO - org.apache.kerby#token-provider;1.0.1 from central in [default]
[2025-05-02T02:21:42.495+0000] {spark_submit.py:649} INFO - org.apache.logging.log4j#log4j-1.2-api;2.17.1 from central in [default]
[2025-05-02T02:21:42.495+0000] {spark_submit.py:649} INFO - org.apache.logging.log4j#log4j-api;2.10.0 from central in [default]
[2025-05-02T02:21:42.496+0000] {spark_submit.py:649} INFO - org.apache.logging.log4j#log4j-core;2.17.1 from central in [default]
[2025-05-02T02:21:42.497+0000] {spark_submit.py:649} INFO - org.apache.logging.log4j#log4j-slf4j-impl;2.17.1 from central in [default]
[2025-05-02T02:21:42.498+0000] {spark_submit.py:649} INFO - org.apache.logging.log4j#log4j-web;2.17.1 from central in [default]
[2025-05-02T02:21:42.499+0000] {spark_submit.py:649} INFO - org.apache.orc#orc-core;1.5.8 from central in [default]
[2025-05-02T02:21:42.500+0000] {spark_submit.py:649} INFO - org.apache.orc#orc-shims;1.5.8 from central in [default]
[2025-05-02T02:21:42.501+0000] {spark_submit.py:649} INFO - org.apache.parquet#parquet-hadoop-bundle;1.10.0 from central in [default]
[2025-05-02T02:21:42.502+0000] {spark_submit.py:649} INFO - org.apache.thrift#libfb303;0.9.3 from central in [default]
[2025-05-02T02:21:42.503+0000] {spark_submit.py:649} INFO - org.apache.thrift#libthrift;0.9.3 from central in [default]
[2025-05-02T02:21:42.504+0000] {spark_submit.py:649} INFO - org.apache.twill#twill-api;0.6.0-incubating from central in [default]
[2025-05-02T02:21:42.505+0000] {spark_submit.py:649} INFO - org.apache.twill#twill-common;0.6.0-incubating from central in [default]
[2025-05-02T02:21:42.506+0000] {spark_submit.py:649} INFO - org.apache.twill#twill-core;0.6.0-incubating from central in [default]
[2025-05-02T02:21:42.507+0000] {spark_submit.py:649} INFO - org.apache.twill#twill-discovery-api;0.6.0-incubating from central in [default]
[2025-05-02T02:21:42.508+0000] {spark_submit.py:649} INFO - org.apache.twill#twill-discovery-core;0.6.0-incubating from central in [default]
[2025-05-02T02:21:42.509+0000] {spark_submit.py:649} INFO - org.apache.twill#twill-zookeeper;0.6.0-incubating from central in [default]
[2025-05-02T02:21:42.510+0000] {spark_submit.py:649} INFO - org.apache.yetus#audience-annotations;0.5.0 from central in [default]
[2025-05-02T02:21:42.511+0000] {spark_submit.py:649} INFO - org.apache.zookeeper#zookeeper;3.4.6 from central in [default]
[2025-05-02T02:21:42.512+0000] {spark_submit.py:649} INFO - org.codehaus.groovy#groovy-all;2.4.11 from central in [default]
[2025-05-02T02:21:42.513+0000] {spark_submit.py:649} INFO - org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
[2025-05-02T02:21:42.514+0000] {spark_submit.py:649} INFO - org.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]
[2025-05-02T02:21:42.515+0000] {spark_submit.py:649} INFO - org.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]
[2025-05-02T02:21:42.516+0000] {spark_submit.py:649} INFO - org.codehaus.jackson#jackson-xc;1.9.13 from central in [default]
[2025-05-02T02:21:42.517+0000] {spark_submit.py:649} INFO - org.codehaus.janino#commons-compiler;2.7.6 from central in [default]
[2025-05-02T02:21:42.518+0000] {spark_submit.py:649} INFO - org.codehaus.janino#janino;2.7.6 from central in [default]
[2025-05-02T02:21:42.519+0000] {spark_submit.py:649} INFO - org.codehaus.jettison#jettison;1.1 from central in [default]
[2025-05-02T02:21:42.520+0000] {spark_submit.py:649} INFO - org.codehaus.woodstox#stax2-api;3.1.4 from central in [default]
[2025-05-02T02:21:42.521+0000] {spark_submit.py:649} INFO - org.datanucleus#datanucleus-api-jdo;4.2.4 from central in [default]
[2025-05-02T02:21:42.522+0000] {spark_submit.py:649} INFO - org.datanucleus#datanucleus-core;4.1.17 from central in [default]
[2025-05-02T02:21:42.523+0000] {spark_submit.py:649} INFO - org.datanucleus#datanucleus-rdbms;4.1.19 from central in [default]
[2025-05-02T02:21:42.524+0000] {spark_submit.py:649} INFO - org.datanucleus#javax.jdo;3.2.0-m3 from central in [default]
[2025-05-02T02:21:42.525+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-client;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.526+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-http;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.527+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-io;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.528+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-rewrite;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.529+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-security;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.530+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-server;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.531+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-servlet;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.532+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-util;9.3.19.v20170502 from central in [default]
[2025-05-02T02:21:42.533+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-util-ajax;9.3.19.v20170502 from central in [default]
[2025-05-02T02:21:42.534+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-webapp;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.535+0000] {spark_submit.py:649} INFO - org.eclipse.jetty#jetty-xml;9.3.20.v20170531 from central in [default]
[2025-05-02T02:21:42.536+0000] {spark_submit.py:649} INFO - org.ehcache#ehcache;3.3.1 from central in [default]
[2025-05-02T02:21:42.537+0000] {spark_submit.py:649} INFO - org.fusesource.leveldbjni#leveldbjni-all;1.8 from central in [default]
[2025-05-02T02:21:42.538+0000] {spark_submit.py:649} INFO - org.hamcrest#hamcrest-core;1.3 from central in [default]
[2025-05-02T02:21:42.539+0000] {spark_submit.py:649} INFO - org.jruby.jcodings#jcodings;1.0.18 from central in [default]
[2025-05-02T02:21:42.540+0000] {spark_submit.py:649} INFO - org.jruby.joni#joni;2.1.11 from central in [default]
[2025-05-02T02:21:42.541+0000] {spark_submit.py:649} INFO - org.ow2.asm#asm;5.0.4 from central in [default]
[2025-05-02T02:21:42.549+0000] {spark_submit.py:649} INFO - org.slf4j#slf4j-api;1.7.36 from central in [default]
[2025-05-02T02:21:42.550+0000] {spark_submit.py:649} INFO - org.slf4j#slf4j-log4j12;1.6.1 from central in [default]
[2025-05-02T02:21:42.551+0000] {spark_submit.py:649} INFO - org.tukaani#xz;1.5 from central in [default]
[2025-05-02T02:21:42.552+0000] {spark_submit.py:649} INFO - org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
[2025-05-02T02:21:42.553+0000] {spark_submit.py:649} INFO - sqlline#sqlline;1.3.0 from central in [default]
[2025-05-02T02:21:42.554+0000] {spark_submit.py:649} INFO - stax#stax-api;1.0.1 from central in [default]
[2025-05-02T02:21:42.555+0000] {spark_submit.py:649} INFO - :: evicted modules:
[2025-05-02T02:21:42.555+0000] {spark_submit.py:649} INFO - org.slf4j#slf4j-api;1.7.10 by [org.slf4j#slf4j-api;1.7.36] in [default]
[2025-05-02T02:21:42.556+0000] {spark_submit.py:649} INFO - log4j#log4j;1.2.16 by [log4j#log4j;1.2.17] in [default]
[2025-05-02T02:21:42.557+0000] {spark_submit.py:649} INFO - commons-logging#commons-logging;1.1.3 by [commons-logging#commons-logging;1.2] in [default]
[2025-05-02T02:21:42.558+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-lang3;3.4 by [org.apache.commons#commons-lang3;3.9] in [default]
[2025-05-02T02:21:42.558+0000] {spark_submit.py:649} INFO - org.xerial.snappy#snappy-java;1.1.4 by [org.xerial.snappy#snappy-java;1.1.8.2] in [default]
[2025-05-02T02:21:42.559+0000] {spark_submit.py:649} INFO - com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.1] in [default]
[2025-05-02T02:21:42.560+0000] {spark_submit.py:649} INFO - commons-logging#commons-logging;1.0.4 by [commons-logging#commons-logging;1.2] in [default]
[2025-05-02T02:21:42.561+0000] {spark_submit.py:649} INFO - io.dropwizard.metrics#metrics-core;3.1.0 by [io.dropwizard.metrics#metrics-core;3.2.1] in [default]
[2025-05-02T02:21:42.562+0000] {spark_submit.py:649} INFO - io.dropwizard.metrics#metrics-core;3.1.2 by [io.dropwizard.metrics#metrics-core;3.1.0] in [default]
[2025-05-02T02:21:42.563+0000] {spark_submit.py:649} INFO - com.google.code.findbugs#jsr305;3.0.2 by [com.google.code.findbugs#jsr305;3.0.1] in [default]
[2025-05-02T02:21:42.564+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-lang3;3.2 by [org.apache.commons#commons-lang3;3.9] in [default]
[2025-05-02T02:21:42.564+0000] {spark_submit.py:649} INFO - org.apache.commons#commons-lang3;3.6 by [org.apache.commons#commons-lang3;3.9] in [default]
[2025-05-02T02:21:42.565+0000] {spark_submit.py:649} INFO - com.google.inject#guice;3.0 by [com.google.inject#guice;4.0] in [default]
[2025-05-02T02:21:42.566+0000] {spark_submit.py:649} INFO - com.google.code.findbugs#jsr305;2.0.1 by [com.google.code.findbugs#jsr305;3.0.0] in [default]
[2025-05-02T02:21:42.568+0000] {spark_submit.py:649} INFO - com.google.guava#guava;14.0.1 by [com.google.guava#guava;19.0] in [default]
[2025-05-02T02:21:42.568+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2025-05-02T02:21:42.569+0000] {spark_submit.py:649} INFO - |                  |            modules            ||   artifacts   |
[2025-05-02T02:21:42.570+0000] {spark_submit.py:649} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-02T02:21:42.571+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2025-05-02T02:21:42.572+0000] {spark_submit.py:649} INFO - |      default     |  224  |   0   |   0   |   15  ||  209  |   0   |
[2025-05-02T02:21:42.573+0000] {spark_submit.py:649} INFO - ---------------------------------------------------------------------
[2025-05-02T02:21:42.574+0000] {spark_submit.py:649} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-d7530b0b-f2df-4130-b953-348ddac67177
[2025-05-02T02:21:42.575+0000] {spark_submit.py:649} INFO - confs: [default]
[2025-05-02T02:21:42.576+0000] {spark_submit.py:649} INFO - 0 artifacts copied, 209 already retrieved (0kB/62ms)
[2025-05-02T02:21:43.626+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:43 INFO IsolatedClientLoader: Downloaded metastore jars to /tmp/hive-v3_1-74880417-547d-45d1-8446-2e60c5c3d219
[2025-05-02T02:21:44.327+0000] {spark_submit.py:649} INFO - Hive Session ID = 7b971e83-f772-439d-9687-b88338e47dad
[2025-05-02T02:21:44.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:44 INFO HiveClientImpl: Warehouse location for Hive client (version 3.1.3) is file:/opt/***/spark-warehouse
[2025-05-02T02:21:45.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:45 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-05-02T02:21:45.616+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:45 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-05-02T02:21:45.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:45 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-05-02T02:21:47.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:47 INFO DelegatingLogStore: LogStore LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore) is used for scheme s3a
[2025-05-02T02:21:47.605+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:47 INFO DeltaLog: Loading version 0.
[2025-05-02T02:21:48.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:48 INFO Snapshot: [tableId=cf55fba8-b1ba-4fd1-8f4c-17adc41406c9] Created snapshot Snapshot(path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log, version=0, metadata=Metadata(bef1654a-6e63-429e-80f2-5aee639b1a79,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"ID","type":"string","nullable":true,"metadata":{}},{"name":"START","type":"timestamp","nullable":true,"metadata":{}},{"name":"STOP","type":"timestamp","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ORGANIZATION","type":"string","nullable":true,"metadata":{}},{"name":"PROVIDER","type":"string","nullable":true,"metadata":{}},{"name":"PAYER","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTERCLASS","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"BASE_ENCOUNTER_COST","type":"double","nullable":true,"metadata":{}},{"name":"TOTAL_CLAIM_COST","type":"double","nullable":true,"metadata":{}},{"name":"PAYER_COVERAGE","type":"double","nullable":true,"metadata":{}},{"name":"REASONCODE","type":"long","nullable":true,"metadata":{}},{"name":"REASONDESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146876315)), logSegment=LogSegment(s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log/00000000000000000000.json; isDirectory=false; length=3809; replication=1; blocksize=33554432; modification_time=1746146891634; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c6cf02d75a5e1d847860a64372b5c6a1 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746146891634), checksumOpt=Some(VersionChecksum(Some(cbd06523-1a84-4650-8367-1bfcb4d80071),1470370,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(bef1654a-6e63-429e-80f2-5aee639b1a79,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"ID","type":"string","nullable":true,"metadata":{}},{"name":"START","type":"timestamp","nullable":true,"metadata":{}},{"name":"STOP","type":"timestamp","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ORGANIZATION","type":"string","nullable":true,"metadata":{}},{"name":"PROVIDER","type":"string","nullable":true,"metadata":{}},{"name":"PAYER","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTERCLASS","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"BASE_ENCOUNTER_COST","type":"double","nullable":true,"metadata":{}},{"name":"TOTAL_CLAIM_COST","type":"double","nullable":true,"metadata":{}},{"name":"PAYER_COVERAGE","type":"double","nullable":true,"metadata":{}},{"name":"REASONCODE","type":"long","nullable":true,"metadata":{}},{"name":"REASONDESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146876315)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-ea7425f2-9107-4d6c-bddb-e4d1ec24a4da-c000.snappy.parquet,Map(),1470370,1746146888000,false,{"numRecords":7049,"minValues":{"ID":"0004591c-7253-3a60-3435-8bd8dd25","START":"1931-04-21T11:59:06.000Z","STOP":"1931-04-21T12:19:24.000Z","PATIENT":"00732e11-5e4d-37b7-01f8-929a2553","ORGANIZATION":"00ffb204-07b4-3c72-a678-fa252e6c","PROVIDER":"00b1a913-31e7-3941-8f26-9a07f04e","PAYER":"0133f751-9229-3cfd-815f-b6d4979b","ENCOUNTERCLASS":"ambulatory","CODE":1505002,"DESCRIPTION":"Administration of vaccine to pro","BASE_ENCOUNTER_COST":75.0,"TOTAL_CLAIM_COST":75.0,"PAYER_COVERAGE":0.0,"REASONCODE":3718001,"REASONDESCRIPTION":"Abnormal findings diagnostic ima","HASH":"0004591c-7253-3a60-3435-8bd8dd25"},"maxValues":{"ID":"fffa37f5-08f3-5c8a-09e0-a379d113","START":"2024-11-04T08:21:17.000Z","STOP":"2024-11-05T00:34:10.000Z","PATIENT":"fb164202-4e38-04a0-470a-b7229db1","ORGANIZATION":"fe30f2b4-9bc8-346e-afba-4455d176","PROVIDER":"fffdc2e7-c175-3e01-a2da-185da48c","PAYER":"e03e23c9-4df1-3eb6-a62d-f70f0230","ENCOUNTERCLASS":"wellness","CODE":453131000124105,"DESCRIPTION":"Well child visit (procedure)","BASE_ENCOUNTER_COST":146.18,"TOTAL_CLAIM_COST":67764.63,"PAYER_COVERAGE":56814.68,"REASONCODE":442571000124108,"REASONDESCRIPTION":"Viral sinusitis (disorder)","HASH":"fffa37f5-08f3-5c8a-09e0-a379d113"},"nullCount":{"ID":0,"START":0,"STOP":0,"PATIENT":0,"ORGANIZATION":0,"PROVIDER":0,"PAYER":0,"ENCOUNTERCLASS":0,"CODE":0,"DESCRIPTION":0,"BASE_ENCOUNTER_COST":0,"TOTAL_CLAIM_COST":0,"PAYER_COVERAGE":0,"REASONCODE":2436,"REASONDESCRIPTION":2436,"HASH":0}},null,null,None,None,None))))))
[2025-05-02T02:21:48.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:48 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log, version=0, metadata=Metadata(bef1654a-6e63-429e-80f2-5aee639b1a79,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"ID","type":"string","nullable":true,"metadata":{}},{"name":"START","type":"timestamp","nullable":true,"metadata":{}},{"name":"STOP","type":"timestamp","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ORGANIZATION","type":"string","nullable":true,"metadata":{}},{"name":"PROVIDER","type":"string","nullable":true,"metadata":{}},{"name":"PAYER","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTERCLASS","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"BASE_ENCOUNTER_COST","type":"double","nullable":true,"metadata":{}},{"name":"TOTAL_CLAIM_COST","type":"double","nullable":true,"metadata":{}},{"name":"PAYER_COVERAGE","type":"double","nullable":true,"metadata":{}},{"name":"REASONCODE","type":"long","nullable":true,"metadata":{}},{"name":"REASONDESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146876315)), logSegment=LogSegment(s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log/00000000000000000000.json; isDirectory=false; length=3809; replication=1; blocksize=33554432; modification_time=1746146891634; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c6cf02d75a5e1d847860a64372b5c6a1 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746146891634), checksumOpt=Some(VersionChecksum(Some(cbd06523-1a84-4650-8367-1bfcb4d80071),1470370,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(bef1654a-6e63-429e-80f2-5aee639b1a79,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"ID","type":"string","nullable":true,"metadata":{}},{"name":"START","type":"timestamp","nullable":true,"metadata":{}},{"name":"STOP","type":"timestamp","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ORGANIZATION","type":"string","nullable":true,"metadata":{}},{"name":"PROVIDER","type":"string","nullable":true,"metadata":{}},{"name":"PAYER","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTERCLASS","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"BASE_ENCOUNTER_COST","type":"double","nullable":true,"metadata":{}},{"name":"TOTAL_CLAIM_COST","type":"double","nullable":true,"metadata":{}},{"name":"PAYER_COVERAGE","type":"double","nullable":true,"metadata":{}},{"name":"REASONCODE","type":"long","nullable":true,"metadata":{}},{"name":"REASONDESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146876315)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-ea7425f2-9107-4d6c-bddb-e4d1ec24a4da-c000.snappy.parquet,Map(),1470370,1746146888000,false,{"numRecords":7049,"minValues":{"ID":"0004591c-7253-3a60-3435-8bd8dd25","START":"1931-04-21T11:59:06.000Z","STOP":"1931-04-21T12:19:24.000Z","PATIENT":"00732e11-5e4d-37b7-01f8-929a2553","ORGANIZATION":"00ffb204-07b4-3c72-a678-fa252e6c","PROVIDER":"00b1a913-31e7-3941-8f26-9a07f04e","PAYER":"0133f751-9229-3cfd-815f-b6d4979b","ENCOUNTERCLASS":"ambulatory","CODE":1505002,"DESCRIPTION":"Administration of vaccine to pro","BASE_ENCOUNTER_COST":75.0,"TOTAL_CLAIM_COST":75.0,"PAYER_COVERAGE":0.0,"REASONCODE":3718001,"REASONDESCRIPTION":"Abnormal findings diagnostic ima","HASH":"0004591c-7253-3a60-3435-8bd8dd25"},"maxValues":{"ID":"fffa37f5-08f3-5c8a-09e0-a379d113","START":"2024-11-04T08:21:17.000Z","STOP":"2024-11-05T00:34:10.000Z","PATIENT":"fb164202-4e38-04a0-470a-b7229db1","ORGANIZATION":"fe30f2b4-9bc8-346e-afba-4455d176","PROVIDER":"fffdc2e7-c175-3e01-a2da-185da48c","PAYER":"e03e23c9-4df1-3eb6-a62d-f70f0230","ENCOUNTERCLASS":"wellness","CODE":453131000124105,"DESCRIPTION":"Well child visit (procedure)","BASE_ENCOUNTER_COST":146.18,"TOTAL_CLAIM_COST":67764.63,"PAYER_COVERAGE":56814.68,"REASONCODE":442571000124108,"REASONDESCRIPTION":"Viral sinusitis (disorder)","HASH":"fffa37f5-08f3-5c8a-09e0-a379d113"},"nullCount":{"ID":0,"START":0,"STOP":0,"PATIENT":0,"ORGANIZATION":0,"PROVIDER":0,"PAYER":0,"ENCOUNTERCLASS":0,"CODE":0,"DESCRIPTION":0,"BASE_ENCOUNTER_COST":0,"TOTAL_CLAIM_COST":0,"PAYER_COVERAGE":0,"REASONCODE":2436,"REASONDESCRIPTION":2436,"HASH":0}},null,null,None,None,None))))))
[2025-05-02T02:21:49.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:49 INFO DelegatingLogStore: LogStore LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore) is used for scheme s3a
[2025-05-02T02:21:49.692+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:49 INFO DeltaLog: Loading version 0.
[2025-05-02T02:21:49.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:49 INFO Snapshot: [tableId=9f886ad5-3bed-4e60-bf98-7dc08a5e7f56] Created snapshot Snapshot(path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log, version=0, metadata=Metadata(8e8819e9-b959-47a8-8de5-fef16154291a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"START","type":"date","nullable":true,"metadata":{}},{"name":"STOP","type":"date","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTER","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"SYSTEM","type":"string","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"TYPE","type":"string","nullable":true,"metadata":{}},{"name":"CATEGORY","type":"string","nullable":true,"metadata":{}},{"name":"REACTION1","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION1","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY1","type":"string","nullable":true,"metadata":{}},{"name":"REACTION2","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION2","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY2","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146472462)), logSegment=LogSegment(s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log/00000000000000000000.json; isDirectory=false; length=3418; replication=1; blocksize=33554432; modification_time=1746146488390; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=980164d7b81fb9d95a2f5e1388e53177 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746146488390), checksumOpt=Some(VersionChecksum(Some(8058b232-cfff-4cc3-83b4-b9894b699d3a),11706,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(8e8819e9-b959-47a8-8de5-fef16154291a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"START","type":"date","nullable":true,"metadata":{}},{"name":"STOP","type":"date","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTER","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"SYSTEM","type":"string","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"TYPE","type":"string","nullable":true,"metadata":{}},{"name":"CATEGORY","type":"string","nullable":true,"metadata":{}},{"name":"REACTION1","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION1","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY1","type":"string","nullable":true,"metadata":{}},{"name":"REACTION2","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION2","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY2","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146472462)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet,Map(),11706,1746146482000,false,{"numRecords":92,"minValues":{"START":"1956-02-19","PATIENT":"14dc5e57-1b84-3305-c042-86c9fc7e","ENCOUNTER":"1b4bd750-5f83-2a44-1470-f88e7460","CODE":1191,"SYSTEM":"RxNorm","DESCRIPTION":"Allergy to substance (finding)","TYPE":"allergy","CATEGORY":"environment","REACTION1":21522001,"DESCRIPTION1":"Abdominal pain (finding)","SEVERITY1":"MILD","REACTION2":21522001,"DESCRIPTION2":"Abdominal pain (finding)","SEVERITY2":"MILD","HASH":"1956-02-19|be3fe2c4-52da-02bb-e6"},"maxValues":{"START":"2021-05-11","PATIENT":"de480ca4-19a6-f2e0-7922-1c51e7c8","ENCOUNTER":"fdb6f8fe-e6b9-c990-3b65-154b5bf7","CODE":442571000124108,"SYSTEM":"SNOMED-CT","DESCRIPTION":"cefdinir","TYPE":"allergy","CATEGORY":"medication","REACTION1":878820003,"DESCRIPTION1":"Wheal (finding)","SEVERITY1":"SEVERE","REACTION2":402387002,"DESCRIPTION2":"Wheezing (finding)","SEVERITY2":"MODERATE","HASH":"2021-05-11|de480ca4-19a6-f2e0-79"},"nullCount":{"START":0,"STOP":92,"PATIENT":0,"ENCOUNTER":0,"CODE":0,"SYSTEM":0,"DESCRIPTION":0,"TYPE":0,"CATEGORY":0,"REACTION1":48,"DESCRIPTION1":48,"SEVERITY1":48,"REACTION2":62,"DESCRIPTION2":62,"SEVERITY2":62,"HASH":0}},null,null,None,None,None))))))
[2025-05-02T02:21:49.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:49 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log, version=0, metadata=Metadata(8e8819e9-b959-47a8-8de5-fef16154291a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"START","type":"date","nullable":true,"metadata":{}},{"name":"STOP","type":"date","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTER","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"SYSTEM","type":"string","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"TYPE","type":"string","nullable":true,"metadata":{}},{"name":"CATEGORY","type":"string","nullable":true,"metadata":{}},{"name":"REACTION1","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION1","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY1","type":"string","nullable":true,"metadata":{}},{"name":"REACTION2","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION2","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY2","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146472462)), logSegment=LogSegment(s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log/00000000000000000000.json; isDirectory=false; length=3418; replication=1; blocksize=33554432; modification_time=1746146488390; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=980164d7b81fb9d95a2f5e1388e53177 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746146488390), checksumOpt=Some(VersionChecksum(Some(8058b232-cfff-4cc3-83b4-b9894b699d3a),11706,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(8e8819e9-b959-47a8-8de5-fef16154291a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"START","type":"date","nullable":true,"metadata":{}},{"name":"STOP","type":"date","nullable":true,"metadata":{}},{"name":"PATIENT","type":"string","nullable":true,"metadata":{}},{"name":"ENCOUNTER","type":"string","nullable":true,"metadata":{}},{"name":"CODE","type":"long","nullable":true,"metadata":{}},{"name":"SYSTEM","type":"string","nullable":true,"metadata":{}},{"name":"DESCRIPTION","type":"string","nullable":true,"metadata":{}},{"name":"TYPE","type":"string","nullable":true,"metadata":{}},{"name":"CATEGORY","type":"string","nullable":true,"metadata":{}},{"name":"REACTION1","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION1","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY1","type":"string","nullable":true,"metadata":{}},{"name":"REACTION2","type":"long","nullable":true,"metadata":{}},{"name":"DESCRIPTION2","type":"string","nullable":true,"metadata":{}},{"name":"SEVERITY2","type":"string","nullable":true,"metadata":{}},{"name":"HASH","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746146472462)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet,Map(),11706,1746146482000,false,{"numRecords":92,"minValues":{"START":"1956-02-19","PATIENT":"14dc5e57-1b84-3305-c042-86c9fc7e","ENCOUNTER":"1b4bd750-5f83-2a44-1470-f88e7460","CODE":1191,"SYSTEM":"RxNorm","DESCRIPTION":"Allergy to substance (finding)","TYPE":"allergy","CATEGORY":"environment","REACTION1":21522001,"DESCRIPTION1":"Abdominal pain (finding)","SEVERITY1":"MILD","REACTION2":21522001,"DESCRIPTION2":"Abdominal pain (finding)","SEVERITY2":"MILD","HASH":"1956-02-19|be3fe2c4-52da-02bb-e6"},"maxValues":{"START":"2021-05-11","PATIENT":"de480ca4-19a6-f2e0-7922-1c51e7c8","ENCOUNTER":"fdb6f8fe-e6b9-c990-3b65-154b5bf7","CODE":442571000124108,"SYSTEM":"SNOMED-CT","DESCRIPTION":"cefdinir","TYPE":"allergy","CATEGORY":"medication","REACTION1":878820003,"DESCRIPTION1":"Wheal (finding)","SEVERITY1":"SEVERE","REACTION2":402387002,"DESCRIPTION2":"Wheezing (finding)","SEVERITY2":"MODERATE","HASH":"2021-05-11|de480ca4-19a6-f2e0-79"},"nullCount":{"START":0,"STOP":92,"PATIENT":0,"ENCOUNTER":0,"CODE":0,"SYSTEM":0,"DESCRIPTION":0,"TYPE":0,"CATEGORY":0,"REACTION1":48,"DESCRIPTION1":48,"SEVERITY1":48,"REACTION2":62,"DESCRIPTION2":62,"SEVERITY2":62,"HASH":0}},null,null,None,None,None))))))
[2025-05-02T02:21:50.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:50 INFO DelegatingLogStore: LogStore LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore) is used for scheme s3a
[2025-05-02T02:21:50.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:50 INFO DeltaLog: Loading version 0.
[2025-05-02T02:21:50.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:50 INFO Snapshot: [tableId=1f017660-7076-46a3-9cd5-689b6322ae54] Created snapshot Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log, version=0, metadata=Metadata(9e0b0383-315d-40fb-b9a4-184f95c6af0b,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Code","type":"long","nullable":true,"metadata":{}},{"name":"Allergy_System","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Description","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151872914)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log/00000000000000000000.json; isDirectory=false; length=1706; replication=1; blocksize=33554432; modification_time=1746151904445; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=baa35173596589af7dda84d515d43ff3 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746151904445), checksumOpt=Some(VersionChecksum(Some(b81360c4-0932-4a36-bbe1-cafd40100d58),3225,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(9e0b0383-315d-40fb-b9a4-184f95c6af0b,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Code","type":"long","nullable":true,"metadata":{}},{"name":"Allergy_System","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Description","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151872914)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-21df6e80-7b21-498b-992b-71fe9091b4c4-c000.snappy.parquet,Map(),3225,1746151902000,false,{"numRecords":18,"minValues":{"Allergy_Key":"00000000000000000000000000000000","Allergy_Code":0,"Allergy_System":"RxNorm","Allergy_Description":"Allergy to substance (finding)"},"maxValues":{"Allergy_Key":"f987f55b75c0dd020567099859c75a82","Allergy_Code":442571000124108,"Allergy_System":"Unknown","Allergy_Description":"cefdinir"},"nullCount":{"Allergy_Key":0,"Allergy_Code":0,"Allergy_System":0,"Allergy_Description":0}},null,null,None,None,None))))))
[2025-05-02T02:21:50.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:50 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log, version=0, metadata=Metadata(9e0b0383-315d-40fb-b9a4-184f95c6af0b,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Code","type":"long","nullable":true,"metadata":{}},{"name":"Allergy_System","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Description","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151872914)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log/00000000000000000000.json; isDirectory=false; length=1706; replication=1; blocksize=33554432; modification_time=1746151904445; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=baa35173596589af7dda84d515d43ff3 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746151904445), checksumOpt=Some(VersionChecksum(Some(b81360c4-0932-4a36-bbe1-cafd40100d58),3225,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(9e0b0383-315d-40fb-b9a4-184f95c6af0b,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Code","type":"long","nullable":true,"metadata":{}},{"name":"Allergy_System","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Description","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151872914)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-21df6e80-7b21-498b-992b-71fe9091b4c4-c000.snappy.parquet,Map(),3225,1746151902000,false,{"numRecords":18,"minValues":{"Allergy_Key":"00000000000000000000000000000000","Allergy_Code":0,"Allergy_System":"RxNorm","Allergy_Description":"Allergy to substance (finding)"},"maxValues":{"Allergy_Key":"f987f55b75c0dd020567099859c75a82","Allergy_Code":442571000124108,"Allergy_System":"Unknown","Allergy_Description":"cefdinir"},"nullCount":{"Allergy_Key":0,"Allergy_Code":0,"Allergy_System":0,"Allergy_Description":0}},null,null,None,None,None))))))
[2025-05-02T02:21:52.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO MergeIntoCommand: DELTA: MERGE operation - materialize source
[2025-05-02T02:21:52.210+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:21:52.212+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO MergeIntoCommand: DELTA: MERGE operation - writing new files for only inserts
[2025-05-02T02:21:52.225+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO Snapshot: DELTA: Compute snapshot for version: 0
[2025-05-02T02:21:52.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 204.7 KiB, free 434.2 MiB)
[2025-05-02T02:21:52.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 434.2 MiB)
[2025-05-02T02:21:52.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ***-scheduler:33063 (size: 35.8 KiB, free: 434.4 MiB)
[2025-05-02T02:21:52.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:52 INFO SparkContext: Created broadcast 0 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:21:53.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:53 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1706)
[2025-05-02T02:21:55.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:55 INFO DataSourceStrategy: Pruning directories with:
[2025-05-02T02:21:55.358+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:55 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:21:55.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:21:55.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-05-02T02:21:56.333+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO CodeGenerator: Code generated in 549.923946 ms
[2025-05-02T02:21:56.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 205.0 KiB, free 434.0 MiB)
[2025-05-02T02:21:56.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 433.9 MiB)
[2025-05-02T02:21:56.358+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ***-scheduler:33063 (size: 35.9 KiB, free: 434.3 MiB)
[2025-05-02T02:21:56.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO SparkContext: Created broadcast 1 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:21:56.398+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4196010 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:21:56.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Registering RDD 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 0
[2025-05-02T02:21:56.744+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Got map stage job 0 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:21:56.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Final stage: ShuffleMapStage 0 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:21:56.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:21:56.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:21:56.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:21:56.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 105.9 KiB, free 433.8 MiB)
[2025-05-02T02:21:56.891+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 433.8 MiB)
[2025-05-02T02:21:56.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ***-scheduler:33063 (size: 32.6 KiB, free: 434.3 MiB)
[2025-05-02T02:21:56.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:21:56.921+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:21:56.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-02T02:21:56.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10885 bytes)
[2025-05-02T02:21:57.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-05-02T02:21:57.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO CodeGenerator: Code generated in 225.031671 ms
[2025-05-02T02:21:57.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO CodeGenerator: Code generated in 19.935579 ms
[2025-05-02T02:21:57.506+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/_delta_log/00000000000000000000.json, range: 0-1706, partition values: [0]
[2025-05-02T02:21:57.617+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO CodeGenerator: Code generated in 84.042168 ms
[2025-05-02T02:21:57.844+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO CodeGenerator: Code generated in 8.602705 ms
[2025-05-02T02:21:57.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO CodeGenerator: Code generated in 11.05328 ms
[2025-05-02T02:21:57.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1884 bytes result sent to driver
[2025-05-02T02:21:57.940+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 957 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:21:57.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-02T02:21:57.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO DAGScheduler: ShuffleMapStage 0 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.170 s
[2025-05-02T02:21:57.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:21:57.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO DAGScheduler: running: Set()
[2025-05-02T02:21:57.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:21:57.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:57 INFO DAGScheduler: failed: Set()
[2025-05-02T02:21:58.070+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:58 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ***-scheduler:33063 in memory (size: 32.6 KiB, free: 434.3 MiB)
[2025-05-02T02:21:58.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:58 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 25072 bytes
[2025-05-02T02:21:58.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:58 INFO CodeGenerator: Code generated in 435.97732 ms
[2025-05-02T02:21:49.390+0000] {spark_submit.py:649} INFO - 25/05/02 02:21:49 INFO CodeGenerator: Code generated in 118.375972 ms
[2025-05-02T02:22:00.033+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO CodeGenerator: Code generated in 123.320013 ms
[2025-05-02T02:22:00.055+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Registering RDD 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1
[2025-05-02T02:22:00.056+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Got map stage job 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:00.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Final stage: ShuffleMapStage 2 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:00.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-02T02:22:00.061+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:00.062+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:00.178+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 605.5 KiB, free 433.3 MiB)
[2025-05-02T02:22:00.183+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 138.8 KiB, free 433.2 MiB)
[2025-05-02T02:22:00.185+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ***-scheduler:33063 (size: 138.8 KiB, free: 434.2 MiB)
[2025-05-02T02:22:00.186+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:00.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:00.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 50 tasks resource profile 0
[2025-05-02T02:22:00.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO TaskSetManager: Starting task 38.0 in stage 2.0 (TID 1) (***-scheduler, executor driver, partition 38, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:00.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO Executor: Running task 38.0 in stage 2.0 (TID 1)
[2025-05-02T02:22:00.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:00.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
[2025-05-02T02:22:00.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO CodeGenerator: Code generated in 81.960348 ms
[2025-05-02T02:22:00.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO CodeGenerator: Code generated in 14.384893 ms
[2025-05-02T02:22:00.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO CodeGenerator: Code generated in 8.067408 ms
[2025-05-02T02:22:00.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:00 INFO CodeGenerator: Code generated in 115.846763 ms
[2025-05-02T02:22:01.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 25072 bytes
[2025-05-02T02:22:01.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 483.114686 ms
[2025-05-02T02:22:01.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO MemoryStore: Block rdd_10_38 stored as values in memory (estimated size 562.0 B, free 433.2 MiB)
[2025-05-02T02:22:01.269+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO BlockManagerInfo: Added rdd_10_38 in memory on ***-scheduler:33063 (size: 562.0 B, free: 434.2 MiB)
[2025-05-02T02:22:01.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 88.461896 ms
[2025-05-02T02:22:01.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 8.397678 ms
[2025-05-02T02:22:01.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 14.14335 ms
[2025-05-02T02:22:01.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 5.544465 ms
[2025-05-02T02:22:01.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 21.766206 ms
[2025-05-02T02:22:01.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 17.236195 ms
[2025-05-02T02:22:01.562+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 7.7784 ms
[2025-05-02T02:22:01.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO CodeGenerator: Code generated in 7.946054 ms
[2025-05-02T02:22:01.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO Executor: Finished task 38.0 in stage 2.0 (TID 1). 5308 bytes result sent to driver
[2025-05-02T02:22:01.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO TaskSetManager: Starting task 42.0 in stage 2.0 (TID 2) (***-scheduler, executor driver, partition 42, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:01.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO Executor: Running task 42.0 in stage 2.0 (TID 2)
[2025-05-02T02:22:01.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO TaskSetManager: Finished task 38.0 in stage 2.0 (TID 1) in 1390 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:01.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:01.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:01.786+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO MemoryStore: Block rdd_10_42 stored as values in memory (estimated size 495.0 B, free 433.2 MiB)
[2025-05-02T02:22:01.788+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO BlockManagerInfo: Added rdd_10_42 in memory on ***-scheduler:33063 (size: 495.0 B, free: 434.2 MiB)
[2025-05-02T02:22:01.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO Executor: Finished task 42.0 in stage 2.0 (TID 2). 5308 bytes result sent to driver
[2025-05-02T02:22:01.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:01.833+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO TaskSetManager: Finished task 42.0 in stage 2.0 (TID 2) in 252 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:01.835+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
[2025-05-02T02:22:01.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:01.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:01.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:01.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO BlockManagerInfo: Added rdd_10_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:01.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 5308 bytes result sent to driver
[2025-05-02T02:22:01.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:01.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 136 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:01.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO Executor: Running task 1.0 in stage 2.0 (TID 4)
[2025-05-02T02:22:01.995+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:01.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:02.066+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 1.0 in stage 2.0 (TID 4). 5351 bytes result sent to driver
[2025-05-02T02:22:02.108+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 5) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.109+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 2.0 in stage 2.0 (TID 5)
[2025-05-02T02:22:02.110+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 144 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:02.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.143+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:02.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.191+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_2 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 2.0 in stage 2.0 (TID 5). 5351 bytes result sent to driver
[2025-05-02T02:22:02.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 6) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 3.0 in stage 2.0 (TID 6)
[2025-05-02T02:22:02.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 5) in 122 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:02.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:02.304+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.343+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 3.0 in stage 2.0 (TID 6). 5308 bytes result sent to driver
[2025-05-02T02:22:02.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 7) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 6) in 117 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:02.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 4.0 in stage 2.0 (TID 7)
[2025-05-02T02:22:02.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.369+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:02.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_4 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_4 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 4.0 in stage 2.0 (TID 7). 5308 bytes result sent to driver
[2025-05-02T02:22:02.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 8) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.461+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 7) in 116 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:02.462+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 5.0 in stage 2.0 (TID 8)
[2025-05-02T02:22:02.491+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:02.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_5 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.539+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 5.0 in stage 2.0 (TID 8). 5394 bytes result sent to driver
[2025-05-02T02:22:02.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 9) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 8) in 124 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:02.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 6.0 in stage 2.0 (TID 9)
[2025-05-02T02:22:02.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:02.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_6 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.730+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 6.0 in stage 2.0 (TID 9). 5351 bytes result sent to driver
[2025-05-02T02:22:02.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 10) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 9) in 151 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:02.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 7.0 in stage 2.0 (TID 10)
[2025-05-02T02:22:02.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:02.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_7 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 7.0 in stage 2.0 (TID 10). 5308 bytes result sent to driver
[2025-05-02T02:22:02.839+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 11) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 8.0 in stage 2.0 (TID 11)
[2025-05-02T02:22:02.841+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 10) in 108 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:02.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:02.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO MemoryStore: Block rdd_10_8 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:02.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO BlockManagerInfo: Added rdd_10_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:02.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Finished task 8.0 in stage 2.0 (TID 11). 5308 bytes result sent to driver
[2025-05-02T02:22:02.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 12) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:02.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO Executor: Running task 9.0 in stage 2.0 (TID 12)
[2025-05-02T02:22:02.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 11) in 116 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:02.973+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:02.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:03.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_9 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.054+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 9.0 in stage 2.0 (TID 12). 5308 bytes result sent to driver
[2025-05-02T02:22:03.056+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 13) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 10.0 in stage 2.0 (TID 13)
[2025-05-02T02:22:03.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 12) in 104 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:03.075+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:03.122+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_10 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.123+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 10.0 in stage 2.0 (TID 13). 5308 bytes result sent to driver
[2025-05-02T02:22:03.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 14) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 13) in 117 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:03.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 11.0 in stage 2.0 (TID 14)
[2025-05-02T02:22:03.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:03.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_11 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_11 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 11.0 in stage 2.0 (TID 14). 5308 bytes result sent to driver
[2025-05-02T02:22:03.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 12.0 in stage 2.0 (TID 15) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 14) in 116 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:03.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 12.0 in stage 2.0 (TID 15)
[2025-05-02T02:22:03.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:03.355+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_12 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.356+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.389+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 12.0 in stage 2.0 (TID 15). 5308 bytes result sent to driver
[2025-05-02T02:22:03.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 13.0 in stage 2.0 (TID 16) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 13.0 in stage 2.0 (TID 16)
[2025-05-02T02:22:03.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 12.0 in stage 2.0 (TID 15) in 107 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:03.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:03.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_13 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 13.0 in stage 2.0 (TID 16). 5308 bytes result sent to driver
[2025-05-02T02:22:03.514+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 14.0 in stage 2.0 (TID 17) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 13.0 in stage 2.0 (TID 16) in 125 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:03.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 14.0 in stage 2.0 (TID 17)
[2025-05-02T02:22:03.540+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:03.598+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_14 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.599+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.653+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 14.0 in stage 2.0 (TID 17). 5351 bytes result sent to driver
[2025-05-02T02:22:03.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 15.0 in stage 2.0 (TID 18) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.657+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 15.0 in stage 2.0 (TID 18)
[2025-05-02T02:22:03.658+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 14.0 in stage 2.0 (TID 17) in 142 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:03.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:03.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_15 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.774+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 15.0 in stage 2.0 (TID 18). 5351 bytes result sent to driver
[2025-05-02T02:22:03.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 16.0 in stage 2.0 (TID 19) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.777+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 16.0 in stage 2.0 (TID 19)
[2025-05-02T02:22:03.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 15.0 in stage 2.0 (TID 18) in 122 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:03.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:03.876+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO MemoryStore: Block rdd_10_16 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:03.877+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO BlockManagerInfo: Added rdd_10_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:03.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Finished task 16.0 in stage 2.0 (TID 19). 5308 bytes result sent to driver
[2025-05-02T02:22:03.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Starting task 17.0 in stage 2.0 (TID 20) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:03.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO TaskSetManager: Finished task 16.0 in stage 2.0 (TID 19) in 156 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:03.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO Executor: Running task 17.0 in stage 2.0 (TID 20)
[2025-05-02T02:22:03.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:03.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:04.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_17 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.063+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 17.0 in stage 2.0 (TID 20). 5308 bytes result sent to driver
[2025-05-02T02:22:04.065+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 18.0 in stage 2.0 (TID 21) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 18.0 in stage 2.0 (TID 21)
[2025-05-02T02:22:04.070+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 17.0 in stage 2.0 (TID 20) in 136 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:04.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.088+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:04.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_18 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 18.0 in stage 2.0 (TID 21). 5308 bytes result sent to driver
[2025-05-02T02:22:04.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 19.0 in stage 2.0 (TID 22) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 19.0 in stage 2.0 (TID 22)
[2025-05-02T02:22:04.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 18.0 in stage 2.0 (TID 21) in 131 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:04.217+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:04.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_19 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.280+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 19.0 in stage 2.0 (TID 22). 5308 bytes result sent to driver
[2025-05-02T02:22:04.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 20.0 in stage 2.0 (TID 23) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.317+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 20.0 in stage 2.0 (TID 23)
[2025-05-02T02:22:04.318+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 19.0 in stage 2.0 (TID 22) in 124 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:04.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:04.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_20 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 20.0 in stage 2.0 (TID 23). 5308 bytes result sent to driver
[2025-05-02T02:22:04.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 21.0 in stage 2.0 (TID 24) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 21.0 in stage 2.0 (TID 24)
[2025-05-02T02:22:04.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 20.0 in stage 2.0 (TID 23) in 151 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:04.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:04.531+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_21 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 21.0 in stage 2.0 (TID 24). 5308 bytes result sent to driver
[2025-05-02T02:22:04.565+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 22.0 in stage 2.0 (TID 25) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 22.0 in stage 2.0 (TID 25)
[2025-05-02T02:22:04.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 21.0 in stage 2.0 (TID 24) in 102 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:04.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:04.626+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_22 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 22.0 in stage 2.0 (TID 25). 5308 bytes result sent to driver
[2025-05-02T02:22:04.662+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 23.0 in stage 2.0 (TID 26) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.664+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 22.0 in stage 2.0 (TID 25) in 99 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:04.665+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 23.0 in stage 2.0 (TID 26)
[2025-05-02T02:22:04.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:04.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_23 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 23.0 in stage 2.0 (TID 26). 5308 bytes result sent to driver
[2025-05-02T02:22:04.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 24.0 in stage 2.0 (TID 27) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 23.0 in stage 2.0 (TID 26) in 98 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:04.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 24.0 in stage 2.0 (TID 27)
[2025-05-02T02:22:04.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:04.817+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_24 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.848+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 24.0 in stage 2.0 (TID 27). 5308 bytes result sent to driver
[2025-05-02T02:22:04.850+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 25.0 in stage 2.0 (TID 28) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 24.0 in stage 2.0 (TID 27) in 93 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:04.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 25.0 in stage 2.0 (TID 28)
[2025-05-02T02:22:04.866+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:04.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO MemoryStore: Block rdd_10_25 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:04.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO BlockManagerInfo: Added rdd_10_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:04.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Finished task 25.0 in stage 2.0 (TID 28). 5394 bytes result sent to driver
[2025-05-02T02:22:04.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Starting task 26.0 in stage 2.0 (TID 29) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:04.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO Executor: Running task 26.0 in stage 2.0 (TID 29)
[2025-05-02T02:22:04.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO TaskSetManager: Finished task 25.0 in stage 2.0 (TID 28) in 108 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:04.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:04.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:05.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_26 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 26.0 in stage 2.0 (TID 29). 5308 bytes result sent to driver
[2025-05-02T02:22:05.092+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 27.0 in stage 2.0 (TID 30) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 26.0 in stage 2.0 (TID 29) in 137 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:05.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 27.0 in stage 2.0 (TID 30)
[2025-05-02T02:22:05.114+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:05.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_27 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.160+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 27.0 in stage 2.0 (TID 30). 5308 bytes result sent to driver
[2025-05-02T02:22:05.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 28.0 in stage 2.0 (TID 31) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 27.0 in stage 2.0 (TID 30) in 107 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:05.199+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 28.0 in stage 2.0 (TID 31)
[2025-05-02T02:22:05.214+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.215+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:05.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_28 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 28.0 in stage 2.0 (TID 31). 5308 bytes result sent to driver
[2025-05-02T02:22:05.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 29.0 in stage 2.0 (TID 32) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 29.0 in stage 2.0 (TID 32)
[2025-05-02T02:22:05.290+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 28.0 in stage 2.0 (TID 31) in 92 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:05.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-05-02T02:22:05.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_29 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 29.0 in stage 2.0 (TID 32). 5308 bytes result sent to driver
[2025-05-02T02:22:05.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 30.0 in stage 2.0 (TID 33) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 30.0 in stage 2.0 (TID 33)
[2025-05-02T02:22:05.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 29.0 in stage 2.0 (TID 32) in 138 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:05.448+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:05.503+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_30 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.505+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 30.0 in stage 2.0 (TID 33). 5308 bytes result sent to driver
[2025-05-02T02:22:05.544+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 31.0 in stage 2.0 (TID 34) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.545+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 31.0 in stage 2.0 (TID 34)
[2025-05-02T02:22:05.547+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 30.0 in stage 2.0 (TID 33) in 122 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:05.565+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:05.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_31 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.653+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 31.0 in stage 2.0 (TID 34). 5308 bytes result sent to driver
[2025-05-02T02:22:05.655+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 32.0 in stage 2.0 (TID 35) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 31.0 in stage 2.0 (TID 34) in 112 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:05.657+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 32.0 in stage 2.0 (TID 35)
[2025-05-02T02:22:05.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:05.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_32 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.770+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 32.0 in stage 2.0 (TID 35). 5308 bytes result sent to driver
[2025-05-02T02:22:05.772+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 33.0 in stage 2.0 (TID 36) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.774+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 32.0 in stage 2.0 (TID 35) in 119 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:05.775+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 33.0 in stage 2.0 (TID 36)
[2025-05-02T02:22:05.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:05.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_33 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 33.0 in stage 2.0 (TID 36). 5308 bytes result sent to driver
[2025-05-02T02:22:05.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 34.0 in stage 2.0 (TID 37) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 34.0 in stage 2.0 (TID 37)
[2025-05-02T02:22:05.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 33.0 in stage 2.0 (TID 36) in 98 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:05.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:05.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO MemoryStore: Block rdd_10_34 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:05.927+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO BlockManagerInfo: Added rdd_10_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:05.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Finished task 34.0 in stage 2.0 (TID 37). 5308 bytes result sent to driver
[2025-05-02T02:22:05.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Starting task 35.0 in stage 2.0 (TID 38) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:05.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO Executor: Running task 35.0 in stage 2.0 (TID 38)
[2025-05-02T02:22:05.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO TaskSetManager: Finished task 34.0 in stage 2.0 (TID 37) in 89 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:05.972+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:05.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_35 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.044+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 35.0 in stage 2.0 (TID 38). 5308 bytes result sent to driver
[2025-05-02T02:22:06.045+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 36.0 in stage 2.0 (TID 39) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.047+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 35.0 in stage 2.0 (TID 38) in 91 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:06.048+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 36.0 in stage 2.0 (TID 39)
[2025-05-02T02:22:06.063+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.064+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.105+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_36 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.106+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 36.0 in stage 2.0 (TID 39). 5351 bytes result sent to driver
[2025-05-02T02:22:06.140+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 37.0 in stage 2.0 (TID 40) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 37.0 in stage 2.0 (TID 40)
[2025-05-02T02:22:06.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 36.0 in stage 2.0 (TID 39) in 97 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:06.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_37 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 37.0 in stage 2.0 (TID 40). 5351 bytes result sent to driver
[2025-05-02T02:22:06.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 39.0 in stage 2.0 (TID 41) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 37.0 in stage 2.0 (TID 40) in 90 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:06.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 39.0 in stage 2.0 (TID 41)
[2025-05-02T02:22:06.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.278+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_39 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.304+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 39.0 in stage 2.0 (TID 41). 5308 bytes result sent to driver
[2025-05-02T02:22:06.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 40.0 in stage 2.0 (TID 42) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 40.0 in stage 2.0 (TID 42)
[2025-05-02T02:22:06.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 39.0 in stage 2.0 (TID 41) in 78 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:06.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_40 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.369+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 40.0 in stage 2.0 (TID 42). 5308 bytes result sent to driver
[2025-05-02T02:22:06.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 41.0 in stage 2.0 (TID 43) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.396+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 40.0 in stage 2.0 (TID 42) in 92 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:06.397+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 41.0 in stage 2.0 (TID 43)
[2025-05-02T02:22:06.411+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.412+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_41 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.446+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 41.0 in stage 2.0 (TID 43). 5308 bytes result sent to driver
[2025-05-02T02:22:06.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 43.0 in stage 2.0 (TID 44) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 41.0 in stage 2.0 (TID 43) in 81 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:06.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 43.0 in stage 2.0 (TID 44)
[2025-05-02T02:22:06.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.496+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_43 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.529+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 43.0 in stage 2.0 (TID 44). 5308 bytes result sent to driver
[2025-05-02T02:22:06.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 44.0 in stage 2.0 (TID 45) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 43.0 in stage 2.0 (TID 44) in 85 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:06.562+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 44.0 in stage 2.0 (TID 45)
[2025-05-02T02:22:06.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_44 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 44.0 in stage 2.0 (TID 45). 5308 bytes result sent to driver
[2025-05-02T02:22:06.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 45.0 in stage 2.0 (TID 46) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 44.0 in stage 2.0 (TID 45) in 89 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:06.649+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 45.0 in stage 2.0 (TID 46)
[2025-05-02T02:22:06.661+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.662+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.692+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_45 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.693+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.717+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 45.0 in stage 2.0 (TID 46). 5308 bytes result sent to driver
[2025-05-02T02:22:06.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 46.0 in stage 2.0 (TID 47) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 45.0 in stage 2.0 (TID 46) in 71 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:06.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 46.0 in stage 2.0 (TID 47)
[2025-05-02T02:22:06.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_46 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.795+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 46.0 in stage 2.0 (TID 47). 5308 bytes result sent to driver
[2025-05-02T02:22:06.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 47.0 in stage 2.0 (TID 48) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 47.0 in stage 2.0 (TID 48)
[2025-05-02T02:22:06.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 46.0 in stage 2.0 (TID 47) in 80 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:06.814+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.815+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.845+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_47 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 47.0 in stage 2.0 (TID 48). 5308 bytes result sent to driver
[2025-05-02T02:22:06.869+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 48.0 in stage 2.0 (TID 49) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 47.0 in stage 2.0 (TID 48) in 73 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:06.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 48.0 in stage 2.0 (TID 49)
[2025-05-02T02:22:06.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.884+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_48 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:06.941+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Finished task 48.0 in stage 2.0 (TID 49). 5308 bytes result sent to driver
[2025-05-02T02:22:06.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Starting task 49.0 in stage 2.0 (TID 50) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:06.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO Executor: Running task 49.0 in stage 2.0 (TID 50)
[2025-05-02T02:22:06.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO TaskSetManager: Finished task 48.0 in stage 2.0 (TID 49) in 75 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:06.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:06.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:06.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO MemoryStore: Block rdd_10_49 stored as values in memory (estimated size 46.0 B, free 433.2 MiB)
[2025-05-02T02:22:06.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:06 INFO BlockManagerInfo: Added rdd_10_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.2 MiB)
[2025-05-02T02:22:07.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO Executor: Finished task 49.0 in stage 2.0 (TID 50). 5308 bytes result sent to driver
[2025-05-02T02:22:07.017+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSetManager: Finished task 49.0 in stage 2.0 (TID 50) in 74 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:07.018+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-02T02:22:07.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: ShuffleMapStage 2 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 6.931 s
[2025-05-02T02:22:07.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:07.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:07.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:07.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:07.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:07.073+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Got job 2 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:07.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:07.075+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-02T02:22:07.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:07.077+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:07.088+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 537.1 KiB, free 432.7 MiB)
[2025-05-02T02:22:07.091+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 125.4 KiB, free 432.6 MiB)
[2025-05-02T02:22:07.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ***-scheduler:33063 (size: 125.4 KiB, free: 434.1 MiB)
[2025-05-02T02:22:07.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:07.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:07.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-02T02:22:07.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 51) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:07.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 51)
[2025-05-02T02:22:07.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO ShuffleBlockFetcherIterator: Getting 50 (4.6 KiB) non-empty blocks including 50 (4.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:07.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:07.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO CodeGenerator: Code generated in 9.045594 ms
[2025-05-02T02:22:07.184+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO CodeGenerator: Code generated in 30.072792 ms
[2025-05-02T02:22:07.213+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO Executor: Finished task 0.0 in stage 5.0 (TID 51). 6987 bytes result sent to driver
[2025-05-02T02:22:07.214+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 51) in 117 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:07.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-02T02:22:07.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: ResultStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.136 s
[2025-05-02T02:22:07.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:07.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-02T02:22:07.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Job 2 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.152462 s
[2025-05-02T02:22:07.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO CodeGenerator: Code generated in 48.368099 ms
[2025-05-02T02:22:07.291+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO Snapshot: DELTA: Done
[2025-05-02T02:22:07.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ***-scheduler:33063 in memory (size: 138.8 KiB, free: 434.2 MiB)
[2025-05-02T02:22:07.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO CodeGenerator: Code generated in 132.685341 ms
[2025-05-02T02:22:07.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:07.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Got job 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:07.830+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Final stage: ResultStage 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:07.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-05-02T02:22:07.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:07.833+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:07.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 687.2 KiB, free 432.6 MiB)
[2025-05-02T02:22:07.850+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 155.3 KiB, free 432.5 MiB)
[2025-05-02T02:22:07.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ***-scheduler:33063 (size: 155.3 KiB, free: 434.1 MiB)
[2025-05-02T02:22:07.853+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:07.854+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:07.855+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSchedulerImpl: Adding task set 7.0 with 50 tasks resource profile 0
[2025-05-02T02:22:07.857+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 52) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:07.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO Executor: Running task 0.0 in stage 7.0 (TID 52)
[2025-05-02T02:22:07.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:07 INFO BlockManager: Found block rdd_10_0 locally
[2025-05-02T02:22:08.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO CodeGenerator: Code generated in 173.423611 ms
[2025-05-02T02:22:08.066+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 0.0 in stage 7.0 (TID 52). 4181 bytes result sent to driver
[2025-05-02T02:22:08.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 53) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 1.0 in stage 7.0 (TID 53)
[2025-05-02T02:22:08.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 52) in 212 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:08.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_1 locally
[2025-05-02T02:22:08.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 1.0 in stage 7.0 (TID 53). 4181 bytes result sent to driver
[2025-05-02T02:22:08.091+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 54) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.092+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 53) in 25 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:08.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 2.0 in stage 7.0 (TID 54)
[2025-05-02T02:22:08.104+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_2 locally
[2025-05-02T02:22:08.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 2.0 in stage 7.0 (TID 54). 4181 bytes result sent to driver
[2025-05-02T02:22:08.109+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 55) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.110+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 54) in 19 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:08.111+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 3.0 in stage 7.0 (TID 55)
[2025-05-02T02:22:08.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_3 locally
[2025-05-02T02:22:08.130+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 3.0 in stage 7.0 (TID 55). 4181 bytes result sent to driver
[2025-05-02T02:22:08.131+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 56) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.132+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 4.0 in stage 7.0 (TID 56)
[2025-05-02T02:22:08.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 55) in 24 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:08.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_4 locally
[2025-05-02T02:22:08.148+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 4.0 in stage 7.0 (TID 56). 4181 bytes result sent to driver
[2025-05-02T02:22:08.149+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 57) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.150+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 5.0 in stage 7.0 (TID 57)
[2025-05-02T02:22:08.151+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 56) in 19 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:08.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_5 locally
[2025-05-02T02:22:08.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 5.0 in stage 7.0 (TID 57). 4181 bytes result sent to driver
[2025-05-02T02:22:08.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 58) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 6.0 in stage 7.0 (TID 58)
[2025-05-02T02:22:08.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 57) in 20 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:08.185+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_6 locally
[2025-05-02T02:22:08.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 6.0 in stage 7.0 (TID 58). 4181 bytes result sent to driver
[2025-05-02T02:22:08.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 59) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 7.0 in stage 7.0 (TID 59)
[2025-05-02T02:22:08.191+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 58) in 22 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:08.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_7 locally
[2025-05-02T02:22:08.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 7.0 in stage 7.0 (TID 59). 4181 bytes result sent to driver
[2025-05-02T02:22:08.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 60) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.208+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 59) in 19 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:08.209+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 8.0 in stage 7.0 (TID 60)
[2025-05-02T02:22:08.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_8 locally
[2025-05-02T02:22:08.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 8.0 in stage 7.0 (TID 60). 4181 bytes result sent to driver
[2025-05-02T02:22:08.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 61) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 60) in 21 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:08.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 9.0 in stage 7.0 (TID 61)
[2025-05-02T02:22:08.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_9 locally
[2025-05-02T02:22:08.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 9.0 in stage 7.0 (TID 61). 4181 bytes result sent to driver
[2025-05-02T02:22:08.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 62) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 10.0 in stage 7.0 (TID 62)
[2025-05-02T02:22:08.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 61) in 24 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:08.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_10 locally
[2025-05-02T02:22:08.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 10.0 in stage 7.0 (TID 62). 4181 bytes result sent to driver
[2025-05-02T02:22:08.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 63) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 62) in 20 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:08.272+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 11.0 in stage 7.0 (TID 63)
[2025-05-02T02:22:08.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_11 locally
[2025-05-02T02:22:08.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 11.0 in stage 7.0 (TID 63). 4181 bytes result sent to driver
[2025-05-02T02:22:08.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 64) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 12.0 in stage 7.0 (TID 64)
[2025-05-02T02:22:08.291+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 63) in 20 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:08.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_12 locally
[2025-05-02T02:22:08.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 12.0 in stage 7.0 (TID 64). 4181 bytes result sent to driver
[2025-05-02T02:22:08.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 65) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.308+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 13.0 in stage 7.0 (TID 65)
[2025-05-02T02:22:08.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 64) in 20 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:08.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_13 locally
[2025-05-02T02:22:08.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 13.0 in stage 7.0 (TID 65). 4181 bytes result sent to driver
[2025-05-02T02:22:08.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 66) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 65) in 22 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:08.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 14.0 in stage 7.0 (TID 66)
[2025-05-02T02:22:08.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_14 locally
[2025-05-02T02:22:08.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 14.0 in stage 7.0 (TID 66). 4181 bytes result sent to driver
[2025-05-02T02:22:08.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 67) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.347+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 15.0 in stage 7.0 (TID 67)
[2025-05-02T02:22:08.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 66) in 20 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:08.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_15 locally
[2025-05-02T02:22:08.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 15.0 in stage 7.0 (TID 67). 4181 bytes result sent to driver
[2025-05-02T02:22:08.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 68) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 16.0 in stage 7.0 (TID 68)
[2025-05-02T02:22:08.365+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 67) in 19 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:08.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_16 locally
[2025-05-02T02:22:08.378+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 16.0 in stage 7.0 (TID 68). 4181 bytes result sent to driver
[2025-05-02T02:22:08.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 69) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 17.0 in stage 7.0 (TID 69)
[2025-05-02T02:22:08.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 68) in 18 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:08.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_17 locally
[2025-05-02T02:22:08.402+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 17.0 in stage 7.0 (TID 69). 4267 bytes result sent to driver
[2025-05-02T02:22:08.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 70) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ***-scheduler:33063 in memory (size: 125.4 KiB, free: 434.2 MiB)
[2025-05-02T02:22:08.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 18.0 in stage 7.0 (TID 70)
[2025-05-02T02:22:08.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 69) in 25 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:08.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_18 locally
[2025-05-02T02:22:08.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 18.0 in stage 7.0 (TID 70). 4181 bytes result sent to driver
[2025-05-02T02:22:08.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 71) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 19.0 in stage 7.0 (TID 71)
[2025-05-02T02:22:08.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 70) in 18 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:08.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_19 locally
[2025-05-02T02:22:08.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 19.0 in stage 7.0 (TID 71). 4181 bytes result sent to driver
[2025-05-02T02:22:08.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 72) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 20.0 in stage 7.0 (TID 72)
[2025-05-02T02:22:08.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 71) in 17 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:08.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_20 locally
[2025-05-02T02:22:08.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 20.0 in stage 7.0 (TID 72). 4181 bytes result sent to driver
[2025-05-02T02:22:08.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 73) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 72) in 18 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:08.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 21.0 in stage 7.0 (TID 73)
[2025-05-02T02:22:08.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_21 locally
[2025-05-02T02:22:08.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 21.0 in stage 7.0 (TID 73). 4181 bytes result sent to driver
[2025-05-02T02:22:08.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 74) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 22.0 in stage 7.0 (TID 74)
[2025-05-02T02:22:08.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 73) in 18 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:08.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_22 locally
[2025-05-02T02:22:08.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 22.0 in stage 7.0 (TID 74). 4181 bytes result sent to driver
[2025-05-02T02:22:08.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 75) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.488+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 23.0 in stage 7.0 (TID 75)
[2025-05-02T02:22:08.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 74) in 18 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:08.506+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_23 locally
[2025-05-02T02:22:08.508+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 23.0 in stage 7.0 (TID 75). 4224 bytes result sent to driver
[2025-05-02T02:22:08.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 76) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 24.0 in stage 7.0 (TID 76)
[2025-05-02T02:22:08.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 75) in 24 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:08.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_24 locally
[2025-05-02T02:22:08.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 24.0 in stage 7.0 (TID 76). 4181 bytes result sent to driver
[2025-05-02T02:22:08.526+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 77) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.527+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 25.0 in stage 7.0 (TID 77)
[2025-05-02T02:22:08.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 76) in 17 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:08.539+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_25 locally
[2025-05-02T02:22:08.541+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 25.0 in stage 7.0 (TID 77). 4181 bytes result sent to driver
[2025-05-02T02:22:08.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 78) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.543+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 26.0 in stage 7.0 (TID 78)
[2025-05-02T02:22:08.544+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 77) in 18 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:08.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_26 locally
[2025-05-02T02:22:08.557+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 26.0 in stage 7.0 (TID 78). 4181 bytes result sent to driver
[2025-05-02T02:22:08.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 79) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 27.0 in stage 7.0 (TID 79)
[2025-05-02T02:22:08.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 78) in 16 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:08.571+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_27 locally
[2025-05-02T02:22:08.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 27.0 in stage 7.0 (TID 79). 4181 bytes result sent to driver
[2025-05-02T02:22:08.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 80) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 28.0 in stage 7.0 (TID 80)
[2025-05-02T02:22:08.576+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 79) in 18 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:08.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_28 locally
[2025-05-02T02:22:08.590+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 28.0 in stage 7.0 (TID 80). 4181 bytes result sent to driver
[2025-05-02T02:22:08.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 81) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 80) in 18 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:08.593+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 29.0 in stage 7.0 (TID 81)
[2025-05-02T02:22:08.604+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_29 locally
[2025-05-02T02:22:08.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 29.0 in stage 7.0 (TID 81). 4181 bytes result sent to driver
[2025-05-02T02:22:08.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 82) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 81) in 17 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:08.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 30.0 in stage 7.0 (TID 82)
[2025-05-02T02:22:08.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_30 locally
[2025-05-02T02:22:08.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 30.0 in stage 7.0 (TID 82). 4181 bytes result sent to driver
[2025-05-02T02:22:08.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 83) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 82) in 17 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:08.626+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 31.0 in stage 7.0 (TID 83)
[2025-05-02T02:22:08.641+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_31 locally
[2025-05-02T02:22:08.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 31.0 in stage 7.0 (TID 83). 4181 bytes result sent to driver
[2025-05-02T02:22:08.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 84) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 83) in 23 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:08.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 32.0 in stage 7.0 (TID 84)
[2025-05-02T02:22:08.659+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_32 locally
[2025-05-02T02:22:08.662+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 32.0 in stage 7.0 (TID 84). 4181 bytes result sent to driver
[2025-05-02T02:22:08.663+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 85) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.664+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 84) in 18 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:08.665+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 33.0 in stage 7.0 (TID 85)
[2025-05-02T02:22:08.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_33 locally
[2025-05-02T02:22:08.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 33.0 in stage 7.0 (TID 85). 4181 bytes result sent to driver
[2025-05-02T02:22:08.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 86) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 34.0 in stage 7.0 (TID 86)
[2025-05-02T02:22:08.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 85) in 20 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:08.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_34 locally
[2025-05-02T02:22:08.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 34.0 in stage 7.0 (TID 86). 4181 bytes result sent to driver
[2025-05-02T02:22:08.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 87) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 35.0 in stage 7.0 (TID 87)
[2025-05-02T02:22:08.705+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 86) in 23 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:08.716+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_35 locally
[2025-05-02T02:22:08.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 35.0 in stage 7.0 (TID 87). 4181 bytes result sent to driver
[2025-05-02T02:22:08.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 88) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 87) in 17 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:08.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 36.0 in stage 7.0 (TID 88)
[2025-05-02T02:22:08.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_36 locally
[2025-05-02T02:22:08.738+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 36.0 in stage 7.0 (TID 88). 4181 bytes result sent to driver
[2025-05-02T02:22:08.740+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 89) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.741+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 37.0 in stage 7.0 (TID 89)
[2025-05-02T02:22:08.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 88) in 22 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:08.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_37 locally
[2025-05-02T02:22:08.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 37.0 in stage 7.0 (TID 89). 4181 bytes result sent to driver
[2025-05-02T02:22:08.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 90) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 38.0 in stage 7.0 (TID 90)
[2025-05-02T02:22:08.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 89) in 22 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:08.773+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_38 locally
[2025-05-02T02:22:08.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 38.0 in stage 7.0 (TID 90). 4349 bytes result sent to driver
[2025-05-02T02:22:08.777+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 91) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 39.0 in stage 7.0 (TID 91)
[2025-05-02T02:22:08.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 90) in 18 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:08.789+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_39 locally
[2025-05-02T02:22:08.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 39.0 in stage 7.0 (TID 91). 4181 bytes result sent to driver
[2025-05-02T02:22:08.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 92) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 40.0 in stage 7.0 (TID 92)
[2025-05-02T02:22:08.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 91) in 16 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:08.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_40 locally
[2025-05-02T02:22:08.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 40.0 in stage 7.0 (TID 92). 4181 bytes result sent to driver
[2025-05-02T02:22:08.807+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 93) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.808+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 41.0 in stage 7.0 (TID 93)
[2025-05-02T02:22:08.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 92) in 16 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:08.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_41 locally
[2025-05-02T02:22:08.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 41.0 in stage 7.0 (TID 93). 4181 bytes result sent to driver
[2025-05-02T02:22:08.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 94) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 42.0 in stage 7.0 (TID 94)
[2025-05-02T02:22:08.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 93) in 17 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:08.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_42 locally
[2025-05-02T02:22:08.843+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 42.0 in stage 7.0 (TID 94). 4224 bytes result sent to driver
[2025-05-02T02:22:08.845+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 95) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 43.0 in stage 7.0 (TID 95)
[2025-05-02T02:22:08.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 94) in 22 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:08.857+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_43 locally
[2025-05-02T02:22:08.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 43.0 in stage 7.0 (TID 95). 4267 bytes result sent to driver
[2025-05-02T02:22:08.866+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 96) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 44.0 in stage 7.0 (TID 96)
[2025-05-02T02:22:08.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 95) in 23 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:08.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_44 locally
[2025-05-02T02:22:08.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 44.0 in stage 7.0 (TID 96). 4224 bytes result sent to driver
[2025-05-02T02:22:08.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 97) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 45.0 in stage 7.0 (TID 97)
[2025-05-02T02:22:08.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 96) in 21 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:08.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_45 locally
[2025-05-02T02:22:08.901+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 45.0 in stage 7.0 (TID 97). 4181 bytes result sent to driver
[2025-05-02T02:22:08.902+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 98) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.903+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 46.0 in stage 7.0 (TID 98)
[2025-05-02T02:22:08.904+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 97) in 17 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:08.914+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_46 locally
[2025-05-02T02:22:08.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 46.0 in stage 7.0 (TID 98). 4181 bytes result sent to driver
[2025-05-02T02:22:08.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 99) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 47.0 in stage 7.0 (TID 99)
[2025-05-02T02:22:08.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 98) in 17 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:08.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_47 locally
[2025-05-02T02:22:08.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 47.0 in stage 7.0 (TID 99). 4181 bytes result sent to driver
[2025-05-02T02:22:08.933+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 100) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 48.0 in stage 7.0 (TID 100)
[2025-05-02T02:22:08.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 99) in 17 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:08.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_48 locally
[2025-05-02T02:22:08.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 48.0 in stage 7.0 (TID 100). 4181 bytes result sent to driver
[2025-05-02T02:22:08.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 101) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:08.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 100) in 21 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:08.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Running task 49.0 in stage 7.0 (TID 101)
[2025-05-02T02:22:08.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO BlockManager: Found block rdd_10_49 locally
[2025-05-02T02:22:08.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO Executor: Finished task 49.0 in stage 7.0 (TID 101). 4181 bytes result sent to driver
[2025-05-02T02:22:08.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 101) in 32 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:08.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-05-02T02:22:08.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO DAGScheduler: ResultStage 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.152 s
[2025-05-02T02:22:08.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:08.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-05-02T02:22:08.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:08 INFO DAGScheduler: Job 3 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.160062 s
[2025-05-02T02:22:09.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO CodeGenerator: Code generated in 17.025278 ms
[2025-05-02T02:22:09.358+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:09.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO Snapshot: DELTA: Compute snapshot for version: 0
[2025-05-02T02:22:09.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 204.7 KiB, free 432.9 MiB)
[2025-05-02T02:22:09.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 432.9 MiB)
[2025-05-02T02:22:09.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ***-scheduler:33063 (size: 35.8 KiB, free: 434.1 MiB)
[2025-05-02T02:22:09.378+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO SparkContext: Created broadcast 6 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:09.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3418)
[2025-05-02T02:22:09.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DataSourceStrategy: Pruning directories with:
[2025-05-02T02:22:09.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:09.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:09.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 205.0 KiB, free 432.7 MiB)
[2025-05-02T02:22:09.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 432.6 MiB)
[2025-05-02T02:22:09.688+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ***-scheduler:33063 (size: 35.9 KiB, free: 434.1 MiB)
[2025-05-02T02:22:09.688+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO SparkContext: Created broadcast 7 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:09.690+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197722 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:09.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Registering RDD 22 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 2
[2025-05-02T02:22:09.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Got map stage job 4 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:09.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Final stage: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:09.705+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:09.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:09.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[22] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:09.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 105.9 KiB, free 432.5 MiB)
[2025-05-02T02:22:09.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 432.5 MiB)
[2025-05-02T02:22:09.711+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ***-scheduler:33063 (size: 32.7 KiB, free: 434.1 MiB)
[2025-05-02T02:22:09.712+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:09.713+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[22] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:09.714+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-02T02:22:09.714+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 102) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10891 bytes)
[2025-05-02T02:22:09.715+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 102)
[2025-05-02T02:22:09.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/_delta_log/00000000000000000000.json, range: 0-3418, partition values: [0]
[2025-05-02T02:22:09.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 102). 1841 bytes result sent to driver
[2025-05-02T02:22:09.784+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 102) in 71 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:09.785+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-02T02:22:09.786+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.081 s
[2025-05-02T02:22:09.787+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:09.788+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:09.788+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:09.789+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:09.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:09 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ***-scheduler:33063 in memory (size: 32.7 KiB, free: 434.1 MiB)
[2025-05-02T02:22:10.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Registering RDD 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 3
[2025-05-02T02:22:10.043+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Got map stage job 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:10.043+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Final stage: ShuffleMapStage 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:10.045+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
[2025-05-02T02:22:10.051+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:10.052+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[32] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:10.064+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 605.5 KiB, free 432.0 MiB)
[2025-05-02T02:22:10.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 138.9 KiB, free 431.9 MiB)
[2025-05-02T02:22:10.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ***-scheduler:33063 (size: 138.9 KiB, free: 434.0 MiB)
[2025-05-02T02:22:10.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:10.070+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[32] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:10.071+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSchedulerImpl: Adding task set 10.0 with 50 tasks resource profile 0
[2025-05-02T02:22:10.073+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 103) (***-scheduler, executor driver, partition 4, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 4.0 in stage 10.0 (TID 103)
[2025-05-02T02:22:10.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 1 (955.0 B) non-empty blocks including 1 (955.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_4 stored as values in memory (estimated size 1042.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_4 in memory on ***-scheduler:33063 (size: 1042.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 4.0 in stage 10.0 (TID 103). 5308 bytes result sent to driver
[2025-05-02T02:22:10.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 42.0 in stage 10.0 (TID 104) (***-scheduler, executor driver, partition 42, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.172+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 42.0 in stage 10.0 (TID 104)
[2025-05-02T02:22:10.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 103) in 100 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:10.186+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 1 (1051.0 B) non-empty blocks including 1 (1051.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_42 stored as values in memory (estimated size 631.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_42 in memory on ***-scheduler:33063 (size: 631.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 42.0 in stage 10.0 (TID 104). 5308 bytes result sent to driver
[2025-05-02T02:22:10.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 105) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 42.0 in stage 10.0 (TID 104) in 79 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:10.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 0.0 in stage 10.0 (TID 105)
[2025-05-02T02:22:10.264+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.296+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_0 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 0.0 in stage 10.0 (TID 105). 5308 bytes result sent to driver
[2025-05-02T02:22:10.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 106) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 105) in 73 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:10.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 1.0 in stage 10.0 (TID 106)
[2025-05-02T02:22:10.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.337+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_1 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 1.0 in stage 10.0 (TID 106). 5308 bytes result sent to driver
[2025-05-02T02:22:10.410+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 107) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.411+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 106) in 89 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:10.412+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 2.0 in stage 10.0 (TID 107)
[2025-05-02T02:22:10.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.425+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_2 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_2 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 2.0 in stage 10.0 (TID 107). 5308 bytes result sent to driver
[2025-05-02T02:22:10.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 108) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.481+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 107) in 71 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:10.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 3.0 in stage 10.0 (TID 108)
[2025-05-02T02:22:10.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_3 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 3.0 in stage 10.0 (TID 108). 5308 bytes result sent to driver
[2025-05-02T02:22:10.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 109) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.562+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 5.0 in stage 10.0 (TID 109)
[2025-05-02T02:22:10.562+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 108) in 81 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:10.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_5 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 5.0 in stage 10.0 (TID 109). 5308 bytes result sent to driver
[2025-05-02T02:22:10.631+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 110) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 109) in 71 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:10.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 6.0 in stage 10.0 (TID 110)
[2025-05-02T02:22:10.644+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_6 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 6.0 in stage 10.0 (TID 110). 5308 bytes result sent to driver
[2025-05-02T02:22:10.700+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 111) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 7.0 in stage 10.0 (TID 111)
[2025-05-02T02:22:10.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 110) in 70 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:10.714+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.715+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_7 stored as values in memory (estimated size 46.0 B, free 431.9 MiB)
[2025-05-02T02:22:10.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:10.777+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 7.0 in stage 10.0 (TID 111). 5351 bytes result sent to driver
[2025-05-02T02:22:10.779+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 112) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 111) in 80 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:10.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 8.0 in stage 10.0 (TID 112)
[2025-05-02T02:22:10.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ***-scheduler:33063 in memory (size: 155.3 KiB, free: 434.1 MiB)
[2025-05-02T02:22:10.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_8 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:10.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:10.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 8.0 in stage 10.0 (TID 112). 5308 bytes result sent to driver
[2025-05-02T02:22:10.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 113) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 112) in 103 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:10.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 9.0 in stage 10.0 (TID 113)
[2025-05-02T02:22:10.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_9 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:10.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:10.946+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Finished task 9.0 in stage 10.0 (TID 113). 5308 bytes result sent to driver
[2025-05-02T02:22:10.947+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 114) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:10.948+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 113) in 68 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:10.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO Executor: Running task 10.0 in stage 10.0 (TID 114)
[2025-05-02T02:22:10.960+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:10.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:10.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO MemoryStore: Block rdd_29_10 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:10.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:10 INFO BlockManagerInfo: Added rdd_29_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.011+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 10.0 in stage 10.0 (TID 114). 5308 bytes result sent to driver
[2025-05-02T02:22:11.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 11.0 in stage 10.0 (TID 115) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 11.0 in stage 10.0 (TID 115)
[2025-05-02T02:22:11.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 114) in 66 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:11.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.055+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_11 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.056+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_11 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.077+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 11.0 in stage 10.0 (TID 115). 5308 bytes result sent to driver
[2025-05-02T02:22:11.078+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 12.0 in stage 10.0 (TID 116) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.079+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 12.0 in stage 10.0 (TID 116)
[2025-05-02T02:22:11.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 11.0 in stage 10.0 (TID 115) in 67 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:11.091+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.092+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_12 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 12.0 in stage 10.0 (TID 116). 5308 bytes result sent to driver
[2025-05-02T02:22:11.143+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 13.0 in stage 10.0 (TID 117) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.144+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 12.0 in stage 10.0 (TID 116) in 65 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:11.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 13.0 in stage 10.0 (TID 117)
[2025-05-02T02:22:11.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_13 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 13.0 in stage 10.0 (TID 117). 5308 bytes result sent to driver
[2025-05-02T02:22:11.209+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 14.0 in stage 10.0 (TID 118) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.210+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 13.0 in stage 10.0 (TID 117) in 66 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:11.211+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 14.0 in stage 10.0 (TID 118)
[2025-05-02T02:22:11.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_14 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 14.0 in stage 10.0 (TID 118). 5308 bytes result sent to driver
[2025-05-02T02:22:11.277+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 15.0 in stage 10.0 (TID 119) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.278+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 14.0 in stage 10.0 (TID 118) in 69 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:11.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 15.0 in stage 10.0 (TID 119)
[2025-05-02T02:22:11.290+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.291+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.325+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_15 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.326+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 15.0 in stage 10.0 (TID 119). 5308 bytes result sent to driver
[2025-05-02T02:22:11.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 16.0 in stage 10.0 (TID 120) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 15.0 in stage 10.0 (TID 119) in 74 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:11.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 16.0 in stage 10.0 (TID 120)
[2025-05-02T02:22:11.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_16 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 16.0 in stage 10.0 (TID 120). 5308 bytes result sent to driver
[2025-05-02T02:22:11.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 17.0 in stage 10.0 (TID 121) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 17.0 in stage 10.0 (TID 121)
[2025-05-02T02:22:11.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 16.0 in stage 10.0 (TID 120) in 66 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:11.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_17 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 17.0 in stage 10.0 (TID 121). 5351 bytes result sent to driver
[2025-05-02T02:22:11.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 18.0 in stage 10.0 (TID 122) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 18.0 in stage 10.0 (TID 122)
[2025-05-02T02:22:11.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 17.0 in stage 10.0 (TID 121) in 70 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:11.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_18 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.556+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 18.0 in stage 10.0 (TID 122). 5351 bytes result sent to driver
[2025-05-02T02:22:11.557+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 19.0 in stage 10.0 (TID 123) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 18.0 in stage 10.0 (TID 122) in 72 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:11.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 19.0 in stage 10.0 (TID 123)
[2025-05-02T02:22:11.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.598+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_19 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.599+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 19.0 in stage 10.0 (TID 123). 5308 bytes result sent to driver
[2025-05-02T02:22:11.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 20.0 in stage 10.0 (TID 124) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 19.0 in stage 10.0 (TID 123) in 63 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:11.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 20.0 in stage 10.0 (TID 124)
[2025-05-02T02:22:11.631+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.659+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_20 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.679+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 20.0 in stage 10.0 (TID 124). 5308 bytes result sent to driver
[2025-05-02T02:22:11.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 21.0 in stage 10.0 (TID 125) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 20.0 in stage 10.0 (TID 124) in 61 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:11.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 21.0 in stage 10.0 (TID 125)
[2025-05-02T02:22:11.692+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.693+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_21 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 21.0 in stage 10.0 (TID 125). 5308 bytes result sent to driver
[2025-05-02T02:22:11.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 22.0 in stage 10.0 (TID 126) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 21.0 in stage 10.0 (TID 125) in 71 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:11.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 22.0 in stage 10.0 (TID 126)
[2025-05-02T02:22:11.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.789+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_22 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.790+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.808+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 22.0 in stage 10.0 (TID 126). 5308 bytes result sent to driver
[2025-05-02T02:22:11.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 23.0 in stage 10.0 (TID 127) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 22.0 in stage 10.0 (TID 126) in 61 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:11.811+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 23.0 in stage 10.0 (TID 127)
[2025-05-02T02:22:11.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_23 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 23.0 in stage 10.0 (TID 127). 5308 bytes result sent to driver
[2025-05-02T02:22:11.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 24.0 in stage 10.0 (TID 128) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 24.0 in stage 10.0 (TID 128)
[2025-05-02T02:22:11.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 23.0 in stage 10.0 (TID 127) in 72 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:11.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:11.940+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO MemoryStore: Block rdd_29_24 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:11.941+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO BlockManagerInfo: Added rdd_29_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:11.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Finished task 24.0 in stage 10.0 (TID 128). 5308 bytes result sent to driver
[2025-05-02T02:22:11.960+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Starting task 25.0 in stage 10.0 (TID 129) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:11.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO TaskSetManager: Finished task 24.0 in stage 10.0 (TID 128) in 79 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:11.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO Executor: Running task 25.0 in stage 10.0 (TID 129)
[2025-05-02T02:22:11.973+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:11.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_25 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.001+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 25.0 in stage 10.0 (TID 129). 5308 bytes result sent to driver
[2025-05-02T02:22:12.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 26.0 in stage 10.0 (TID 130) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 25.0 in stage 10.0 (TID 129) in 62 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:12.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 26.0 in stage 10.0 (TID 130)
[2025-05-02T02:22:12.032+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.033+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_26 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.060+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 26.0 in stage 10.0 (TID 130). 5308 bytes result sent to driver
[2025-05-02T02:22:12.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 27.0 in stage 10.0 (TID 131) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 26.0 in stage 10.0 (TID 130) in 69 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:12.091+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 27.0 in stage 10.0 (TID 131)
[2025-05-02T02:22:12.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_27 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.126+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.144+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 27.0 in stage 10.0 (TID 131). 5308 bytes result sent to driver
[2025-05-02T02:22:12.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 28.0 in stage 10.0 (TID 132) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 28.0 in stage 10.0 (TID 132)
[2025-05-02T02:22:12.147+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 27.0 in stage 10.0 (TID 131) in 57 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:12.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_28 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 28.0 in stage 10.0 (TID 132). 5351 bytes result sent to driver
[2025-05-02T02:22:12.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 29.0 in stage 10.0 (TID 133) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 28.0 in stage 10.0 (TID 132) in 78 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:12.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 29.0 in stage 10.0 (TID 133)
[2025-05-02T02:22:12.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.238+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_29 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.310+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 29.0 in stage 10.0 (TID 133). 5308 bytes result sent to driver
[2025-05-02T02:22:12.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 30.0 in stage 10.0 (TID 134) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 30.0 in stage 10.0 (TID 134)
[2025-05-02T02:22:12.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 29.0 in stage 10.0 (TID 133) in 90 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:12.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.325+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_30 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 30.0 in stage 10.0 (TID 134). 5308 bytes result sent to driver
[2025-05-02T02:22:12.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 31.0 in stage 10.0 (TID 135) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 30.0 in stage 10.0 (TID 134) in 73 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:12.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 31.0 in stage 10.0 (TID 135)
[2025-05-02T02:22:12.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_31 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.447+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 31.0 in stage 10.0 (TID 135). 5308 bytes result sent to driver
[2025-05-02T02:22:12.448+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 32.0 in stage 10.0 (TID 136) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 32.0 in stage 10.0 (TID 136)
[2025-05-02T02:22:12.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 31.0 in stage 10.0 (TID 135) in 66 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:12.459+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_32 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.488+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 32.0 in stage 10.0 (TID 136). 5308 bytes result sent to driver
[2025-05-02T02:22:12.508+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 33.0 in stage 10.0 (TID 137) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 32.0 in stage 10.0 (TID 136) in 60 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:12.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 33.0 in stage 10.0 (TID 137)
[2025-05-02T02:22:12.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.546+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_33 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.547+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 33.0 in stage 10.0 (TID 137). 5308 bytes result sent to driver
[2025-05-02T02:22:12.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 34.0 in stage 10.0 (TID 138) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 33.0 in stage 10.0 (TID 137) in 60 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:12.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 34.0 in stage 10.0 (TID 138)
[2025-05-02T02:22:12.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_34 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 34.0 in stage 10.0 (TID 138). 5308 bytes result sent to driver
[2025-05-02T02:22:12.626+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 35.0 in stage 10.0 (TID 139) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 34.0 in stage 10.0 (TID 138) in 59 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:12.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 35.0 in stage 10.0 (TID 139)
[2025-05-02T02:22:12.641+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.642+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_35 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.687+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 35.0 in stage 10.0 (TID 139). 5308 bytes result sent to driver
[2025-05-02T02:22:12.688+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 36.0 in stage 10.0 (TID 140) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.689+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 35.0 in stage 10.0 (TID 139) in 64 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:12.690+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 36.0 in stage 10.0 (TID 140)
[2025-05-02T02:22:12.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_36 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.746+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 36.0 in stage 10.0 (TID 140). 5308 bytes result sent to driver
[2025-05-02T02:22:12.765+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 37.0 in stage 10.0 (TID 141) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 37.0 in stage 10.0 (TID 141)
[2025-05-02T02:22:12.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 36.0 in stage 10.0 (TID 140) in 77 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:12.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.777+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_37 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 37.0 in stage 10.0 (TID 141). 5308 bytes result sent to driver
[2025-05-02T02:22:12.822+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 38.0 in stage 10.0 (TID 142) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 38.0 in stage 10.0 (TID 142)
[2025-05-02T02:22:12.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 37.0 in stage 10.0 (TID 141) in 57 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:12.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.863+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_38 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.864+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 38.0 in stage 10.0 (TID 142). 5308 bytes result sent to driver
[2025-05-02T02:22:12.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 39.0 in stage 10.0 (TID 143) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.884+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 38.0 in stage 10.0 (TID 142) in 62 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:12.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 39.0 in stage 10.0 (TID 143)
[2025-05-02T02:22:12.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_39 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:12.947+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Finished task 39.0 in stage 10.0 (TID 143). 5351 bytes result sent to driver
[2025-05-02T02:22:12.948+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Starting task 40.0 in stage 10.0 (TID 144) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:12.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO TaskSetManager: Finished task 39.0 in stage 10.0 (TID 143) in 65 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:12.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO Executor: Running task 40.0 in stage 10.0 (TID 144)
[2025-05-02T02:22:12.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:12.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:12.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO MemoryStore: Block rdd_29_40 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:12.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:12 INFO BlockManagerInfo: Added rdd_29_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 40.0 in stage 10.0 (TID 144). 5351 bytes result sent to driver
[2025-05-02T02:22:13.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 41.0 in stage 10.0 (TID 145) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 40.0 in stage 10.0 (TID 144) in 65 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:13.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 41.0 in stage 10.0 (TID 145)
[2025-05-02T02:22:13.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.050+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_41 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.051+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 41.0 in stage 10.0 (TID 145). 5308 bytes result sent to driver
[2025-05-02T02:22:13.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 43.0 in stage 10.0 (TID 146) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.075+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 41.0 in stage 10.0 (TID 145) in 63 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:13.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 43.0 in stage 10.0 (TID 146)
[2025-05-02T02:22:13.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.112+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_43 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.113+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.132+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 43.0 in stage 10.0 (TID 146). 5308 bytes result sent to driver
[2025-05-02T02:22:13.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 44.0 in stage 10.0 (TID 147) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 43.0 in stage 10.0 (TID 146) in 59 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:13.134+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 44.0 in stage 10.0 (TID 147)
[2025-05-02T02:22:13.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_44 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.174+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 44.0 in stage 10.0 (TID 147). 5308 bytes result sent to driver
[2025-05-02T02:22:13.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 45.0 in stage 10.0 (TID 148) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 44.0 in stage 10.0 (TID 147) in 61 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:13.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 45.0 in stage 10.0 (TID 148)
[2025-05-02T02:22:13.204+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.205+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_45 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 45.0 in stage 10.0 (TID 148). 5308 bytes result sent to driver
[2025-05-02T02:22:13.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 46.0 in stage 10.0 (TID 149) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 46.0 in stage 10.0 (TID 149)
[2025-05-02T02:22:13.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 45.0 in stage 10.0 (TID 148) in 57 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:13.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.262+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_46 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 46.0 in stage 10.0 (TID 149). 5308 bytes result sent to driver
[2025-05-02T02:22:13.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 47.0 in stage 10.0 (TID 150) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.308+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 46.0 in stage 10.0 (TID 149) in 58 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:13.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 47.0 in stage 10.0 (TID 150)
[2025-05-02T02:22:13.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_47 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 47.0 in stage 10.0 (TID 150). 5308 bytes result sent to driver
[2025-05-02T02:22:13.369+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 48.0 in stage 10.0 (TID 151) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 47.0 in stage 10.0 (TID 150) in 63 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:13.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 48.0 in stage 10.0 (TID 151)
[2025-05-02T02:22:13.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_48 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 48.0 in stage 10.0 (TID 151). 5308 bytes result sent to driver
[2025-05-02T02:22:13.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 49.0 in stage 10.0 (TID 152) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:13.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 48.0 in stage 10.0 (TID 151) in 59 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:13.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 49.0 in stage 10.0 (TID 152)
[2025-05-02T02:22:13.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block rdd_29_49 stored as values in memory (estimated size 46.0 B, free 432.7 MiB)
[2025-05-02T02:22:13.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added rdd_29_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.1 MiB)
[2025-05-02T02:22:13.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 49.0 in stage 10.0 (TID 152). 5308 bytes result sent to driver
[2025-05-02T02:22:13.481+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 49.0 in stage 10.0 (TID 152) in 55 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:13.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-05-02T02:22:13.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: ShuffleMapStage 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 3.427 s
[2025-05-02T02:22:13.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:13.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:13.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:13.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:13.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:13.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Got job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:13.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Final stage: ResultStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:13.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
[2025-05-02T02:22:13.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:13.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[35] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:13.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 537.2 KiB, free 432.2 MiB)
[2025-05-02T02:22:13.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 125.5 KiB, free 432.1 MiB)
[2025-05-02T02:22:13.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ***-scheduler:33063 (size: 125.5 KiB, free: 434.0 MiB)
[2025-05-02T02:22:13.529+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:13.530+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[35] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:13.531+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-05-02T02:22:13.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 153) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 0.0 in stage 13.0 (TID 153)
[2025-05-02T02:22:13.541+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Getting 50 (4.8 KiB) non-empty blocks including 50 (4.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:13.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:13.565+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 0.0 in stage 13.0 (TID 153). 7028 bytes result sent to driver
[2025-05-02T02:22:13.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 153) in 36 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:13.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-05-02T02:22:13.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: ResultStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.050 s
[2025-05-02T02:22:13.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:13.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
[2025-05-02T02:22:13.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Job 6 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.054130 s
[2025-05-02T02:22:13.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Snapshot: DELTA: Done
[2025-05-02T02:22:13.739+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Removed broadcast_10_piece0 on ***-scheduler:33063 in memory (size: 125.5 KiB, free: 434.1 MiB)
[2025-05-02T02:22:13.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:13.785+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Got job 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:13.786+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Final stage: ResultStage 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:13.787+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
[2025-05-02T02:22:13.787+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:13.788+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[37] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:13.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 687.2 KiB, free 432.1 MiB)
[2025-05-02T02:22:13.800+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 155.3 KiB, free 431.9 MiB)
[2025-05-02T02:22:13.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on ***-scheduler:33063 (size: 155.3 KiB, free: 434.0 MiB)
[2025-05-02T02:22:13.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:13.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 15 (MapPartitionsRDD[37] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:13.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSchedulerImpl: Adding task set 15.0 with 50 tasks resource profile 0
[2025-05-02T02:22:13.805+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 154) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 0.0 in stage 15.0 (TID 154)
[2025-05-02T02:22:13.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_0 locally
[2025-05-02T02:22:13.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 0.0 in stage 15.0 (TID 154). 4181 bytes result sent to driver
[2025-05-02T02:22:13.822+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 155) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 154) in 18 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:13.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 1.0 in stage 15.0 (TID 155)
[2025-05-02T02:22:13.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_1 locally
[2025-05-02T02:22:13.835+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 1.0 in stage 15.0 (TID 155). 4181 bytes result sent to driver
[2025-05-02T02:22:13.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 156) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 2.0 in stage 15.0 (TID 156)
[2025-05-02T02:22:13.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 155) in 15 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:13.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_2 locally
[2025-05-02T02:22:13.848+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 2.0 in stage 15.0 (TID 156). 4181 bytes result sent to driver
[2025-05-02T02:22:13.848+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 157) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 3.0 in stage 15.0 (TID 157)
[2025-05-02T02:22:13.850+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 156) in 14 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:13.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManagerInfo: Removed broadcast_9_piece0 on ***-scheduler:33063 in memory (size: 138.9 KiB, free: 434.1 MiB)
[2025-05-02T02:22:13.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_3 locally
[2025-05-02T02:22:13.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 3.0 in stage 15.0 (TID 157). 4181 bytes result sent to driver
[2025-05-02T02:22:13.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 158) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 4.0 in stage 15.0 (TID 158)
[2025-05-02T02:22:13.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 157) in 23 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:13.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_4 locally
[2025-05-02T02:22:13.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 4.0 in stage 15.0 (TID 158). 4349 bytes result sent to driver
[2025-05-02T02:22:13.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 159) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.884+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 5.0 in stage 15.0 (TID 159)
[2025-05-02T02:22:13.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 158) in 13 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:13.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_5 locally
[2025-05-02T02:22:13.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 5.0 in stage 15.0 (TID 159). 4181 bytes result sent to driver
[2025-05-02T02:22:13.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 160) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 6.0 in stage 15.0 (TID 160)
[2025-05-02T02:22:13.900+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 159) in 17 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:13.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_6 locally
[2025-05-02T02:22:13.911+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 6.0 in stage 15.0 (TID 160). 4181 bytes result sent to driver
[2025-05-02T02:22:13.912+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 161) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.913+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 7.0 in stage 15.0 (TID 161)
[2025-05-02T02:22:13.913+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 160) in 14 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:13.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_7 locally
[2025-05-02T02:22:13.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 7.0 in stage 15.0 (TID 161). 4181 bytes result sent to driver
[2025-05-02T02:22:13.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 162) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 161) in 13 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:13.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 8.0 in stage 15.0 (TID 162)
[2025-05-02T02:22:13.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_8 locally
[2025-05-02T02:22:13.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 8.0 in stage 15.0 (TID 162). 4181 bytes result sent to driver
[2025-05-02T02:22:13.937+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 163) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.937+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 162) in 13 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:13.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 9.0 in stage 15.0 (TID 163)
[2025-05-02T02:22:13.946+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_9 locally
[2025-05-02T02:22:13.948+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 9.0 in stage 15.0 (TID 163). 4181 bytes result sent to driver
[2025-05-02T02:22:13.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 164) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 163) in 13 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:13.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 10.0 in stage 15.0 (TID 164)
[2025-05-02T02:22:13.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_10 locally
[2025-05-02T02:22:13.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 10.0 in stage 15.0 (TID 164). 4181 bytes result sent to driver
[2025-05-02T02:22:13.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 165) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 164) in 14 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:13.963+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 11.0 in stage 15.0 (TID 165)
[2025-05-02T02:22:13.971+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_11 locally
[2025-05-02T02:22:13.973+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 11.0 in stage 15.0 (TID 165). 4181 bytes result sent to driver
[2025-05-02T02:22:13.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 12.0 in stage 15.0 (TID 166) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 12.0 in stage 15.0 (TID 166)
[2025-05-02T02:22:13.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 165) in 13 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:13.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_12 locally
[2025-05-02T02:22:13.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 12.0 in stage 15.0 (TID 166). 4181 bytes result sent to driver
[2025-05-02T02:22:13.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 13.0 in stage 15.0 (TID 167) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 12.0 in stage 15.0 (TID 166) in 13 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:13.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 13.0 in stage 15.0 (TID 167)
[2025-05-02T02:22:13.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO BlockManager: Found block rdd_29_13 locally
[2025-05-02T02:22:13.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Finished task 13.0 in stage 15.0 (TID 167). 4181 bytes result sent to driver
[2025-05-02T02:22:13.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Starting task 14.0 in stage 15.0 (TID 168) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:13.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO Executor: Running task 14.0 in stage 15.0 (TID 168)
[2025-05-02T02:22:14.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:13 INFO TaskSetManager: Finished task 13.0 in stage 15.0 (TID 167) in 13 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:14.008+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_14 locally
[2025-05-02T02:22:14.010+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 14.0 in stage 15.0 (TID 168). 4181 bytes result sent to driver
[2025-05-02T02:22:14.011+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 15.0 in stage 15.0 (TID 169) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 15.0 in stage 15.0 (TID 169)
[2025-05-02T02:22:14.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 14.0 in stage 15.0 (TID 168) in 13 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:14.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_15 locally
[2025-05-02T02:22:14.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 15.0 in stage 15.0 (TID 169). 4181 bytes result sent to driver
[2025-05-02T02:22:14.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 16.0 in stage 15.0 (TID 170) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 16.0 in stage 15.0 (TID 170)
[2025-05-02T02:22:14.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 15.0 in stage 15.0 (TID 169) in 13 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:14.033+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_16 locally
[2025-05-02T02:22:14.035+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 16.0 in stage 15.0 (TID 170). 4181 bytes result sent to driver
[2025-05-02T02:22:14.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 17.0 in stage 15.0 (TID 171) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 16.0 in stage 15.0 (TID 170) in 13 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:14.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 17.0 in stage 15.0 (TID 171)
[2025-05-02T02:22:14.046+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_17 locally
[2025-05-02T02:22:14.048+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 17.0 in stage 15.0 (TID 171). 4181 bytes result sent to driver
[2025-05-02T02:22:14.049+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 18.0 in stage 15.0 (TID 172) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.050+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 17.0 in stage 15.0 (TID 171) in 13 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:14.051+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 18.0 in stage 15.0 (TID 172)
[2025-05-02T02:22:14.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_18 locally
[2025-05-02T02:22:14.061+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 18.0 in stage 15.0 (TID 172). 4181 bytes result sent to driver
[2025-05-02T02:22:14.062+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 19.0 in stage 15.0 (TID 173) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.062+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 19.0 in stage 15.0 (TID 173)
[2025-05-02T02:22:14.063+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 18.0 in stage 15.0 (TID 172) in 14 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:14.072+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_19 locally
[2025-05-02T02:22:14.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 19.0 in stage 15.0 (TID 173). 4181 bytes result sent to driver
[2025-05-02T02:22:14.075+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 20.0 in stage 15.0 (TID 174) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 20.0 in stage 15.0 (TID 174)
[2025-05-02T02:22:14.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 19.0 in stage 15.0 (TID 173) in 14 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:14.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_20 locally
[2025-05-02T02:22:14.088+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 20.0 in stage 15.0 (TID 174). 4181 bytes result sent to driver
[2025-05-02T02:22:14.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 21.0 in stage 15.0 (TID 175) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 21.0 in stage 15.0 (TID 175)
[2025-05-02T02:22:14.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 20.0 in stage 15.0 (TID 174) in 15 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:14.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_21 locally
[2025-05-02T02:22:14.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 21.0 in stage 15.0 (TID 175). 4181 bytes result sent to driver
[2025-05-02T02:22:14.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 22.0 in stage 15.0 (TID 176) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.102+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 21.0 in stage 15.0 (TID 175) in 13 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:14.103+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 22.0 in stage 15.0 (TID 176)
[2025-05-02T02:22:14.114+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_22 locally
[2025-05-02T02:22:14.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 22.0 in stage 15.0 (TID 176). 4181 bytes result sent to driver
[2025-05-02T02:22:14.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 23.0 in stage 15.0 (TID 177) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.118+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 22.0 in stage 15.0 (TID 176) in 17 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:14.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 23.0 in stage 15.0 (TID 177)
[2025-05-02T02:22:14.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_23 locally
[2025-05-02T02:22:14.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 23.0 in stage 15.0 (TID 177). 4181 bytes result sent to driver
[2025-05-02T02:22:14.129+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 24.0 in stage 15.0 (TID 178) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.130+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 24.0 in stage 15.0 (TID 178)
[2025-05-02T02:22:14.131+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 23.0 in stage 15.0 (TID 177) in 13 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:14.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_24 locally
[2025-05-02T02:22:14.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 24.0 in stage 15.0 (TID 178). 4181 bytes result sent to driver
[2025-05-02T02:22:14.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 25.0 in stage 15.0 (TID 179) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.143+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 25.0 in stage 15.0 (TID 179)
[2025-05-02T02:22:14.144+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 24.0 in stage 15.0 (TID 178) in 13 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:14.152+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_25 locally
[2025-05-02T02:22:14.153+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 25.0 in stage 15.0 (TID 179). 4181 bytes result sent to driver
[2025-05-02T02:22:14.154+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 26.0 in stage 15.0 (TID 180) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 26.0 in stage 15.0 (TID 180)
[2025-05-02T02:22:14.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 25.0 in stage 15.0 (TID 179) in 14 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:14.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_26 locally
[2025-05-02T02:22:14.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 26.0 in stage 15.0 (TID 180). 4181 bytes result sent to driver
[2025-05-02T02:22:14.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 27.0 in stage 15.0 (TID 181) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 27.0 in stage 15.0 (TID 181)
[2025-05-02T02:22:14.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 26.0 in stage 15.0 (TID 180) in 14 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:14.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_27 locally
[2025-05-02T02:22:14.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 27.0 in stage 15.0 (TID 181). 4181 bytes result sent to driver
[2025-05-02T02:22:14.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 28.0 in stage 15.0 (TID 182) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 28.0 in stage 15.0 (TID 182)
[2025-05-02T02:22:14.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 27.0 in stage 15.0 (TID 181) in 13 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:14.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_28 locally
[2025-05-02T02:22:14.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 28.0 in stage 15.0 (TID 182). 4181 bytes result sent to driver
[2025-05-02T02:22:14.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 29.0 in stage 15.0 (TID 183) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 29.0 in stage 15.0 (TID 183)
[2025-05-02T02:22:14.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 28.0 in stage 15.0 (TID 182) in 14 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:14.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_29 locally
[2025-05-02T02:22:14.204+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 29.0 in stage 15.0 (TID 183). 4181 bytes result sent to driver
[2025-05-02T02:22:14.205+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 30.0 in stage 15.0 (TID 184) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 30.0 in stage 15.0 (TID 184)
[2025-05-02T02:22:14.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 29.0 in stage 15.0 (TID 183) in 14 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:14.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_30 locally
[2025-05-02T02:22:14.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 30.0 in stage 15.0 (TID 184). 4181 bytes result sent to driver
[2025-05-02T02:22:14.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 31.0 in stage 15.0 (TID 185) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 31.0 in stage 15.0 (TID 185)
[2025-05-02T02:22:14.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 30.0 in stage 15.0 (TID 184) in 14 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:14.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_31 locally
[2025-05-02T02:22:14.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 31.0 in stage 15.0 (TID 185). 4181 bytes result sent to driver
[2025-05-02T02:22:14.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 32.0 in stage 15.0 (TID 186) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 32.0 in stage 15.0 (TID 186)
[2025-05-02T02:22:14.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 31.0 in stage 15.0 (TID 185) in 14 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:14.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_32 locally
[2025-05-02T02:22:14.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 32.0 in stage 15.0 (TID 186). 4181 bytes result sent to driver
[2025-05-02T02:22:14.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 33.0 in stage 15.0 (TID 187) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 32.0 in stage 15.0 (TID 186) in 18 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:14.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 33.0 in stage 15.0 (TID 187)
[2025-05-02T02:22:14.262+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_33 locally
[2025-05-02T02:22:14.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 33.0 in stage 15.0 (TID 187). 4181 bytes result sent to driver
[2025-05-02T02:22:14.266+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 34.0 in stage 15.0 (TID 188) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 33.0 in stage 15.0 (TID 187) in 18 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:14.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 34.0 in stage 15.0 (TID 188)
[2025-05-02T02:22:14.277+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_34 locally
[2025-05-02T02:22:14.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 34.0 in stage 15.0 (TID 188). 4267 bytes result sent to driver
[2025-05-02T02:22:14.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 35.0 in stage 15.0 (TID 189) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 34.0 in stage 15.0 (TID 188) in 21 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:14.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 35.0 in stage 15.0 (TID 189)
[2025-05-02T02:22:14.296+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_35 locally
[2025-05-02T02:22:14.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 35.0 in stage 15.0 (TID 189). 4181 bytes result sent to driver
[2025-05-02T02:22:14.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 36.0 in stage 15.0 (TID 190) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 36.0 in stage 15.0 (TID 190)
[2025-05-02T02:22:14.301+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 35.0 in stage 15.0 (TID 189) in 15 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:14.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_36 locally
[2025-05-02T02:22:14.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 36.0 in stage 15.0 (TID 190). 4181 bytes result sent to driver
[2025-05-02T02:22:14.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 37.0 in stage 15.0 (TID 191) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 36.0 in stage 15.0 (TID 190) in 13 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:14.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 37.0 in stage 15.0 (TID 191)
[2025-05-02T02:22:14.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_37 locally
[2025-05-02T02:22:14.325+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 37.0 in stage 15.0 (TID 191). 4181 bytes result sent to driver
[2025-05-02T02:22:14.326+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 38.0 in stage 15.0 (TID 192) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 38.0 in stage 15.0 (TID 192)
[2025-05-02T02:22:14.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 37.0 in stage 15.0 (TID 191) in 14 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:14.338+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_38 locally
[2025-05-02T02:22:14.339+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 38.0 in stage 15.0 (TID 192). 4181 bytes result sent to driver
[2025-05-02T02:22:14.340+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 39.0 in stage 15.0 (TID 193) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.341+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 38.0 in stage 15.0 (TID 192) in 16 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:14.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 39.0 in stage 15.0 (TID 193)
[2025-05-02T02:22:14.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_39 locally
[2025-05-02T02:22:14.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 39.0 in stage 15.0 (TID 193). 4181 bytes result sent to driver
[2025-05-02T02:22:14.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 40.0 in stage 15.0 (TID 194) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 39.0 in stage 15.0 (TID 193) in 14 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:14.355+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 40.0 in stage 15.0 (TID 194)
[2025-05-02T02:22:14.365+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_40 locally
[2025-05-02T02:22:14.367+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 40.0 in stage 15.0 (TID 194). 4181 bytes result sent to driver
[2025-05-02T02:22:14.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 41.0 in stage 15.0 (TID 195) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 40.0 in stage 15.0 (TID 194) in 21 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:14.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 41.0 in stage 15.0 (TID 195)
[2025-05-02T02:22:14.388+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_41 locally
[2025-05-02T02:22:14.390+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 41.0 in stage 15.0 (TID 195). 4181 bytes result sent to driver
[2025-05-02T02:22:14.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 42.0 in stage 15.0 (TID 196) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 41.0 in stage 15.0 (TID 195) in 18 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:14.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 42.0 in stage 15.0 (TID 196)
[2025-05-02T02:22:14.401+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_42 locally
[2025-05-02T02:22:14.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 42.0 in stage 15.0 (TID 196). 4224 bytes result sent to driver
[2025-05-02T02:22:14.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 43.0 in stage 15.0 (TID 197) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 42.0 in stage 15.0 (TID 196) in 14 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:14.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 43.0 in stage 15.0 (TID 197)
[2025-05-02T02:22:14.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_43 locally
[2025-05-02T02:22:14.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 43.0 in stage 15.0 (TID 197). 4181 bytes result sent to driver
[2025-05-02T02:22:14.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 44.0 in stage 15.0 (TID 198) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 44.0 in stage 15.0 (TID 198)
[2025-05-02T02:22:14.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 43.0 in stage 15.0 (TID 197) in 17 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:14.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_44 locally
[2025-05-02T02:22:14.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 44.0 in stage 15.0 (TID 198). 4181 bytes result sent to driver
[2025-05-02T02:22:14.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 45.0 in stage 15.0 (TID 199) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 44.0 in stage 15.0 (TID 198) in 17 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:14.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 45.0 in stage 15.0 (TID 199)
[2025-05-02T02:22:14.447+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_45 locally
[2025-05-02T02:22:14.448+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 45.0 in stage 15.0 (TID 199). 4181 bytes result sent to driver
[2025-05-02T02:22:14.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 46.0 in stage 15.0 (TID 200) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 45.0 in stage 15.0 (TID 199) in 14 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:14.451+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 46.0 in stage 15.0 (TID 200)
[2025-05-02T02:22:14.459+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_46 locally
[2025-05-02T02:22:14.461+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 46.0 in stage 15.0 (TID 200). 4181 bytes result sent to driver
[2025-05-02T02:22:14.462+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 47.0 in stage 15.0 (TID 201) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 46.0 in stage 15.0 (TID 200) in 13 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:14.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 47.0 in stage 15.0 (TID 201)
[2025-05-02T02:22:14.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_47 locally
[2025-05-02T02:22:14.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 47.0 in stage 15.0 (TID 201). 4181 bytes result sent to driver
[2025-05-02T02:22:14.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 48.0 in stage 15.0 (TID 202) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 48.0 in stage 15.0 (TID 202)
[2025-05-02T02:22:14.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 47.0 in stage 15.0 (TID 201) in 16 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:14.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_48 locally
[2025-05-02T02:22:14.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 48.0 in stage 15.0 (TID 202). 4181 bytes result sent to driver
[2025-05-02T02:22:14.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 49.0 in stage 15.0 (TID 203) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:14.491+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 48.0 in stage 15.0 (TID 202) in 14 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:14.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 49.0 in stage 15.0 (TID 203)
[2025-05-02T02:22:14.503+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManager: Found block rdd_29_49 locally
[2025-05-02T02:22:14.505+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Finished task 49.0 in stage 15.0 (TID 203). 4181 bytes result sent to driver
[2025-05-02T02:22:14.506+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Finished task 49.0 in stage 15.0 (TID 203) in 17 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:14.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-02T02:22:14.508+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: ResultStage 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.718 s
[2025-05-02T02:22:14.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:14.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-05-02T02:22:14.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Job 7 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.724246 s
[2025-05-02T02:22:14.514+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:14.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:14.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:14.586+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Key)
[2025-05-02T02:22:14.587+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Key#88)
[2025-05-02T02:22:14.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:22:14.784+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 12.627598 ms
[2025-05-02T02:22:14.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 206.5 KiB, free 432.4 MiB)
[2025-05-02T02:22:14.807+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 432.4 MiB)
[2025-05-02T02:22:14.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on ***-scheduler:33063 (size: 36.3 KiB, free: 434.1 MiB)
[2025-05-02T02:22:14.811+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:14.845+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 56.685426 ms
[2025-05-02T02:22:14.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 206.7 KiB, free 432.2 MiB)
[2025-05-02T02:22:14.860+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 432.2 MiB)
[2025-05-02T02:22:14.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on ***-scheduler:33063 (size: 36.5 KiB, free: 434.0 MiB)
[2025-05-02T02:22:14.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO SparkContext: Created broadcast 13 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:14.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4206010 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:14.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 32.25621 ms
[2025-05-02T02:22:14.914+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Registering RDD 42 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 4
[2025-05-02T02:22:14.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Got map stage job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:14.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Final stage: ShuffleMapStage 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:14.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:14.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:14.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[42] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:14.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 45.6 KiB, free 432.1 MiB)
[2025-05-02T02:22:14.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 432.1 MiB)
[2025-05-02T02:22:14.921+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on ***-scheduler:33063 (size: 19.6 KiB, free: 434.0 MiB)
[2025-05-02T02:22:14.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:14.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[42] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:14.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-05-02T02:22:14.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 204) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10908 bytes)
[2025-05-02T02:22:14.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 3.572608 ms
[2025-05-02T02:22:14.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO Executor: Running task 0.0 in stage 16.0 (TID 204)
[2025-05-02T02:22:14.945+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 11.895491 ms
[2025-05-02T02:22:14.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197529 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:14.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 23.947309 ms
[2025-05-02T02:22:14.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:14.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Got job 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-02T02:22:14.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:14.977+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:14.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:14.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[46] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:14.979+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 17.3 KiB, free 432.1 MiB)
[2025-05-02T02:22:14.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 432.1 MiB)
[2025-05-02T02:22:14.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on ***-scheduler:33063 (size: 7.7 KiB, free: 434.0 MiB)
[2025-05-02T02:22:14.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:14.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[46] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:14.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-05-02T02:22:14.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 11.852725 ms
[2025-05-02T02:22:14.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:14 INFO CodeGenerator: Code generated in 5.033013 ms
[2025-05-02T02:22:15.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet, range: 0-11706, partition values: [empty row]
[2025-05-02T02:22:15.123+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:15.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO CodecPool: Got brand-new decompressor [.snappy]
[2025-05-02T02:22:15.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO Executor: Finished task 0.0 in stage 16.0 (TID 204). 2935 bytes result sent to driver
[2025-05-02T02:22:15.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 205) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10913 bytes)
[2025-05-02T02:22:15.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO Executor: Running task 0.0 in stage 17.0 (TID 205)
[2025-05-02T02:22:15.992+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 204) in 1068 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:15.993+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-05-02T02:22:15.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO DAGScheduler: ShuffleMapStage 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.076 s
[2025-05-02T02:22:15.995+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:15.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO DAGScheduler: running: Set(ResultStage 17)
[2025-05-02T02:22:15.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:15.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:15 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:16.008+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 12.654236 ms
[2025-05-02T02:22:16.009+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergies/part-00000-21df6e80-7b21-498b-992b-71fe9091b4c4-c000.snappy.parquet, range: 0-3225, partition values: [empty row]
[2025-05-02T02:22:16.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:16.061+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:16.111+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 37.600253 ms
[2025-05-02T02:22:16.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO FilterCompat: Filtering using predicate: noteq(Allergy_Key, null)
[2025-05-02T02:22:16.148+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 5.554802 ms
[2025-05-02T02:22:16.176+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 5.827733 ms
[2025-05-02T02:22:16.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:16.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Got job 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions
[2025-05-02T02:22:16.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Final stage: ResultStage 19 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:16.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
[2025-05-02T02:22:16.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:16.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:16.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[53] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:16.240+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 57.3 KiB, free 432.0 MiB)
[2025-05-02T02:22:16.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 432.0 MiB)
[2025-05-02T02:22:16.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on ***-scheduler:33063 (size: 25.0 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:16.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 19 (MapPartitionsRDD[53] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-02T02:22:16.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks resource profile 0
[2025-05-02T02:22:16.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Finished task 0.0 in stage 17.0 (TID 205). 2986 bytes result sent to driver
[2025-05-02T02:22:16.295+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 206) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10315 bytes)
[2025-05-02T02:22:16.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Running task 0.0 in stage 19.0 (TID 206)
[2025-05-02T02:22:16.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 205) in 307 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:16.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-05-02T02:22:16.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.320 s
[2025-05-02T02:22:16.301+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:16.302+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2025-05-02T02:22:16.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Job 9 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.323227 s
[2025-05-02T02:22:16.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShuffleBlockFetcherIterator: Getting 1 (1919.0 B) non-empty blocks including 1 (1919.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:16.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-05-02T02:22:16.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 7.218639 ms
[2025-05-02T02:22:16.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 16.0 MiB, free 416.0 MiB)
[2025-05-02T02:22:16.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 1484.0 B, free 416.0 MiB)
[2025-05-02T02:22:16.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on ***-scheduler:33063 (size: 1484.0 B, free: 434.0 MiB)
[2025-05-02T02:22:16.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:16.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 31.866707 ms
[2025-05-02T02:22:16.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 6.193639 ms
[2025-05-02T02:22:16.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Finished task 0.0 in stage 19.0 (TID 206). 6106 bytes result sent to driver
[2025-05-02T02:22:16.372+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 207) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10523 bytes)
[2025-05-02T02:22:16.373+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Running task 1.0 in stage 19.0 (TID 207)
[2025-05-02T02:22:16.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 206) in 81 ms on ***-scheduler (executor driver) (1/2)
[2025-05-02T02:22:16.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 5.515828 ms
[2025-05-02T02:22:16.389+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Finished task 1.0 in stage 19.0 (TID 207). 4804 bytes result sent to driver
[2025-05-02T02:22:16.390+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 207) in 21 ms on ***-scheduler (executor driver) (2/2)
[2025-05-02T02:22:16.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-05-02T02:22:16.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: ResultStage 19 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.154 s
[2025-05-02T02:22:16.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:16.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
[2025-05-02T02:22:16.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Job 10 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.169518 s
[2025-05-02T02:22:16.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Registering RDD 54 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 5
[2025-05-02T02:22:16.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Got map stage job 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions
[2025-05-02T02:22:16.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Final stage: ShuffleMapStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:16.409+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
[2025-05-02T02:22:16.410+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:16.411+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[54] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:16.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 58.0 KiB, free 415.9 MiB)
[2025-05-02T02:22:16.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 25.3 KiB, free 415.9 MiB)
[2025-05-02T02:22:16.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on ***-scheduler:33063 (size: 25.3 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:16.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[54] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-02T02:22:16.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks resource profile 0
[2025-05-02T02:22:16.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 208) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10304 bytes)
[2025-05-02T02:22:16.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Running task 0.0 in stage 21.0 (TID 208)
[2025-05-02T02:22:16.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 5.078607 ms
[2025-05-02T02:22:16.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShuffleBlockFetcherIterator: Getting 1 (1919.0 B) non-empty blocks including 1 (1919.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:16.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:16.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Finished task 0.0 in stage 21.0 (TID 208). 5601 bytes result sent to driver
[2025-05-02T02:22:16.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 209) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10512 bytes)
[2025-05-02T02:22:16.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 208) in 34 ms on ***-scheduler (executor driver) (1/2)
[2025-05-02T02:22:16.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Running task 1.0 in stage 21.0 (TID 209)
[2025-05-02T02:22:16.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Finished task 1.0 in stage 21.0 (TID 209). 4827 bytes result sent to driver
[2025-05-02T02:22:16.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 209) in 12 ms on ***-scheduler (executor driver) (2/2)
[2025-05-02T02:22:16.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2025-05-02T02:22:16.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: ShuffleMapStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.057 s
[2025-05-02T02:22:16.468+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:16.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:16.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:16.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:16.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:16.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Removed broadcast_18_piece0 on ***-scheduler:33063 in memory (size: 25.3 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 22.192262 ms
[2025-05-02T02:22:16.527+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Removed broadcast_15_piece0 on ***-scheduler:33063 in memory (size: 7.7 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.533+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Removed broadcast_16_piece0 on ***-scheduler:33063 in memory (size: 25.0 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Removed broadcast_14_piece0 on ***-scheduler:33063 in memory (size: 19.6 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.543+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Removed broadcast_11_piece0 on ***-scheduler:33063 in memory (size: 155.3 KiB, free: 434.2 MiB)
[2025-05-02T02:22:16.616+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:16.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Got job 12 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:16.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Final stage: ResultStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:16.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2025-05-02T02:22:16.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:16.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[56] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:16.664+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 381.8 KiB, free 416.6 MiB)
[2025-05-02T02:22:16.667+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 139.4 KiB, free 416.5 MiB)
[2025-05-02T02:22:16.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on ***-scheduler:33063 (size: 139.4 KiB, free: 434.0 MiB)
[2025-05-02T02:22:16.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:16.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[56] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:16.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-05-02T02:22:16.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 210) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:16.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO Executor: Running task 0.0 in stage 24.0 (TID 210)
[2025-05-02T02:22:16.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShuffleBlockFetcherIterator: Getting 2 (3.3 KiB) non-empty blocks including 2 (3.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:16.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:16.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 15.802472 ms
[2025-05-02T02:22:16.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 7.162256 ms
[2025-05-02T02:22:16.781+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 17.874648 ms
[2025-05-02T02:22:16.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 8.329366 ms
[2025-05-02T02:22:16.847+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 17.422965 ms
[2025-05-02T02:22:16.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodeGenerator: Code generated in 5.305966 ms
[2025-05-02T02:22:16.864+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:22:16.869+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:22:16.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-05-02T02:22:16.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-05-02T02:22:16.909+0000] {spark_submit.py:649} INFO - {
[2025-05-02T02:22:16.910+0000] {spark_submit.py:649} INFO - "type" : "struct",
[2025-05-02T02:22:16.911+0000] {spark_submit.py:649} INFO - "fields" : [ {
[2025-05-02T02:22:16.912+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Key",
[2025-05-02T02:22:16.913+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:16.914+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:16.915+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:16.916+0000] {spark_submit.py:649} INFO - }, {
[2025-05-02T02:22:16.917+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Code",
[2025-05-02T02:22:16.918+0000] {spark_submit.py:649} INFO - "type" : "long",
[2025-05-02T02:22:16.919+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:16.920+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:16.920+0000] {spark_submit.py:649} INFO - }, {
[2025-05-02T02:22:16.921+0000] {spark_submit.py:649} INFO - "name" : "Allergy_System",
[2025-05-02T02:22:16.922+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:16.923+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:16.924+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:16.925+0000] {spark_submit.py:649} INFO - }, {
[2025-05-02T02:22:16.926+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Description",
[2025-05-02T02:22:16.926+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:16.927+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:16.928+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:16.929+0000] {spark_submit.py:649} INFO - } ]
[2025-05-02T02:22:16.929+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:22:16.930+0000] {spark_submit.py:649} INFO - and corresponding Parquet message type:
[2025-05-02T02:22:16.931+0000] {spark_submit.py:649} INFO - message spark_schema {
[2025-05-02T02:22:16.931+0000] {spark_submit.py:649} INFO - optional binary Allergy_Key (STRING);
[2025-05-02T02:22:16.932+0000] {spark_submit.py:649} INFO - optional int64 Allergy_Code;
[2025-05-02T02:22:16.932+0000] {spark_submit.py:649} INFO - optional binary Allergy_System (STRING);
[2025-05-02T02:22:16.933+0000] {spark_submit.py:649} INFO - optional binary Allergy_Description (STRING);
[2025-05-02T02:22:16.934+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:22:16.935+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:22:16.936+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:22:17.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO CodecPool: Got brand-new compressor [.snappy]
[2025-05-02T02:22:17.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO Executor: Finished task 0.0 in stage 24.0 (TID 210). 9835 bytes result sent to driver
[2025-05-02T02:22:17.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 210) in 881 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:17.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-05-02T02:22:17.555+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DAGScheduler: ResultStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.934 s
[2025-05-02T02:22:17.556+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:17.557+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
[2025-05-02T02:22:17.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DAGScheduler: Job 12 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.939470 s
[2025-05-02T02:22:17.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DeltaFileFormatWriter: Start to commit write Job aeceff23-ca75-447f-a754-ee4325631f6a.
[2025-05-02T02:22:17.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DeltaFileFormatWriter: Write Job aeceff23-ca75-447f-a754-ee4325631f6a committed. Elapsed time: 1 ms.
[2025-05-02T02:22:17.564+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DeltaFileFormatWriter: Finished processing stats for write job aeceff23-ca75-447f-a754-ee4325631f6a.
[2025-05-02T02:22:17.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:17.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:17 INFO DelegatingLogStore: LogStore LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore) is used for scheme s3a
[2025-05-02T02:22:18.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO DeltaLog: Loading version 0.
[2025-05-02T02:22:18.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO Snapshot: [tableId=10bea571-2cb1-4d8a-9aa1-439f178273cb] Created snapshot Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=0, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746151929961), checksumOpt=Some(VersionChecksum(Some(b7505c80-e955-4a08-8a66-b5d03c342f49),443236,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-ce72f691-2bbf-4528-b5d4-495c385509f4-c000.snappy.parquet,Map(),443236,1746151929000,false,{"numRecords":7126,"minValues":{"Allergy_Group_Key":"000574ab68a9589cb8a2dc1b07c26439","Allergy_Key":"00000000000000000000000000000000"},"maxValues":{"Allergy_Group_Key":"fffd2fd32ad5431dc6df8b048878a8d8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:22:18.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=0, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746151929961), checksumOpt=Some(VersionChecksum(Some(b7505c80-e955-4a08-8a66-b5d03c342f49),443236,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-ce72f691-2bbf-4528-b5d4-495c385509f4-c000.snappy.parquet,Map(),443236,1746151929000,false,{"numRecords":7126,"minValues":{"Allergy_Group_Key":"000574ab68a9589cb8a2dc1b07c26439","Allergy_Key":"00000000000000000000000000000000"},"maxValues":{"Allergy_Group_Key":"fffd2fd32ad5431dc6df8b048878a8d8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:22:18.779+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO MergeIntoCommand: DELTA: MERGE operation - materialize source
[2025-05-02T02:22:18.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:18.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 204.7 KiB, free 416.3 MiB)
[2025-05-02T02:22:18.933+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 416.2 MiB)
[2025-05-02T02:22:18.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on ***-scheduler:33063 (size: 35.8 KiB, free: 434.0 MiB)
[2025-05-02T02:22:18.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO SparkContext: Created broadcast 20 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:18.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:18 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1416)
[2025-05-02T02:22:19.122+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DataSourceStrategy: Pruning directories with:
[2025-05-02T02:22:19.123+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:19.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:19.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 205.0 KiB, free 416.0 MiB)
[2025-05-02T02:22:19.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 416.0 MiB)
[2025-05-02T02:22:19.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on ***-scheduler:33063 (size: 35.9 KiB, free: 434.0 MiB)
[2025-05-02T02:22:19.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO SparkContext: Created broadcast 21 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:19.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195720 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:19.191+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Registering RDD 60 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 6
[2025-05-02T02:22:19.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Got map stage job 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:19.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Final stage: ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:19.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:19.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:19.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[60] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:19.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 105.9 KiB, free 415.9 MiB)
[2025-05-02T02:22:19.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 415.9 MiB)
[2025-05-02T02:22:19.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on ***-scheduler:33063 (size: 32.7 KiB, free: 433.9 MiB)
[2025-05-02T02:22:19.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:19.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[60] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:19.199+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-05-02T02:22:19.200+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 211) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10892 bytes)
[2025-05-02T02:22:19.201+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO Executor: Running task 0.0 in stage 25.0 (TID 211)
[2025-05-02T02:22:19.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json, range: 0-1416, partition values: [0]
[2025-05-02T02:22:19.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO Executor: Finished task 0.0 in stage 25.0 (TID 211). 1841 bytes result sent to driver
[2025-05-02T02:22:19.256+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 211) in 58 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:19.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-05-02T02:22:19.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.064 s
[2025-05-02T02:22:19.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:19.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:19.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:19.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:19.318+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO BlockManagerInfo: Removed broadcast_22_piece0 on ***-scheduler:33063 in memory (size: 32.7 KiB, free: 434.0 MiB)
[2025-05-02T02:22:19.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on ***-scheduler:33063 in memory (size: 139.4 KiB, free: 434.1 MiB)
[2025-05-02T02:22:19.653+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO CodeGenerator: Code generated in 127.4176 ms
[2025-05-02T02:22:19.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO CodeGenerator: Code generated in 53.344798 ms
[2025-05-02T02:22:19.903+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:19.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Got job 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:19.906+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:19.907+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-05-02T02:22:19.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:19.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:19.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 743.2 KiB, free 415.8 MiB)
[2025-05-02T02:22:19.928+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 171.9 KiB, free 415.6 MiB)
[2025-05-02T02:22:19.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on ***-scheduler:33063 (size: 171.9 KiB, free: 433.9 MiB)
[2025-05-02T02:22:19.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:19.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 27 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:19.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO TaskSchedulerImpl: Adding task set 27.0 with 50 tasks resource profile 0
[2025-05-02T02:22:19.933+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO TaskSetManager: Starting task 11.0 in stage 27.0 (TID 212) (***-scheduler, executor driver, partition 11, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:19.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO Executor: Running task 11.0 in stage 27.0 (TID 212)
[2025-05-02T02:22:19.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:19.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.001+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_11 stored as values in memory (estimated size 514.0 B, free 415.6 MiB)
[2025-05-02T02:22:20.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_11 in memory on ***-scheduler:33063 (size: 514.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO CodeGenerator: Code generated in 122.496117 ms
[2025-05-02T02:22:20.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO CodeGenerator: Code generated in 20.233541 ms
[2025-05-02T02:22:20.176+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_11 stored as values in memory (estimated size 469.0 B, free 415.6 MiB)
[2025-05-02T02:22:20.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_11 in memory on ***-scheduler:33063 (size: 469.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.241+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO CodeGenerator: Code generated in 63.95429 ms
[2025-05-02T02:22:20.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO CodeGenerator: Code generated in 7.294872 ms
[2025-05-02T02:22:20.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 11.0 in stage 27.0 (TID 212). 5565 bytes result sent to driver
[2025-05-02T02:22:20.269+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 42.0 in stage 27.0 (TID 213) (***-scheduler, executor driver, partition 42, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 42.0 in stage 27.0 (TID 213)
[2025-05-02T02:22:20.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 11.0 in stage 27.0 (TID 212) in 338 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:20.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.293+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Removed broadcast_17_piece0 on ***-scheduler:33063 in memory (size: 1484.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on ***-scheduler:33063 in memory (size: 36.3 KiB, free: 434.0 MiB)
[2025-05-02T02:22:20.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Removed broadcast_13_piece0 on ***-scheduler:33063 in memory (size: 36.5 KiB, free: 434.0 MiB)
[2025-05-02T02:22:20.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_42 stored as values in memory (estimated size 465.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_42 in memory on ***-scheduler:33063 (size: 465.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.372+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_42 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_42 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 42.0 in stage 27.0 (TID 213). 5397 bytes result sent to driver
[2025-05-02T02:22:20.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 214) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 42.0 in stage 27.0 (TID 213) in 112 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:20.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 0.0 in stage 27.0 (TID 214)
[2025-05-02T02:22:20.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_0 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.459+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_0 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 0.0 in stage 27.0 (TID 214). 5397 bytes result sent to driver
[2025-05-02T02:22:20.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 215) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 214) in 93 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:20.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 1.0 in stage 27.0 (TID 215)
[2025-05-02T02:22:20.491+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_1 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.543+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_1 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.556+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 1.0 in stage 27.0 (TID 215). 5397 bytes result sent to driver
[2025-05-02T02:22:20.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 216) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 215) in 90 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:20.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 2.0 in stage 27.0 (TID 216)
[2025-05-02T02:22:20.586+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.587+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:20.661+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_2 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_2 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_2 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_2 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 2.0 in stage 27.0 (TID 216). 5397 bytes result sent to driver
[2025-05-02T02:22:20.678+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 217) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 3.0 in stage 27.0 (TID 217)
[2025-05-02T02:22:20.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 216) in 121 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:20.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_3 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_3 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 3.0 in stage 27.0 (TID 217). 5397 bytes result sent to driver
[2025-05-02T02:22:20.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 218) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.765+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 4.0 in stage 27.0 (TID 218)
[2025-05-02T02:22:20.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 217) in 88 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:20.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:20.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_4 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_4 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_4 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_4 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 4.0 in stage 27.0 (TID 218). 5397 bytes result sent to driver
[2025-05-02T02:22:20.866+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 219) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 218) in 104 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:20.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 5.0 in stage 27.0 (TID 219)
[2025-05-02T02:22:20.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_67_5 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_67_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_71_5 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:20.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_71_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:20.972+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 5.0 in stage 27.0 (TID 219). 5397 bytes result sent to driver
[2025-05-02T02:22:20.973+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 6.0 in stage 27.0 (TID 220) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 219) in 108 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:20.977+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 6.0 in stage 27.0 (TID 220)
[2025-05-02T02:22:20.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.065+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_6 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_6 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.077+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 6.0 in stage 27.0 (TID 220). 5397 bytes result sent to driver
[2025-05-02T02:22:21.082+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 7.0 in stage 27.0 (TID 221) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.083+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 6.0 in stage 27.0 (TID 220) in 110 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:21.084+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 7.0 in stage 27.0 (TID 221)
[2025-05-02T02:22:21.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.122+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.176+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_7 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_7 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.210+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 7.0 in stage 27.0 (TID 221). 5440 bytes result sent to driver
[2025-05-02T02:22:21.211+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 8.0 in stage 27.0 (TID 222) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.213+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 8.0 in stage 27.0 (TID 222)
[2025-05-02T02:22:21.215+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 7.0 in stage 27.0 (TID 221) in 129 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:21.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.236+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:21.293+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_8 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.295+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_8 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.308+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 8.0 in stage 27.0 (TID 222). 5397 bytes result sent to driver
[2025-05-02T02:22:21.310+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 9.0 in stage 27.0 (TID 223) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 8.0 in stage 27.0 (TID 222) in 101 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:21.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 9.0 in stage 27.0 (TID 223)
[2025-05-02T02:22:21.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.337+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_9 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.388+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_9 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.389+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 9.0 in stage 27.0 (TID 223). 5397 bytes result sent to driver
[2025-05-02T02:22:21.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 10.0 in stage 27.0 (TID 224) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 10.0 in stage 27.0 (TID 224)
[2025-05-02T02:22:21.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 9.0 in stage 27.0 (TID 223) in 84 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:21.413+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_10 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_10 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 10.0 in stage 27.0 (TID 224). 5397 bytes result sent to driver
[2025-05-02T02:22:21.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 12.0 in stage 27.0 (TID 225) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 10.0 in stage 27.0 (TID 224) in 79 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:21.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 12.0 in stage 27.0 (TID 225)
[2025-05-02T02:22:21.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_12 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.539+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.546+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_12 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.548+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 12.0 in stage 27.0 (TID 225). 5397 bytes result sent to driver
[2025-05-02T02:22:21.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 13.0 in stage 27.0 (TID 226) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 12.0 in stage 27.0 (TID 225) in 82 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:21.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 13.0 in stage 27.0 (TID 226)
[2025-05-02T02:22:21.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_13 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.644+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_13 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 13.0 in stage 27.0 (TID 226). 5397 bytes result sent to driver
[2025-05-02T02:22:21.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 14.0 in stage 27.0 (TID 227) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.650+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 14.0 in stage 27.0 (TID 227)
[2025-05-02T02:22:21.651+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 13.0 in stage 27.0 (TID 226) in 98 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:21.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:21.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_14 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.711+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_14 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 14.0 in stage 27.0 (TID 227). 5397 bytes result sent to driver
[2025-05-02T02:22:21.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 15.0 in stage 27.0 (TID 228) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 15.0 in stage 27.0 (TID 228)
[2025-05-02T02:22:21.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 14.0 in stage 27.0 (TID 227) in 76 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:21.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.743+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.781+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_15 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.782+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_15 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 15.0 in stage 27.0 (TID 228). 5397 bytes result sent to driver
[2025-05-02T02:22:21.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 16.0 in stage 27.0 (TID 229) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.800+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 15.0 in stage 27.0 (TID 228) in 76 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:21.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 16.0 in stage 27.0 (TID 229)
[2025-05-02T02:22:21.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_16 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.864+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_16 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 16.0 in stage 27.0 (TID 229). 5397 bytes result sent to driver
[2025-05-02T02:22:21.875+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 17.0 in stage 27.0 (TID 230) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.876+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 17.0 in stage 27.0 (TID 230)
[2025-05-02T02:22:21.878+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 16.0 in stage 27.0 (TID 229) in 77 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:21.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:21.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_67_17 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_67_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.937+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO MemoryStore: Block rdd_71_17 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:21.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO BlockManagerInfo: Added rdd_71_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:21.939+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Finished task 17.0 in stage 27.0 (TID 230). 5397 bytes result sent to driver
[2025-05-02T02:22:21.941+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Starting task 18.0 in stage 27.0 (TID 231) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:21.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO TaskSetManager: Finished task 17.0 in stage 27.0 (TID 230) in 67 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:21.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO Executor: Running task 18.0 in stage 27.0 (TID 231)
[2025-05-02T02:22:21.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:21.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.011+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_18 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_18 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 18.0 in stage 27.0 (TID 231). 5440 bytes result sent to driver
[2025-05-02T02:22:22.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 19.0 in stage 27.0 (TID 232) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 19.0 in stage 27.0 (TID 232)
[2025-05-02T02:22:22.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 18.0 in stage 27.0 (TID 231) in 87 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:22.046+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.047+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.084+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_19 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_19 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.095+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 19.0 in stage 27.0 (TID 232). 5397 bytes result sent to driver
[2025-05-02T02:22:22.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 20.0 in stage 27.0 (TID 233) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 20.0 in stage 27.0 (TID 233)
[2025-05-02T02:22:22.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 19.0 in stage 27.0 (TID 232) in 72 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:22.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.183+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_20 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.184+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_20 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 20.0 in stage 27.0 (TID 233). 5397 bytes result sent to driver
[2025-05-02T02:22:22.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 21.0 in stage 27.0 (TID 234) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 21.0 in stage 27.0 (TID 234)
[2025-05-02T02:22:22.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 20.0 in stage 27.0 (TID 233) in 99 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:22.212+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.213+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_21 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_21 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.256+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 21.0 in stage 27.0 (TID 234). 5397 bytes result sent to driver
[2025-05-02T02:22:22.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 22.0 in stage 27.0 (TID 235) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 21.0 in stage 27.0 (TID 234) in 63 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:22.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 22.0 in stage 27.0 (TID 235)
[2025-05-02T02:22:22.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.274+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_22 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.308+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_22 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.315+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.317+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 22.0 in stage 27.0 (TID 235). 5397 bytes result sent to driver
[2025-05-02T02:22:22.318+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 23.0 in stage 27.0 (TID 236) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.319+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 23.0 in stage 27.0 (TID 236)
[2025-05-02T02:22:22.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 22.0 in stage 27.0 (TID 235) in 62 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:22.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_23 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_23 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.378+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 23.0 in stage 27.0 (TID 236). 5397 bytes result sent to driver
[2025-05-02T02:22:22.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 24.0 in stage 27.0 (TID 237) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 23.0 in stage 27.0 (TID 236) in 63 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:22.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 24.0 in stage 27.0 (TID 237)
[2025-05-02T02:22:22.396+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.397+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_24 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_24 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 24.0 in stage 27.0 (TID 237). 5397 bytes result sent to driver
[2025-05-02T02:22:22.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 25.0 in stage 27.0 (TID 238) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 25.0 in stage 27.0 (TID 238)
[2025-05-02T02:22:22.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 24.0 in stage 27.0 (TID 237) in 62 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:22.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_25 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.488+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.496+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_25 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.497+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 25.0 in stage 27.0 (TID 238). 5397 bytes result sent to driver
[2025-05-02T02:22:22.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 26.0 in stage 27.0 (TID 239) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 26.0 in stage 27.0 (TID 239)
[2025-05-02T02:22:22.502+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 25.0 in stage 27.0 (TID 238) in 61 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:22.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_26 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_26 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 26.0 in stage 27.0 (TID 239). 5440 bytes result sent to driver
[2025-05-02T02:22:22.565+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 27.0 in stage 27.0 (TID 240) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 27.0 in stage 27.0 (TID 240)
[2025-05-02T02:22:22.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 26.0 in stage 27.0 (TID 239) in 65 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:22.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_27 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_27 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.634+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 27.0 in stage 27.0 (TID 240). 5440 bytes result sent to driver
[2025-05-02T02:22:22.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 28.0 in stage 27.0 (TID 241) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 28.0 in stage 27.0 (TID 241)
[2025-05-02T02:22:22.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 27.0 in stage 27.0 (TID 240) in 72 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:22.651+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_28 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.691+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_28 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.692+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.694+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 28.0 in stage 27.0 (TID 241). 5397 bytes result sent to driver
[2025-05-02T02:22:22.695+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 29.0 in stage 27.0 (TID 242) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 28.0 in stage 27.0 (TID 241) in 60 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:22.697+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 29.0 in stage 27.0 (TID 242)
[2025-05-02T02:22:22.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_29 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.743+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_29 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 29.0 in stage 27.0 (TID 242). 5397 bytes result sent to driver
[2025-05-02T02:22:22.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 30.0 in stage 27.0 (TID 243) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 30.0 in stage 27.0 (TID 243)
[2025-05-02T02:22:22.754+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 29.0 in stage 27.0 (TID 242) in 58 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:22.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_30 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_30 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.811+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.813+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 30.0 in stage 27.0 (TID 243). 5397 bytes result sent to driver
[2025-05-02T02:22:22.814+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 31.0 in stage 27.0 (TID 244) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.815+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 30.0 in stage 27.0 (TID 243) in 62 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:22.816+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 31.0 in stage 27.0 (TID 244)
[2025-05-02T02:22:22.828+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_31 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_31 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.869+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 31.0 in stage 27.0 (TID 244). 5397 bytes result sent to driver
[2025-05-02T02:22:22.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 32.0 in stage 27.0 (TID 245) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.873+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 32.0 in stage 27.0 (TID 245)
[2025-05-02T02:22:22.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 31.0 in stage 27.0 (TID 244) in 59 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:22.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_32 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_32 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.927+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.928+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 32.0 in stage 27.0 (TID 245). 5397 bytes result sent to driver
[2025-05-02T02:22:22.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 33.0 in stage 27.0 (TID 246) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 33.0 in stage 27.0 (TID 246)
[2025-05-02T02:22:22.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 32.0 in stage 27.0 (TID 245) in 58 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:22.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:22.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:22.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_67_33 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_67_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO MemoryStore: Block rdd_71_33 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:22.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO BlockManagerInfo: Added rdd_71_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:22.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Finished task 33.0 in stage 27.0 (TID 246). 5397 bytes result sent to driver
[2025-05-02T02:22:22.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Starting task 34.0 in stage 27.0 (TID 247) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:22.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO Executor: Running task 34.0 in stage 27.0 (TID 247)
[2025-05-02T02:22:22.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO TaskSetManager: Finished task 33.0 in stage 27.0 (TID 246) in 57 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:22.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_34 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.030+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.035+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_34 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 34.0 in stage 27.0 (TID 247). 5397 bytes result sent to driver
[2025-05-02T02:22:23.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 35.0 in stage 27.0 (TID 248) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.039+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 34.0 in stage 27.0 (TID 247) in 53 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:23.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 35.0 in stage 27.0 (TID 248)
[2025-05-02T02:22:23.052+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.053+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.084+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_35 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.084+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.092+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_35 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 35.0 in stage 27.0 (TID 248). 5397 bytes result sent to driver
[2025-05-02T02:22:23.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 36.0 in stage 27.0 (TID 249) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 36.0 in stage 27.0 (TID 249)
[2025-05-02T02:22:23.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 35.0 in stage 27.0 (TID 248) in 59 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:23.113+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.113+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_36 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.165+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_36 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 36.0 in stage 27.0 (TID 249). 5440 bytes result sent to driver
[2025-05-02T02:22:23.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 37.0 in stage 27.0 (TID 250) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 36.0 in stage 27.0 (TID 249) in 74 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:23.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 37.0 in stage 27.0 (TID 250)
[2025-05-02T02:22:23.185+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_37 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_37 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 37.0 in stage 27.0 (TID 250). 5397 bytes result sent to driver
[2025-05-02T02:22:23.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 38.0 in stage 27.0 (TID 251) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 38.0 in stage 27.0 (TID 251)
[2025-05-02T02:22:23.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 37.0 in stage 27.0 (TID 250) in 79 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:23.264+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_38 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.315+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_38 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 38.0 in stage 27.0 (TID 251). 5397 bytes result sent to driver
[2025-05-02T02:22:23.325+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 39.0 in stage 27.0 (TID 252) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.326+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 39.0 in stage 27.0 (TID 252)
[2025-05-02T02:22:23.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 38.0 in stage 27.0 (TID 251) in 79 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:23.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_39 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.398+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_39 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.401+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 39.0 in stage 27.0 (TID 252). 5397 bytes result sent to driver
[2025-05-02T02:22:23.402+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 40.0 in stage 27.0 (TID 253) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 39.0 in stage 27.0 (TID 252) in 78 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:23.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 40.0 in stage 27.0 (TID 253)
[2025-05-02T02:22:23.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_40 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_40 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 40.0 in stage 27.0 (TID 253). 5397 bytes result sent to driver
[2025-05-02T02:22:23.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 41.0 in stage 27.0 (TID 254) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.468+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 41.0 in stage 27.0 (TID 254)
[2025-05-02T02:22:23.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 40.0 in stage 27.0 (TID 253) in 66 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:23.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_41 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.521+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_41 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.524+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 41.0 in stage 27.0 (TID 254). 5397 bytes result sent to driver
[2025-05-02T02:22:23.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 43.0 in stage 27.0 (TID 255) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.526+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 41.0 in stage 27.0 (TID 254) in 58 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:23.527+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 43.0 in stage 27.0 (TID 255)
[2025-05-02T02:22:23.539+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.541+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_43 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_43 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 43.0 in stage 27.0 (TID 255). 5397 bytes result sent to driver
[2025-05-02T02:22:23.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 44.0 in stage 27.0 (TID 256) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 44.0 in stage 27.0 (TID 256)
[2025-05-02T02:22:23.585+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 43.0 in stage 27.0 (TID 255) in 59 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:23.597+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.598+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_44 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.630+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_44 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 44.0 in stage 27.0 (TID 256). 5397 bytes result sent to driver
[2025-05-02T02:22:23.639+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 45.0 in stage 27.0 (TID 257) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.640+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 45.0 in stage 27.0 (TID 257)
[2025-05-02T02:22:23.641+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 44.0 in stage 27.0 (TID 256) in 58 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:23.659+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.691+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_45 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.692+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_45 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 45.0 in stage 27.0 (TID 257). 5397 bytes result sent to driver
[2025-05-02T02:22:23.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 46.0 in stage 27.0 (TID 258) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 46.0 in stage 27.0 (TID 258)
[2025-05-02T02:22:23.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 45.0 in stage 27.0 (TID 257) in 63 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:23.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_46 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_46 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.758+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 46.0 in stage 27.0 (TID 258). 5397 bytes result sent to driver
[2025-05-02T02:22:23.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 47.0 in stage 27.0 (TID 259) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 46.0 in stage 27.0 (TID 258) in 60 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:23.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 47.0 in stage 27.0 (TID 259)
[2025-05-02T02:22:23.779+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.817+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_47 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_47 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.828+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 47.0 in stage 27.0 (TID 259). 5440 bytes result sent to driver
[2025-05-02T02:22:23.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 48.0 in stage 27.0 (TID 260) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.830+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 48.0 in stage 27.0 (TID 260)
[2025-05-02T02:22:23.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 47.0 in stage 27.0 (TID 259) in 69 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:23.844+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.845+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_48 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.875+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_48 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 48.0 in stage 27.0 (TID 260). 5397 bytes result sent to driver
[2025-05-02T02:22:23.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Starting task 49.0 in stage 27.0 (TID 261) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:23.891+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Running task 49.0 in stage 27.0 (TID 261)
[2025-05-02T02:22:23.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 48.0 in stage 27.0 (TID 260) in 63 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:23.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:23.906+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:23.937+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_67_49 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_67_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO MemoryStore: Block rdd_71_49 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:23.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO BlockManagerInfo: Added rdd_71_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:23.946+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO Executor: Finished task 49.0 in stage 27.0 (TID 261). 5397 bytes result sent to driver
[2025-05-02T02:22:23.947+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSetManager: Finished task 49.0 in stage 27.0 (TID 261) in 63 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:23.948+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-02T02:22:23.948+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO DAGScheduler: ResultStage 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 4.032 s
[2025-05-02T02:22:23.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:23.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-05-02T02:22:23.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO DAGScheduler: Job 14 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 4.044449 s
[2025-05-02T02:22:23.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:23 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:24.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:24.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO CodeGenerator: Code generated in 38.545993 ms
[2025-05-02T02:22:24.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:24.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO DAGScheduler: Got job 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:24.369+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:24.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-05-02T02:22:24.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:24.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[79] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:24.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 740.5 KiB, free 431.4 MiB)
[2025-05-02T02:22:24.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 169.4 KiB, free 431.2 MiB)
[2025-05-02T02:22:24.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on ***-scheduler:33063 (size: 169.4 KiB, free: 433.8 MiB)
[2025-05-02T02:22:24.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:24.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 29 (MapPartitionsRDD[79] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:24.386+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSchedulerImpl: Adding task set 29.0 with 50 tasks resource profile 0
[2025-05-02T02:22:24.387+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 262) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.388+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 0.0 in stage 29.0 (TID 262)
[2025-05-02T02:22:24.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_0 locally
[2025-05-02T02:22:24.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO CodeGenerator: Code generated in 17.991562 ms
[2025-05-02T02:22:24.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_0 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO CodeGenerator: Code generated in 33.01374 ms
[2025-05-02T02:22:24.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 0.0 in stage 29.0 (TID 262). 4666 bytes result sent to driver
[2025-05-02T02:22:24.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 263) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 262) in 79 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:24.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 1.0 in stage 29.0 (TID 263)
[2025-05-02T02:22:24.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_1 locally
[2025-05-02T02:22:24.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_1 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 1.0 in stage 29.0 (TID 263). 4666 bytes result sent to driver
[2025-05-02T02:22:24.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 264) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.488+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 263) in 23 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:24.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 2.0 in stage 29.0 (TID 264)
[2025-05-02T02:22:24.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_2 locally
[2025-05-02T02:22:24.506+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_2 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_2 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 2.0 in stage 29.0 (TID 264). 4666 bytes result sent to driver
[2025-05-02T02:22:24.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 265) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 264) in 24 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:24.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 3.0 in stage 29.0 (TID 265)
[2025-05-02T02:22:24.527+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_3 locally
[2025-05-02T02:22:24.533+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_3 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 3.0 in stage 29.0 (TID 265). 4666 bytes result sent to driver
[2025-05-02T02:22:24.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 266) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 265) in 28 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:24.539+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 4.0 in stage 29.0 (TID 266)
[2025-05-02T02:22:24.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_4 locally
[2025-05-02T02:22:24.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_4 stored as values in memory (estimated size 892.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_4 in memory on ***-scheduler:33063 (size: 892.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.577+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 4.0 in stage 29.0 (TID 266). 4834 bytes result sent to driver
[2025-05-02T02:22:24.578+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 267) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 266) in 43 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:24.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 5.0 in stage 29.0 (TID 267)
[2025-05-02T02:22:24.595+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_5 locally
[2025-05-02T02:22:24.602+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_5 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.603+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.605+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 5.0 in stage 29.0 (TID 267). 4666 bytes result sent to driver
[2025-05-02T02:22:24.605+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 268) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 267) in 28 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:24.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 6.0 in stage 29.0 (TID 268)
[2025-05-02T02:22:24.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_6 locally
[2025-05-02T02:22:24.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_6 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.630+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 6.0 in stage 29.0 (TID 268). 4666 bytes result sent to driver
[2025-05-02T02:22:24.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 269) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.634+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 7.0 in stage 29.0 (TID 269)
[2025-05-02T02:22:24.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 268) in 28 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:24.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_7 locally
[2025-05-02T02:22:24.651+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_7 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.653+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 7.0 in stage 29.0 (TID 269). 4666 bytes result sent to driver
[2025-05-02T02:22:24.655+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 270) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 8.0 in stage 29.0 (TID 270)
[2025-05-02T02:22:24.657+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 269) in 23 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:24.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_8 locally
[2025-05-02T02:22:24.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_8 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 8.0 in stage 29.0 (TID 270). 4666 bytes result sent to driver
[2025-05-02T02:22:24.678+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 271) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.679+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 270) in 24 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:24.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 9.0 in stage 29.0 (TID 271)
[2025-05-02T02:22:24.691+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_9 locally
[2025-05-02T02:22:24.697+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_9 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.700+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 9.0 in stage 29.0 (TID 271). 4666 bytes result sent to driver
[2025-05-02T02:22:24.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 272) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 271) in 24 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:24.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 10.0 in stage 29.0 (TID 272)
[2025-05-02T02:22:24.713+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_10 locally
[2025-05-02T02:22:24.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_10 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 10.0 in stage 29.0 (TID 272). 4666 bytes result sent to driver
[2025-05-02T02:22:24.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 11.0 in stage 29.0 (TID 273) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 11.0 in stage 29.0 (TID 273)
[2025-05-02T02:22:24.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 272) in 23 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:24.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_11 locally
[2025-05-02T02:22:24.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_11 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.743+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_11 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.758+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 11.0 in stage 29.0 (TID 273). 4752 bytes result sent to driver
[2025-05-02T02:22:24.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 12.0 in stage 29.0 (TID 274) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 12.0 in stage 29.0 (TID 274)
[2025-05-02T02:22:24.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 11.0 in stage 29.0 (TID 273) in 36 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:24.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_12 locally
[2025-05-02T02:22:24.787+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_12 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.788+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 12.0 in stage 29.0 (TID 274). 4666 bytes result sent to driver
[2025-05-02T02:22:24.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 13.0 in stage 29.0 (TID 275) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 13.0 in stage 29.0 (TID 275)
[2025-05-02T02:22:24.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 12.0 in stage 29.0 (TID 274) in 34 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:24.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_13 locally
[2025-05-02T02:22:24.820+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_13 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.822+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 13.0 in stage 29.0 (TID 275). 4666 bytes result sent to driver
[2025-05-02T02:22:24.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 14.0 in stage 29.0 (TID 276) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 14.0 in stage 29.0 (TID 276)
[2025-05-02T02:22:24.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 13.0 in stage 29.0 (TID 275) in 33 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:24.841+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_14 locally
[2025-05-02T02:22:24.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_14 stored as values in memory (estimated size 46.0 B, free 431.2 MiB)
[2025-05-02T02:22:24.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.8 MiB)
[2025-05-02T02:22:24.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 14.0 in stage 29.0 (TID 276). 4666 bytes result sent to driver
[2025-05-02T02:22:24.853+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 15.0 in stage 29.0 (TID 277) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.854+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 14.0 in stage 29.0 (TID 276) in 31 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:24.855+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 15.0 in stage 29.0 (TID 277)
[2025-05-02T02:22:24.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_15 locally
[2025-05-02T02:22:24.889+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Removed broadcast_23_piece0 on ***-scheduler:33063 in memory (size: 171.9 KiB, free: 434.0 MiB)
[2025-05-02T02:22:24.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_15 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:24.891+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:24.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 15.0 in stage 29.0 (TID 277). 4666 bytes result sent to driver
[2025-05-02T02:22:24.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 16.0 in stage 29.0 (TID 278) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 15.0 in stage 29.0 (TID 277) in 41 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:24.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 16.0 in stage 29.0 (TID 278)
[2025-05-02T02:22:24.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_16 locally
[2025-05-02T02:22:24.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_16 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:24.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:24.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 16.0 in stage 29.0 (TID 278). 4666 bytes result sent to driver
[2025-05-02T02:22:24.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 17.0 in stage 29.0 (TID 279) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 17.0 in stage 29.0 (TID 279)
[2025-05-02T02:22:24.921+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 16.0 in stage 29.0 (TID 278) in 26 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:24.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_17 locally
[2025-05-02T02:22:24.939+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_17 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:24.940+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:24.941+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 17.0 in stage 29.0 (TID 279). 4666 bytes result sent to driver
[2025-05-02T02:22:24.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 18.0 in stage 29.0 (TID 280) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 17.0 in stage 29.0 (TID 279) in 25 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:24.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 18.0 in stage 29.0 (TID 280)
[2025-05-02T02:22:24.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_18 locally
[2025-05-02T02:22:24.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_18 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:24.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:24.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 18.0 in stage 29.0 (TID 280). 4666 bytes result sent to driver
[2025-05-02T02:22:24.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 19.0 in stage 29.0 (TID 281) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.970+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 19.0 in stage 29.0 (TID 281)
[2025-05-02T02:22:24.971+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 18.0 in stage 29.0 (TID 280) in 28 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:24.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManager: Found block rdd_29_19 locally
[2025-05-02T02:22:24.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO MemoryStore: Block rdd_77_19 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:24.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO BlockManagerInfo: Added rdd_77_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:24.992+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Finished task 19.0 in stage 29.0 (TID 281). 4666 bytes result sent to driver
[2025-05-02T02:22:24.993+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Starting task 20.0 in stage 29.0 (TID 282) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:24.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO Executor: Running task 20.0 in stage 29.0 (TID 282)
[2025-05-02T02:22:24.995+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:24 INFO TaskSetManager: Finished task 19.0 in stage 29.0 (TID 281) in 25 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:25.006+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_20 locally
[2025-05-02T02:22:25.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_20 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 20.0 in stage 29.0 (TID 282). 4666 bytes result sent to driver
[2025-05-02T02:22:25.016+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 21.0 in stage 29.0 (TID 283) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.017+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 21.0 in stage 29.0 (TID 283)
[2025-05-02T02:22:25.018+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 20.0 in stage 29.0 (TID 282) in 23 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:25.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_21 locally
[2025-05-02T02:22:25.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_21 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 21.0 in stage 29.0 (TID 283). 4666 bytes result sent to driver
[2025-05-02T02:22:25.039+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 22.0 in stage 29.0 (TID 284) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 21.0 in stage 29.0 (TID 283) in 24 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:25.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 22.0 in stage 29.0 (TID 284)
[2025-05-02T02:22:25.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_22 locally
[2025-05-02T02:22:25.064+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_22 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.065+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.066+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 22.0 in stage 29.0 (TID 284). 4666 bytes result sent to driver
[2025-05-02T02:22:25.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 23.0 in stage 29.0 (TID 285) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 23.0 in stage 29.0 (TID 285)
[2025-05-02T02:22:25.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 22.0 in stage 29.0 (TID 284) in 29 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:25.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_23 locally
[2025-05-02T02:22:25.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_23 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 23.0 in stage 29.0 (TID 285). 4666 bytes result sent to driver
[2025-05-02T02:22:25.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 24.0 in stage 29.0 (TID 286) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 23.0 in stage 29.0 (TID 285) in 32 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:25.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 24.0 in stage 29.0 (TID 286)
[2025-05-02T02:22:25.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_24 locally
[2025-05-02T02:22:25.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_24 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 24.0 in stage 29.0 (TID 286). 4666 bytes result sent to driver
[2025-05-02T02:22:25.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 25.0 in stage 29.0 (TID 287) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 24.0 in stage 29.0 (TID 286) in 30 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:25.129+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 25.0 in stage 29.0 (TID 287)
[2025-05-02T02:22:25.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_25 locally
[2025-05-02T02:22:25.148+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_25 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.150+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.151+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 25.0 in stage 29.0 (TID 287). 4666 bytes result sent to driver
[2025-05-02T02:22:25.152+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 26.0 in stage 29.0 (TID 288) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.153+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 25.0 in stage 29.0 (TID 287) in 25 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:25.154+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 26.0 in stage 29.0 (TID 288)
[2025-05-02T02:22:25.165+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_26 locally
[2025-05-02T02:22:25.172+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_26 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.175+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 26.0 in stage 29.0 (TID 288). 4666 bytes result sent to driver
[2025-05-02T02:22:25.175+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 27.0 in stage 29.0 (TID 289) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 27.0 in stage 29.0 (TID 289)
[2025-05-02T02:22:25.178+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 26.0 in stage 29.0 (TID 288) in 25 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:25.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_27 locally
[2025-05-02T02:22:25.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_27 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 27.0 in stage 29.0 (TID 289). 4666 bytes result sent to driver
[2025-05-02T02:22:25.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 28.0 in stage 29.0 (TID 290) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.199+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 27.0 in stage 29.0 (TID 289) in 23 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:25.200+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 28.0 in stage 29.0 (TID 290)
[2025-05-02T02:22:25.215+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_28 locally
[2025-05-02T02:22:25.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_28 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.224+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 28.0 in stage 29.0 (TID 290). 4666 bytes result sent to driver
[2025-05-02T02:22:25.225+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 29.0 in stage 29.0 (TID 291) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 28.0 in stage 29.0 (TID 290) in 27 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:25.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 29.0 in stage 29.0 (TID 291)
[2025-05-02T02:22:25.238+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_29 locally
[2025-05-02T02:22:25.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_29 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 29.0 in stage 29.0 (TID 291). 4666 bytes result sent to driver
[2025-05-02T02:22:25.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 30.0 in stage 29.0 (TID 292) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 30.0 in stage 29.0 (TID 292)
[2025-05-02T02:22:25.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 29.0 in stage 29.0 (TID 291) in 23 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:25.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_30 locally
[2025-05-02T02:22:25.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_30 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 30.0 in stage 29.0 (TID 292). 4666 bytes result sent to driver
[2025-05-02T02:22:25.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 31.0 in stage 29.0 (TID 293) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.272+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 31.0 in stage 29.0 (TID 293)
[2025-05-02T02:22:25.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 30.0 in stage 29.0 (TID 292) in 23 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:25.283+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_31 locally
[2025-05-02T02:22:25.290+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_31 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.291+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 31.0 in stage 29.0 (TID 293). 4666 bytes result sent to driver
[2025-05-02T02:22:25.294+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 32.0 in stage 29.0 (TID 294) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.295+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 32.0 in stage 29.0 (TID 294)
[2025-05-02T02:22:25.295+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 31.0 in stage 29.0 (TID 293) in 24 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:25.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_32 locally
[2025-05-02T02:22:25.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_32 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 32.0 in stage 29.0 (TID 294). 4666 bytes result sent to driver
[2025-05-02T02:22:25.315+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 33.0 in stage 29.0 (TID 295) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 32.0 in stage 29.0 (TID 294) in 23 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:25.317+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 33.0 in stage 29.0 (TID 295)
[2025-05-02T02:22:25.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_33 locally
[2025-05-02T02:22:25.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_33 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.335+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 33.0 in stage 29.0 (TID 295). 4666 bytes result sent to driver
[2025-05-02T02:22:25.337+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 34.0 in stage 29.0 (TID 296) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.338+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 34.0 in stage 29.0 (TID 296)
[2025-05-02T02:22:25.339+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 33.0 in stage 29.0 (TID 295) in 23 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:25.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_34 locally
[2025-05-02T02:22:25.356+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_34 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.358+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 34.0 in stage 29.0 (TID 296). 4666 bytes result sent to driver
[2025-05-02T02:22:25.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 35.0 in stage 29.0 (TID 297) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 35.0 in stage 29.0 (TID 297)
[2025-05-02T02:22:25.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 34.0 in stage 29.0 (TID 296) in 22 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:25.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_35 locally
[2025-05-02T02:22:25.388+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_35 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.389+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.390+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 35.0 in stage 29.0 (TID 297). 4709 bytes result sent to driver
[2025-05-02T02:22:25.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 36.0 in stage 29.0 (TID 298) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 36.0 in stage 29.0 (TID 298)
[2025-05-02T02:22:25.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 35.0 in stage 29.0 (TID 297) in 32 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:25.409+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_36 locally
[2025-05-02T02:22:25.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_36 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 36.0 in stage 29.0 (TID 298). 4666 bytes result sent to driver
[2025-05-02T02:22:25.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 37.0 in stage 29.0 (TID 299) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 36.0 in stage 29.0 (TID 298) in 29 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:25.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 37.0 in stage 29.0 (TID 299)
[2025-05-02T02:22:25.432+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_37 locally
[2025-05-02T02:22:25.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_37 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 37.0 in stage 29.0 (TID 299). 4666 bytes result sent to driver
[2025-05-02T02:22:25.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 38.0 in stage 29.0 (TID 300) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.443+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 37.0 in stage 29.0 (TID 299) in 25 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:25.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 38.0 in stage 29.0 (TID 300)
[2025-05-02T02:22:25.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_38 locally
[2025-05-02T02:22:25.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_38 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 38.0 in stage 29.0 (TID 300). 4709 bytes result sent to driver
[2025-05-02T02:22:25.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 39.0 in stage 29.0 (TID 301) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 38.0 in stage 29.0 (TID 300) in 35 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:25.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 39.0 in stage 29.0 (TID 301)
[2025-05-02T02:22:25.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_39 locally
[2025-05-02T02:22:25.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_39 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.502+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.504+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 39.0 in stage 29.0 (TID 301). 4666 bytes result sent to driver
[2025-05-02T02:22:25.505+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 40.0 in stage 29.0 (TID 302) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.505+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 39.0 in stage 29.0 (TID 301) in 29 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:25.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 40.0 in stage 29.0 (TID 302)
[2025-05-02T02:22:25.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_40 locally
[2025-05-02T02:22:25.529+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_40 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.531+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 40.0 in stage 29.0 (TID 302). 4666 bytes result sent to driver
[2025-05-02T02:22:25.533+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 41.0 in stage 29.0 (TID 303) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.534+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 40.0 in stage 29.0 (TID 302) in 29 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:25.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 41.0 in stage 29.0 (TID 303)
[2025-05-02T02:22:25.546+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_41 locally
[2025-05-02T02:22:25.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_41 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.556+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 41.0 in stage 29.0 (TID 303). 4666 bytes result sent to driver
[2025-05-02T02:22:25.557+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 42.0 in stage 29.0 (TID 304) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 42.0 in stage 29.0 (TID 304)
[2025-05-02T02:22:25.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 41.0 in stage 29.0 (TID 303) in 25 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:25.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_42 locally
[2025-05-02T02:22:25.577+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_42 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.578+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_42 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 42.0 in stage 29.0 (TID 304). 4709 bytes result sent to driver
[2025-05-02T02:22:25.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 43.0 in stage 29.0 (TID 305) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 43.0 in stage 29.0 (TID 305)
[2025-05-02T02:22:25.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 42.0 in stage 29.0 (TID 304) in 25 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:25.594+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_43 locally
[2025-05-02T02:22:25.600+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_43 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.602+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.603+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 43.0 in stage 29.0 (TID 305). 4666 bytes result sent to driver
[2025-05-02T02:22:25.604+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 44.0 in stage 29.0 (TID 306) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.605+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 44.0 in stage 29.0 (TID 306)
[2025-05-02T02:22:25.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 43.0 in stage 29.0 (TID 305) in 24 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:25.617+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_44 locally
[2025-05-02T02:22:25.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_44 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.626+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 44.0 in stage 29.0 (TID 306). 4666 bytes result sent to driver
[2025-05-02T02:22:25.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 45.0 in stage 29.0 (TID 307) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 45.0 in stage 29.0 (TID 307)
[2025-05-02T02:22:25.628+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 44.0 in stage 29.0 (TID 306) in 24 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:25.640+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_45 locally
[2025-05-02T02:22:25.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_45 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 45.0 in stage 29.0 (TID 307). 4666 bytes result sent to driver
[2025-05-02T02:22:25.650+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 46.0 in stage 29.0 (TID 308) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.651+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 46.0 in stage 29.0 (TID 308)
[2025-05-02T02:22:25.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 45.0 in stage 29.0 (TID 307) in 24 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:25.663+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_46 locally
[2025-05-02T02:22:25.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_46 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 46.0 in stage 29.0 (TID 308). 4666 bytes result sent to driver
[2025-05-02T02:22:25.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 47.0 in stage 29.0 (TID 309) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 47.0 in stage 29.0 (TID 309)
[2025-05-02T02:22:25.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 46.0 in stage 29.0 (TID 308) in 25 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:25.687+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_47 locally
[2025-05-02T02:22:25.694+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_47 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.695+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 47.0 in stage 29.0 (TID 309). 4666 bytes result sent to driver
[2025-05-02T02:22:25.697+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 48.0 in stage 29.0 (TID 310) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 48.0 in stage 29.0 (TID 310)
[2025-05-02T02:22:25.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 47.0 in stage 29.0 (TID 309) in 25 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:25.711+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_48 locally
[2025-05-02T02:22:25.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_48 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 48.0 in stage 29.0 (TID 310). 4666 bytes result sent to driver
[2025-05-02T02:22:25.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Starting task 49.0 in stage 29.0 (TID 311) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:25.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Running task 49.0 in stage 29.0 (TID 311)
[2025-05-02T02:22:25.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 48.0 in stage 29.0 (TID 310) in 27 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:25.741+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManager: Found block rdd_29_49 locally
[2025-05-02T02:22:25.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block rdd_77_49 stored as values in memory (estimated size 46.0 B, free 432.1 MiB)
[2025-05-02T02:22:25.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added rdd_77_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 434.0 MiB)
[2025-05-02T02:22:25.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO Executor: Finished task 49.0 in stage 29.0 (TID 311). 4666 bytes result sent to driver
[2025-05-02T02:22:25.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSetManager: Finished task 49.0 in stage 29.0 (TID 311) in 28 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:25.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-05-02T02:22:25.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO DAGScheduler: ResultStage 29 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.380 s
[2025-05-02T02:22:25.754+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:25.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
[2025-05-02T02:22:25.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO DAGScheduler: Job 15 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.386267 s
[2025-05-02T02:22:25.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:25.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:25.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 204.7 KiB, free 431.9 MiB)
[2025-05-02T02:22:25.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 431.9 MiB)
[2025-05-02T02:22:25.906+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on ***-scheduler:33063 (size: 35.8 KiB, free: 434.0 MiB)
[2025-05-02T02:22:25.907+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO SparkContext: Created broadcast 25 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:25.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:25 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3809)
[2025-05-02T02:22:26.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DataSourceStrategy: Pruning directories with:
[2025-05-02T02:22:26.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:26.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:26.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 205.0 KiB, free 431.7 MiB)
[2025-05-02T02:22:26.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 431.6 MiB)
[2025-05-02T02:22:26.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on ***-scheduler:33063 (size: 35.9 KiB, free: 433.9 MiB)
[2025-05-02T02:22:26.159+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO SparkContext: Created broadcast 26 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:26.160+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4198113 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:26.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Registering RDD 83 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 7
[2025-05-02T02:22:26.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Got map stage job 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:26.172+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Final stage: ShuffleMapStage 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:26.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:26.174+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:26.175+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[83] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:26.175+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 105.9 KiB, free 431.5 MiB)
[2025-05-02T02:22:26.176+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 431.5 MiB)
[2025-05-02T02:22:26.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on ***-scheduler:33063 (size: 32.6 KiB, free: 433.9 MiB)
[2025-05-02T02:22:26.178+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:26.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[83] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:26.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-05-02T02:22:26.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 312) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10892 bytes)
[2025-05-02T02:22:26.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Running task 0.0 in stage 30.0 (TID 312)
[2025-05-02T02:22:26.186+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/_delta_log/00000000000000000000.json, range: 0-3809, partition values: [0]
[2025-05-02T02:22:26.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Finished task 0.0 in stage 30.0 (TID 312). 1841 bytes result sent to driver
[2025-05-02T02:22:26.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 312) in 68 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:26.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-05-02T02:22:26.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: ShuffleMapStage 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.076 s
[2025-05-02T02:22:26.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:26.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:26.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:26.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:26.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Removed broadcast_27_piece0 on ***-scheduler:33063 in memory (size: 32.6 KiB, free: 433.9 MiB)
[2025-05-02T02:22:26.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Removed broadcast_24_piece0 on ***-scheduler:33063 in memory (size: 169.4 KiB, free: 434.1 MiB)
[2025-05-02T02:22:26.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO CodeGenerator: Code generated in 43.251423 ms
[2025-05-02T02:22:26.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:26.754+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Got job 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:26.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Final stage: ResultStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:26.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-05-02T02:22:26.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:26.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[96] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:26.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 740.5 KiB, free 431.8 MiB)
[2025-05-02T02:22:26.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 169.4 KiB, free 431.6 MiB)
[2025-05-02T02:22:26.770+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on ***-scheduler:33063 (size: 169.4 KiB, free: 433.9 MiB)
[2025-05-02T02:22:26.771+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:26.772+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 32 (MapPartitionsRDD[96] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:26.773+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSchedulerImpl: Adding task set 32.0 with 50 tasks resource profile 0
[2025-05-02T02:22:26.774+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 313) (***-scheduler, executor driver, partition 2, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:26.775+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Running task 2.0 in stage 32.0 (TID 313)
[2025-05-02T02:22:26.787+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO ShuffleBlockFetcherIterator: Getting 1 (1271.0 B) non-empty blocks including 1 (1271.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:26.788+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:26.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block rdd_90_2 stored as values in memory (estimated size 1340.0 B, free 431.6 MiB)
[2025-05-02T02:22:26.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added rdd_90_2 in memory on ***-scheduler:33063 (size: 1340.0 B, free: 433.9 MiB)
[2025-05-02T02:22:26.848+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO CodeGenerator: Code generated in 19.082066 ms
[2025-05-02T02:22:26.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block rdd_94_2 stored as values in memory (estimated size 1041.0 B, free 431.6 MiB)
[2025-05-02T02:22:26.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added rdd_94_2 in memory on ***-scheduler:33063 (size: 1041.0 B, free: 433.9 MiB)
[2025-05-02T02:22:26.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO CodeGenerator: Code generated in 34.039379 ms
[2025-05-02T02:22:26.906+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Finished task 2.0 in stage 32.0 (TID 313). 5522 bytes result sent to driver
[2025-05-02T02:22:26.907+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Starting task 42.0 in stage 32.0 (TID 314) (***-scheduler, executor driver, partition 42, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:26.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Running task 42.0 in stage 32.0 (TID 314)
[2025-05-02T02:22:26.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 313) in 135 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:26.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO ShuffleBlockFetcherIterator: Getting 1 (1051.0 B) non-empty blocks including 1 (1051.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:26.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:26.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block rdd_90_42 stored as values in memory (estimated size 666.0 B, free 431.6 MiB)
[2025-05-02T02:22:26.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added rdd_90_42 in memory on ***-scheduler:33063 (size: 666.0 B, free: 433.9 MiB)
[2025-05-02T02:22:26.963+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO MemoryStore: Block rdd_94_42 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:26.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO BlockManagerInfo: Added rdd_94_42 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:26.965+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Finished task 42.0 in stage 32.0 (TID 314). 5397 bytes result sent to driver
[2025-05-02T02:22:26.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 315) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:26.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO Executor: Running task 0.0 in stage 32.0 (TID 315)
[2025-05-02T02:22:26.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO TaskSetManager: Finished task 42.0 in stage 32.0 (TID 314) in 60 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:26.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:26.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_0 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_0 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 0.0 in stage 32.0 (TID 315). 5397 bytes result sent to driver
[2025-05-02T02:22:27.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 316) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 315) in 57 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:27.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 1.0 in stage 32.0 (TID 316)
[2025-05-02T02:22:27.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.078+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_1 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_1 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 1.0 in stage 32.0 (TID 316). 5440 bytes result sent to driver
[2025-05-02T02:22:27.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 317) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 316) in 67 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:27.091+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 3.0 in stage 32.0 (TID 317)
[2025-05-02T02:22:27.108+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.109+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.151+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_3 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.152+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.162+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_3 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 3.0 in stage 32.0 (TID 317). 5440 bytes result sent to driver
[2025-05-02T02:22:27.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 4.0 in stage 32.0 (TID 318) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 317) in 78 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:27.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 4.0 in stage 32.0 (TID 318)
[2025-05-02T02:22:27.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_4 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_4 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_4 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_4 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 4.0 in stage 32.0 (TID 318). 5397 bytes result sent to driver
[2025-05-02T02:22:27.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 5.0 in stage 32.0 (TID 319) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 4.0 in stage 32.0 (TID 318) in 80 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:27.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 5.0 in stage 32.0 (TID 319)
[2025-05-02T02:22:27.264+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.304+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_5 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_5 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 5.0 in stage 32.0 (TID 319). 5397 bytes result sent to driver
[2025-05-02T02:22:27.315+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 6.0 in stage 32.0 (TID 320) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 6.0 in stage 32.0 (TID 320)
[2025-05-02T02:22:27.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 5.0 in stage 32.0 (TID 319) in 69 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:27.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_6 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_6 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.372+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.373+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 6.0 in stage 32.0 (TID 320). 5397 bytes result sent to driver
[2025-05-02T02:22:27.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 7.0 in stage 32.0 (TID 321) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 7.0 in stage 32.0 (TID 321)
[2025-05-02T02:22:27.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 6.0 in stage 32.0 (TID 320) in 61 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:27.390+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_7 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_7 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 7.0 in stage 32.0 (TID 321). 5397 bytes result sent to driver
[2025-05-02T02:22:27.443+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 8.0 in stage 32.0 (TID 322) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.444+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 7.0 in stage 32.0 (TID 321) in 69 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:27.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 8.0 in stage 32.0 (TID 322)
[2025-05-02T02:22:27.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_8 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_8 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.502+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 8.0 in stage 32.0 (TID 322). 5397 bytes result sent to driver
[2025-05-02T02:22:27.503+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 9.0 in stage 32.0 (TID 323) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.504+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 8.0 in stage 32.0 (TID 322) in 61 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:27.505+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 9.0 in stage 32.0 (TID 323)
[2025-05-02T02:22:27.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_9 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_9 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 9.0 in stage 32.0 (TID 323). 5397 bytes result sent to driver
[2025-05-02T02:22:27.562+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 10.0 in stage 32.0 (TID 324) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 10.0 in stage 32.0 (TID 324)
[2025-05-02T02:22:27.564+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 9.0 in stage 32.0 (TID 323) in 59 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:27.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.577+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_10 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.613+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_10 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.614+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.616+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 10.0 in stage 32.0 (TID 324). 5397 bytes result sent to driver
[2025-05-02T02:22:27.617+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 11.0 in stage 32.0 (TID 325) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 11.0 in stage 32.0 (TID 325)
[2025-05-02T02:22:27.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 10.0 in stage 32.0 (TID 324) in 55 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:27.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.634+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.665+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_11 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.667+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_11 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_11 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_11 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 11.0 in stage 32.0 (TID 325). 5397 bytes result sent to driver
[2025-05-02T02:22:27.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 12.0 in stage 32.0 (TID 326) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.678+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 12.0 in stage 32.0 (TID 326)
[2025-05-02T02:22:27.679+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 11.0 in stage 32.0 (TID 325) in 60 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:27.695+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_12 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.738+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_12 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 12.0 in stage 32.0 (TID 326). 5440 bytes result sent to driver
[2025-05-02T02:22:27.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 13.0 in stage 32.0 (TID 327) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 13.0 in stage 32.0 (TID 327)
[2025-05-02T02:22:27.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 12.0 in stage 32.0 (TID 326) in 75 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:27.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.770+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_13 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.811+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_13 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.812+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.813+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 13.0 in stage 32.0 (TID 327). 5397 bytes result sent to driver
[2025-05-02T02:22:27.814+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 14.0 in stage 32.0 (TID 328) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.816+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 14.0 in stage 32.0 (TID 328)
[2025-05-02T02:22:27.817+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 13.0 in stage 32.0 (TID 327) in 65 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:27.830+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_14 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.863+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_14 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 14.0 in stage 32.0 (TID 328). 5397 bytes result sent to driver
[2025-05-02T02:22:27.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 15.0 in stage 32.0 (TID 329) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 14.0 in stage 32.0 (TID 328) in 75 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:27.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 15.0 in stage 32.0 (TID 329)
[2025-05-02T02:22:27.902+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.903+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_15 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_94_15 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_94_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:27.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Finished task 15.0 in stage 32.0 (TID 329). 5397 bytes result sent to driver
[2025-05-02T02:22:27.945+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Starting task 16.0 in stage 32.0 (TID 330) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:27.946+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO Executor: Running task 16.0 in stage 32.0 (TID 330)
[2025-05-02T02:22:27.947+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO TaskSetManager: Finished task 15.0 in stage 32.0 (TID 329) in 58 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:27.963+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:27.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:27.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO MemoryStore: Block rdd_90_16 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:27.995+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:27 INFO BlockManagerInfo: Added rdd_90_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_16 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.003+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.004+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 16.0 in stage 32.0 (TID 330). 5397 bytes result sent to driver
[2025-05-02T02:22:28.005+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 17.0 in stage 32.0 (TID 331) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.006+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 16.0 in stage 32.0 (TID 330) in 61 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:28.007+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 17.0 in stage 32.0 (TID 331)
[2025-05-02T02:22:28.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.052+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_17 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.053+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_17 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.060+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.062+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 17.0 in stage 32.0 (TID 331). 5397 bytes result sent to driver
[2025-05-02T02:22:28.063+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 18.0 in stage 32.0 (TID 332) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.064+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 18.0 in stage 32.0 (TID 332)
[2025-05-02T02:22:28.065+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 17.0 in stage 32.0 (TID 331) in 58 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:28.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.078+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.108+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_18 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.109+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_18 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.118+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 18.0 in stage 32.0 (TID 332). 5397 bytes result sent to driver
[2025-05-02T02:22:28.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 19.0 in stage 32.0 (TID 333) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 19.0 in stage 32.0 (TID 333)
[2025-05-02T02:22:28.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 18.0 in stage 32.0 (TID 332) in 57 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:28.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.134+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.163+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_19 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_19 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 19.0 in stage 32.0 (TID 333). 5397 bytes result sent to driver
[2025-05-02T02:22:28.174+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 20.0 in stage 32.0 (TID 334) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.175+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 20.0 in stage 32.0 (TID 334)
[2025-05-02T02:22:28.176+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 19.0 in stage 32.0 (TID 333) in 56 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:28.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_20 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_20 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 20.0 in stage 32.0 (TID 334). 5397 bytes result sent to driver
[2025-05-02T02:22:28.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 21.0 in stage 32.0 (TID 335) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 20.0 in stage 32.0 (TID 334) in 56 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:28.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 21.0 in stage 32.0 (TID 335)
[2025-05-02T02:22:28.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_21 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.275+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.281+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_21 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.282+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.283+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 21.0 in stage 32.0 (TID 335). 5397 bytes result sent to driver
[2025-05-02T02:22:28.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 22.0 in stage 32.0 (TID 336) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 22.0 in stage 32.0 (TID 336)
[2025-05-02T02:22:28.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 21.0 in stage 32.0 (TID 335) in 55 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:28.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.333+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_22 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.341+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_22 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 22.0 in stage 32.0 (TID 336). 5440 bytes result sent to driver
[2025-05-02T02:22:28.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 23.0 in stage 32.0 (TID 337) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 23.0 in stage 32.0 (TID 337)
[2025-05-02T02:22:28.347+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 22.0 in stage 32.0 (TID 336) in 61 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:28.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:28.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_23 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_23 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 23.0 in stage 32.0 (TID 337). 5440 bytes result sent to driver
[2025-05-02T02:22:28.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 24.0 in stage 32.0 (TID 338) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 23.0 in stage 32.0 (TID 337) in 75 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:28.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 24.0 in stage 32.0 (TID 338)
[2025-05-02T02:22:28.432+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_24 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_24 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 24.0 in stage 32.0 (TID 338). 5397 bytes result sent to driver
[2025-05-02T02:22:28.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 25.0 in stage 32.0 (TID 339) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 24.0 in stage 32.0 (TID 338) in 57 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:28.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 25.0 in stage 32.0 (TID 339)
[2025-05-02T02:22:28.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.524+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_25 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.531+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_25 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_25 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.533+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 25.0 in stage 32.0 (TID 339). 5397 bytes result sent to driver
[2025-05-02T02:22:28.534+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 26.0 in stage 32.0 (TID 340) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 25.0 in stage 32.0 (TID 339) in 61 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:28.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 26.0 in stage 32.0 (TID 340)
[2025-05-02T02:22:28.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_26 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_26 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.589+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 26.0 in stage 32.0 (TID 340). 5397 bytes result sent to driver
[2025-05-02T02:22:28.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 27.0 in stage 32.0 (TID 341) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.593+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 26.0 in stage 32.0 (TID 340) in 58 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:28.594+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 27.0 in stage 32.0 (TID 341)
[2025-05-02T02:22:28.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_27 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_27 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 27.0 in stage 32.0 (TID 341). 5397 bytes result sent to driver
[2025-05-02T02:22:28.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 28.0 in stage 32.0 (TID 342) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.649+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 27.0 in stage 32.0 (TID 341) in 57 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:28.650+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 28.0 in stage 32.0 (TID 342)
[2025-05-02T02:22:28.662+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.663+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.695+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_28 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_28 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.705+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 28.0 in stage 32.0 (TID 342). 5397 bytes result sent to driver
[2025-05-02T02:22:28.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 29.0 in stage 32.0 (TID 343) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 28.0 in stage 32.0 (TID 342) in 59 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:28.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 29.0 in stage 32.0 (TID 343)
[2025-05-02T02:22:28.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_29 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_29 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 29.0 in stage 32.0 (TID 343). 5397 bytes result sent to driver
[2025-05-02T02:22:28.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 30.0 in stage 32.0 (TID 344) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.765+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 29.0 in stage 32.0 (TID 343) in 58 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:28.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 30.0 in stage 32.0 (TID 344)
[2025-05-02T02:22:28.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_30 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.822+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_30 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.833+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 30.0 in stage 32.0 (TID 344). 5397 bytes result sent to driver
[2025-05-02T02:22:28.834+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 31.0 in stage 32.0 (TID 345) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.835+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 31.0 in stage 32.0 (TID 345)
[2025-05-02T02:22:28.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 30.0 in stage 32.0 (TID 344) in 71 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:28.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_31 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_31 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 31.0 in stage 32.0 (TID 345). 5397 bytes result sent to driver
[2025-05-02T02:22:28.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 32.0 in stage 32.0 (TID 346) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 32.0 in stage 32.0 (TID 346)
[2025-05-02T02:22:28.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 31.0 in stage 32.0 (TID 345) in 62 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:28.913+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.914+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:28.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_90_32 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_90_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO MemoryStore: Block rdd_94_32 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:28.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO BlockManagerInfo: Added rdd_94_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:28.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Finished task 32.0 in stage 32.0 (TID 346). 5397 bytes result sent to driver
[2025-05-02T02:22:28.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Starting task 33.0 in stage 32.0 (TID 347) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:28.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO TaskSetManager: Finished task 32.0 in stage 32.0 (TID 346) in 61 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:28.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO Executor: Running task 33.0 in stage 32.0 (TID 347)
[2025-05-02T02:22:28.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:28.970+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_33 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_33 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 33.0 in stage 32.0 (TID 347). 5440 bytes result sent to driver
[2025-05-02T02:22:29.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 34.0 in stage 32.0 (TID 348) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.028+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 34.0 in stage 32.0 (TID 348)
[2025-05-02T02:22:29.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 33.0 in stage 32.0 (TID 347) in 72 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:29.045+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:29.046+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.085+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_34 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_34 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.095+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 34.0 in stage 32.0 (TID 348). 5397 bytes result sent to driver
[2025-05-02T02:22:29.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 35.0 in stage 32.0 (TID 349) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 35.0 in stage 32.0 (TID 349)
[2025-05-02T02:22:29.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 34.0 in stage 32.0 (TID 348) in 70 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:29.110+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:29.111+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_35 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.163+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_35 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 35.0 in stage 32.0 (TID 349). 5397 bytes result sent to driver
[2025-05-02T02:22:29.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 36.0 in stage 32.0 (TID 350) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 36.0 in stage 32.0 (TID 350)
[2025-05-02T02:22:29.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 35.0 in stage 32.0 (TID 349) in 71 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:29.183+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:29.184+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_36 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_36 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.238+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 36.0 in stage 32.0 (TID 350). 5397 bytes result sent to driver
[2025-05-02T02:22:29.240+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 37.0 in stage 32.0 (TID 351) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.241+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 36.0 in stage 32.0 (TID 350) in 74 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:29.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 37.0 in stage 32.0 (TID 351)
[2025-05-02T02:22:29.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:29.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.291+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_37 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.302+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_37 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 37.0 in stage 32.0 (TID 351). 5397 bytes result sent to driver
[2025-05-02T02:22:29.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 38.0 in stage 32.0 (TID 352) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 37.0 in stage 32.0 (TID 351) in 66 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:29.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 38.0 in stage 32.0 (TID 352)
[2025-05-02T02:22:29.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:29.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_38 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.358+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_38 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 38.0 in stage 32.0 (TID 352). 5397 bytes result sent to driver
[2025-05-02T02:22:29.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 39.0 in stage 32.0 (TID 353) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 38.0 in stage 32.0 (TID 352) in 57 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:29.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 39.0 in stage 32.0 (TID 353)
[2025-05-02T02:22:29.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:29.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:29.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_90_39 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_90_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO MemoryStore: Block rdd_94_39 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:29.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO BlockManagerInfo: Added rdd_94_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:29.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Finished task 39.0 in stage 32.0 (TID 353). 5397 bytes result sent to driver
[2025-05-02T02:22:29.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Starting task 40.0 in stage 32.0 (TID 354) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:29.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO TaskSetManager: Finished task 39.0 in stage 32.0 (TID 353) in 57 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:29.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:29 INFO Executor: Running task 40.0 in stage 32.0 (TID 354)
[2025-05-02T02:22:20.387+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.389+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_90_40 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:20.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_90_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_94_40 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:20.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_94_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.432+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 40.0 in stage 32.0 (TID 354). 5397 bytes result sent to driver
[2025-05-02T02:22:20.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 41.0 in stage 32.0 (TID 355) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 41.0 in stage 32.0 (TID 355)
[2025-05-02T02:22:20.435+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 40.0 in stage 32.0 (TID 354) in -8983 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:20.448+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_90_41 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:20.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_90_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_94_41 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:20.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_94_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.496+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 41.0 in stage 32.0 (TID 355). 5397 bytes result sent to driver
[2025-05-02T02:22:20.497+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 43.0 in stage 32.0 (TID 356) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 43.0 in stage 32.0 (TID 356)
[2025-05-02T02:22:20.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 41.0 in stage 32.0 (TID 355) in 64 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:20.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:20.541+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_90_43 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:20.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_90_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO MemoryStore: Block rdd_94_43 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:20.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO BlockManagerInfo: Added rdd_94_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:20.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Finished task 43.0 in stage 32.0 (TID 356). 5397 bytes result sent to driver
[2025-05-02T02:22:20.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Starting task 44.0 in stage 32.0 (TID 357) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:20.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO Executor: Running task 44.0 in stage 32.0 (TID 357)
[2025-05-02T02:22:20.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO TaskSetManager: Finished task 43.0 in stage 32.0 (TID 356) in 55 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:20.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:20.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:30.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_90_44 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_90_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_94_44 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_94_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.684+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Finished task 44.0 in stage 32.0 (TID 357). 5440 bytes result sent to driver
[2025-05-02T02:22:30.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Starting task 45.0 in stage 32.0 (TID 358) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:30.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Finished task 44.0 in stage 32.0 (TID 357) in 10133 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:30.687+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Running task 45.0 in stage 32.0 (TID 358)
[2025-05-02T02:22:30.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:30.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:30.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_90_45 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_90_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_94_45 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_94_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Finished task 45.0 in stage 32.0 (TID 358). 5440 bytes result sent to driver
[2025-05-02T02:22:30.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Starting task 46.0 in stage 32.0 (TID 359) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:30.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Finished task 45.0 in stage 32.0 (TID 358) in 70 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:30.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Running task 46.0 in stage 32.0 (TID 359)
[2025-05-02T02:22:30.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:30.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:30.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_90_46 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.800+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_90_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_94_46 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.807+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_94_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.808+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Finished task 46.0 in stage 32.0 (TID 359). 5397 bytes result sent to driver
[2025-05-02T02:22:30.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Starting task 47.0 in stage 32.0 (TID 360) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:30.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Finished task 46.0 in stage 32.0 (TID 359) in 57 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:30.811+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Running task 47.0 in stage 32.0 (TID 360)
[2025-05-02T02:22:30.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:30.828+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:30.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_90_47 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_90_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.869+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_94_47 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_94_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Finished task 47.0 in stage 32.0 (TID 360). 5397 bytes result sent to driver
[2025-05-02T02:22:30.873+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Starting task 48.0 in stage 32.0 (TID 361) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:30.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Finished task 47.0 in stage 32.0 (TID 360) in 64 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:30.875+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Running task 48.0 in stage 32.0 (TID 361)
[2025-05-02T02:22:30.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:30.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:30.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_90_48 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_90_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_94_48 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_94_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Finished task 48.0 in stage 32.0 (TID 361). 5397 bytes result sent to driver
[2025-05-02T02:22:30.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Starting task 49.0 in stage 32.0 (TID 362) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:30.927+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Running task 49.0 in stage 32.0 (TID 362)
[2025-05-02T02:22:30.927+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Finished task 48.0 in stage 32.0 (TID 361) in 54 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:30.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:30.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:30.971+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_90_49 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.972+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_90_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO MemoryStore: Block rdd_94_49 stored as values in memory (estimated size 46.0 B, free 431.6 MiB)
[2025-05-02T02:22:30.979+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO BlockManagerInfo: Added rdd_94_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 433.9 MiB)
[2025-05-02T02:22:30.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO Executor: Finished task 49.0 in stage 32.0 (TID 362). 5397 bytes result sent to driver
[2025-05-02T02:22:30.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSetManager: Finished task 49.0 in stage 32.0 (TID 362) in 57 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:30.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-02T02:22:30.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO DAGScheduler: ResultStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 4.223 s
[2025-05-02T02:22:30.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:30.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
[2025-05-02T02:22:30.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO DAGScheduler: Job 17 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 3.209823 s
[2025-05-02T02:22:30.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:30.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:30 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:31.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO CodeGenerator: Code generated in 34.668016 ms
[2025-05-02T02:22:31.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:31.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO DAGScheduler: Got job 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:31.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:31.122+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2025-05-02T02:22:31.123+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:31.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[98] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:31.131+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 744.4 KiB, free 430.9 MiB)
[2025-05-02T02:22:31.134+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 170.7 KiB, free 430.7 MiB)
[2025-05-02T02:22:31.135+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on ***-scheduler:33063 (size: 170.7 KiB, free: 433.8 MiB)
[2025-05-02T02:22:31.136+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:31.137+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 34 (MapPartitionsRDD[98] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:31.137+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSchedulerImpl: Adding task set 34.0 with 50 tasks resource profile 0
[2025-05-02T02:22:31.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 363) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 0.0 in stage 34.0 (TID 363)
[2025-05-02T02:22:31.150+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_0 locally
[2025-05-02T02:22:31.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO CodeGenerator: Code generated in 32.289727 ms
[2025-05-02T02:22:31.186+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 0.0 in stage 34.0 (TID 363). 4666 bytes result sent to driver
[2025-05-02T02:22:31.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 364) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 1.0 in stage 34.0 (TID 364)
[2025-05-02T02:22:31.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 363) in 50 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:31.202+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_1 locally
[2025-05-02T02:22:31.204+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 1.0 in stage 34.0 (TID 364). 4666 bytes result sent to driver
[2025-05-02T02:22:31.205+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 365) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 2.0 in stage 34.0 (TID 365)
[2025-05-02T02:22:31.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 364) in 19 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:31.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_2 locally
[2025-05-02T02:22:31.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 2.0 in stage 34.0 (TID 365). 4666 bytes result sent to driver
[2025-05-02T02:22:31.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 366) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 3.0 in stage 34.0 (TID 366)
[2025-05-02T02:22:31.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 365) in 15 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:31.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_3 locally
[2025-05-02T02:22:31.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 3.0 in stage 34.0 (TID 366). 4666 bytes result sent to driver
[2025-05-02T02:22:31.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 4.0 in stage 34.0 (TID 367) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 366) in 15 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:31.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 4.0 in stage 34.0 (TID 367)
[2025-05-02T02:22:31.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_4 locally
[2025-05-02T02:22:31.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 4.0 in stage 34.0 (TID 367). 4834 bytes result sent to driver
[2025-05-02T02:22:31.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 5.0 in stage 34.0 (TID 368) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 5.0 in stage 34.0 (TID 368)
[2025-05-02T02:22:31.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 4.0 in stage 34.0 (TID 367) in 21 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:31.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_5 locally
[2025-05-02T02:22:31.266+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 5.0 in stage 34.0 (TID 368). 4666 bytes result sent to driver
[2025-05-02T02:22:31.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 6.0 in stage 34.0 (TID 369) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 6.0 in stage 34.0 (TID 369)
[2025-05-02T02:22:31.269+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 5.0 in stage 34.0 (TID 368) in 14 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:31.278+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_6 locally
[2025-05-02T02:22:31.280+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 6.0 in stage 34.0 (TID 369). 4666 bytes result sent to driver
[2025-05-02T02:22:31.281+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 7.0 in stage 34.0 (TID 370) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.282+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 6.0 in stage 34.0 (TID 369) in 15 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:31.283+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 7.0 in stage 34.0 (TID 370)
[2025-05-02T02:22:31.295+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_7 locally
[2025-05-02T02:22:31.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 7.0 in stage 34.0 (TID 370). 4666 bytes result sent to driver
[2025-05-02T02:22:31.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 8.0 in stage 34.0 (TID 371) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 7.0 in stage 34.0 (TID 370) in 18 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:31.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 8.0 in stage 34.0 (TID 371)
[2025-05-02T02:22:31.310+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_8 locally
[2025-05-02T02:22:31.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 8.0 in stage 34.0 (TID 371). 4666 bytes result sent to driver
[2025-05-02T02:22:31.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 9.0 in stage 34.0 (TID 372) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 8.0 in stage 34.0 (TID 371) in 16 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:31.315+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 9.0 in stage 34.0 (TID 372)
[2025-05-02T02:22:31.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_9 locally
[2025-05-02T02:22:31.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 9.0 in stage 34.0 (TID 372). 4666 bytes result sent to driver
[2025-05-02T02:22:31.332+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 10.0 in stage 34.0 (TID 373) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.332+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 10.0 in stage 34.0 (TID 373)
[2025-05-02T02:22:31.333+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 9.0 in stage 34.0 (TID 372) in 20 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:31.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_10 locally
[2025-05-02T02:22:31.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 10.0 in stage 34.0 (TID 373). 4666 bytes result sent to driver
[2025-05-02T02:22:31.347+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 11.0 in stage 34.0 (TID 374) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 10.0 in stage 34.0 (TID 373) in 16 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:31.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 11.0 in stage 34.0 (TID 374)
[2025-05-02T02:22:31.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_11 locally
[2025-05-02T02:22:31.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 11.0 in stage 34.0 (TID 374). 4666 bytes result sent to driver
[2025-05-02T02:22:31.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 12.0 in stage 34.0 (TID 375) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 12.0 in stage 34.0 (TID 375)
[2025-05-02T02:22:31.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 11.0 in stage 34.0 (TID 374) in 18 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:31.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_12 locally
[2025-05-02T02:22:31.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 12.0 in stage 34.0 (TID 375). 4709 bytes result sent to driver
[2025-05-02T02:22:31.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 13.0 in stage 34.0 (TID 376) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 13.0 in stage 34.0 (TID 376)
[2025-05-02T02:22:31.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 12.0 in stage 34.0 (TID 375) in 34 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:31.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_13 locally
[2025-05-02T02:22:31.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 13.0 in stage 34.0 (TID 376). 4666 bytes result sent to driver
[2025-05-02T02:22:31.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 14.0 in stage 34.0 (TID 377) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 13.0 in stage 34.0 (TID 376) in 22 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:31.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 14.0 in stage 34.0 (TID 377)
[2025-05-02T02:22:31.435+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_14 locally
[2025-05-02T02:22:31.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 14.0 in stage 34.0 (TID 377). 4666 bytes result sent to driver
[2025-05-02T02:22:31.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 15.0 in stage 34.0 (TID 378) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 14.0 in stage 34.0 (TID 377) in 21 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:31.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 15.0 in stage 34.0 (TID 378)
[2025-05-02T02:22:31.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_15 locally
[2025-05-02T02:22:31.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 15.0 in stage 34.0 (TID 378). 4666 bytes result sent to driver
[2025-05-02T02:22:31.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 16.0 in stage 34.0 (TID 379) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.459+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 16.0 in stage 34.0 (TID 379)
[2025-05-02T02:22:31.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 15.0 in stage 34.0 (TID 378) in 22 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:31.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_16 locally
[2025-05-02T02:22:31.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 16.0 in stage 34.0 (TID 379). 4666 bytes result sent to driver
[2025-05-02T02:22:31.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 17.0 in stage 34.0 (TID 380) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 16.0 in stage 34.0 (TID 379) in 17 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:31.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 17.0 in stage 34.0 (TID 380)
[2025-05-02T02:22:31.491+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_17 locally
[2025-05-02T02:22:31.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 17.0 in stage 34.0 (TID 380). 4666 bytes result sent to driver
[2025-05-02T02:22:31.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 18.0 in stage 34.0 (TID 381) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 17.0 in stage 34.0 (TID 380) in 20 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:31.496+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 18.0 in stage 34.0 (TID 381)
[2025-05-02T02:22:31.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_18 locally
[2025-05-02T02:22:31.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 18.0 in stage 34.0 (TID 381). 4666 bytes result sent to driver
[2025-05-02T02:22:31.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 19.0 in stage 34.0 (TID 382) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 18.0 in stage 34.0 (TID 381) in 17 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:31.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 19.0 in stage 34.0 (TID 382)
[2025-05-02T02:22:31.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_19 locally
[2025-05-02T02:22:31.530+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 19.0 in stage 34.0 (TID 382). 4666 bytes result sent to driver
[2025-05-02T02:22:31.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 20.0 in stage 34.0 (TID 383) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 19.0 in stage 34.0 (TID 382) in 22 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:31.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 20.0 in stage 34.0 (TID 383)
[2025-05-02T02:22:31.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManagerInfo: Removed broadcast_28_piece0 on ***-scheduler:33063 in memory (size: 169.4 KiB, free: 433.9 MiB)
[2025-05-02T02:22:31.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_20 locally
[2025-05-02T02:22:31.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 20.0 in stage 34.0 (TID 383). 4666 bytes result sent to driver
[2025-05-02T02:22:31.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 21.0 in stage 34.0 (TID 384) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.572+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 20.0 in stage 34.0 (TID 383) in 40 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:31.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 21.0 in stage 34.0 (TID 384)
[2025-05-02T02:22:31.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_21 locally
[2025-05-02T02:22:31.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 21.0 in stage 34.0 (TID 384). 4666 bytes result sent to driver
[2025-05-02T02:22:31.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 22.0 in stage 34.0 (TID 385) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.594+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 21.0 in stage 34.0 (TID 384) in 23 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:31.595+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 22.0 in stage 34.0 (TID 385)
[2025-05-02T02:22:31.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_22 locally
[2025-05-02T02:22:31.612+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 22.0 in stage 34.0 (TID 385). 4666 bytes result sent to driver
[2025-05-02T02:22:31.614+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 23.0 in stage 34.0 (TID 386) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.615+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 22.0 in stage 34.0 (TID 385) in 23 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:31.616+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 23.0 in stage 34.0 (TID 386)
[2025-05-02T02:22:31.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_23 locally
[2025-05-02T02:22:31.634+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 23.0 in stage 34.0 (TID 386). 4666 bytes result sent to driver
[2025-05-02T02:22:31.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 24.0 in stage 34.0 (TID 387) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 24.0 in stage 34.0 (TID 387)
[2025-05-02T02:22:31.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 23.0 in stage 34.0 (TID 386) in 23 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:31.650+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_24 locally
[2025-05-02T02:22:31.651+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 24.0 in stage 34.0 (TID 387). 4666 bytes result sent to driver
[2025-05-02T02:22:31.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 25.0 in stage 34.0 (TID 388) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.653+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 24.0 in stage 34.0 (TID 387) in 19 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:31.654+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 25.0 in stage 34.0 (TID 388)
[2025-05-02T02:22:31.665+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_25 locally
[2025-05-02T02:22:31.667+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 25.0 in stage 34.0 (TID 388). 4666 bytes result sent to driver
[2025-05-02T02:22:31.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 26.0 in stage 34.0 (TID 389) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 26.0 in stage 34.0 (TID 389)
[2025-05-02T02:22:31.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 25.0 in stage 34.0 (TID 388) in 16 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:31.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_26 locally
[2025-05-02T02:22:31.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 26.0 in stage 34.0 (TID 389). 4666 bytes result sent to driver
[2025-05-02T02:22:31.684+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 27.0 in stage 34.0 (TID 390) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 27.0 in stage 34.0 (TID 390)
[2025-05-02T02:22:31.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 26.0 in stage 34.0 (TID 389) in 17 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:31.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_27 locally
[2025-05-02T02:22:31.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 27.0 in stage 34.0 (TID 390). 4666 bytes result sent to driver
[2025-05-02T02:22:31.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 28.0 in stage 34.0 (TID 391) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 27.0 in stage 34.0 (TID 390) in 22 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:31.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 28.0 in stage 34.0 (TID 391)
[2025-05-02T02:22:31.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_28 locally
[2025-05-02T02:22:31.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 28.0 in stage 34.0 (TID 391). 4666 bytes result sent to driver
[2025-05-02T02:22:31.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 29.0 in stage 34.0 (TID 392) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 29.0 in stage 34.0 (TID 392)
[2025-05-02T02:22:31.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 28.0 in stage 34.0 (TID 391) in 17 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:31.739+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_29 locally
[2025-05-02T02:22:31.741+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 29.0 in stage 34.0 (TID 392). 4666 bytes result sent to driver
[2025-05-02T02:22:31.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 30.0 in stage 34.0 (TID 393) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.743+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 29.0 in stage 34.0 (TID 392) in 22 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:31.744+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 30.0 in stage 34.0 (TID 393)
[2025-05-02T02:22:31.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_30 locally
[2025-05-02T02:22:31.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 30.0 in stage 34.0 (TID 393). 4666 bytes result sent to driver
[2025-05-02T02:22:31.758+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 31.0 in stage 34.0 (TID 394) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 31.0 in stage 34.0 (TID 394)
[2025-05-02T02:22:31.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 30.0 in stage 34.0 (TID 393) in 17 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:31.775+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_31 locally
[2025-05-02T02:22:31.777+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 31.0 in stage 34.0 (TID 394). 4666 bytes result sent to driver
[2025-05-02T02:22:31.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 32.0 in stage 34.0 (TID 395) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.779+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 31.0 in stage 34.0 (TID 394) in 21 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:31.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 32.0 in stage 34.0 (TID 395)
[2025-05-02T02:22:31.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_32 locally
[2025-05-02T02:22:31.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 32.0 in stage 34.0 (TID 395). 4666 bytes result sent to driver
[2025-05-02T02:22:31.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 33.0 in stage 34.0 (TID 396) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.795+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 33.0 in stage 34.0 (TID 396)
[2025-05-02T02:22:31.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 32.0 in stage 34.0 (TID 395) in 16 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:31.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_33 locally
[2025-05-02T02:22:31.808+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 33.0 in stage 34.0 (TID 396). 4666 bytes result sent to driver
[2025-05-02T02:22:31.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 34.0 in stage 34.0 (TID 397) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 34.0 in stage 34.0 (TID 397)
[2025-05-02T02:22:31.811+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 33.0 in stage 34.0 (TID 396) in 16 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:31.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_34 locally
[2025-05-02T02:22:31.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 34.0 in stage 34.0 (TID 397). 4666 bytes result sent to driver
[2025-05-02T02:22:31.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 35.0 in stage 34.0 (TID 398) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 35.0 in stage 34.0 (TID 398)
[2025-05-02T02:22:31.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 34.0 in stage 34.0 (TID 397) in 16 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:31.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_35 locally
[2025-05-02T02:22:31.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 35.0 in stage 34.0 (TID 398). 4666 bytes result sent to driver
[2025-05-02T02:22:31.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 36.0 in stage 34.0 (TID 399) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 36.0 in stage 34.0 (TID 399)
[2025-05-02T02:22:31.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 35.0 in stage 34.0 (TID 398) in 16 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:31.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_36 locally
[2025-05-02T02:22:31.853+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 36.0 in stage 34.0 (TID 399). 4666 bytes result sent to driver
[2025-05-02T02:22:31.854+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 37.0 in stage 34.0 (TID 400) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.855+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 37.0 in stage 34.0 (TID 400)
[2025-05-02T02:22:31.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 36.0 in stage 34.0 (TID 399) in 16 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:31.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_37 locally
[2025-05-02T02:22:31.869+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 37.0 in stage 34.0 (TID 400). 4666 bytes result sent to driver
[2025-05-02T02:22:31.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 38.0 in stage 34.0 (TID 401) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 37.0 in stage 34.0 (TID 400) in 16 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:31.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 38.0 in stage 34.0 (TID 401)
[2025-05-02T02:22:31.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_38 locally
[2025-05-02T02:22:31.884+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 38.0 in stage 34.0 (TID 401). 4666 bytes result sent to driver
[2025-05-02T02:22:31.884+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 39.0 in stage 34.0 (TID 402) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 38.0 in stage 34.0 (TID 401) in 16 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:31.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 39.0 in stage 34.0 (TID 402)
[2025-05-02T02:22:31.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_39 locally
[2025-05-02T02:22:31.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 39.0 in stage 34.0 (TID 402). 4666 bytes result sent to driver
[2025-05-02T02:22:31.900+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 40.0 in stage 34.0 (TID 403) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.901+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 39.0 in stage 34.0 (TID 402) in 16 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:31.902+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 40.0 in stage 34.0 (TID 403)
[2025-05-02T02:22:31.913+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_40 locally
[2025-05-02T02:22:31.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 40.0 in stage 34.0 (TID 403). 4666 bytes result sent to driver
[2025-05-02T02:22:31.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 41.0 in stage 34.0 (TID 404) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 41.0 in stage 34.0 (TID 404)
[2025-05-02T02:22:31.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 40.0 in stage 34.0 (TID 403) in 17 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:31.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_41 locally
[2025-05-02T02:22:31.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 41.0 in stage 34.0 (TID 404). 4666 bytes result sent to driver
[2025-05-02T02:22:31.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 42.0 in stage 34.0 (TID 405) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.937+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 42.0 in stage 34.0 (TID 405)
[2025-05-02T02:22:31.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 41.0 in stage 34.0 (TID 404) in 21 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:31.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_42 locally
[2025-05-02T02:22:31.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 42.0 in stage 34.0 (TID 405). 4666 bytes result sent to driver
[2025-05-02T02:22:31.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 43.0 in stage 34.0 (TID 406) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 43.0 in stage 34.0 (TID 406)
[2025-05-02T02:22:31.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 42.0 in stage 34.0 (TID 405) in 18 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:31.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_43 locally
[2025-05-02T02:22:31.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 43.0 in stage 34.0 (TID 406). 4709 bytes result sent to driver
[2025-05-02T02:22:31.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 44.0 in stage 34.0 (TID 407) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 44.0 in stage 34.0 (TID 407)
[2025-05-02T02:22:31.979+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 43.0 in stage 34.0 (TID 406) in 25 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:31.995+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO BlockManager: Found block rdd_77_44 locally
[2025-05-02T02:22:31.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Finished task 44.0 in stage 34.0 (TID 407). 4666 bytes result sent to driver
[2025-05-02T02:22:31.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Starting task 45.0 in stage 34.0 (TID 408) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:31.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO Executor: Running task 45.0 in stage 34.0 (TID 408)
[2025-05-02T02:22:32.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:31 INFO TaskSetManager: Finished task 44.0 in stage 34.0 (TID 407) in 22 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:32.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManager: Found block rdd_77_45 locally
[2025-05-02T02:22:32.018+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 45.0 in stage 34.0 (TID 408). 4666 bytes result sent to driver
[2025-05-02T02:22:32.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 46.0 in stage 34.0 (TID 409) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:32.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 45.0 in stage 34.0 (TID 408) in 22 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:32.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 46.0 in stage 34.0 (TID 409)
[2025-05-02T02:22:32.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManager: Found block rdd_77_46 locally
[2025-05-02T02:22:32.039+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 46.0 in stage 34.0 (TID 409). 4666 bytes result sent to driver
[2025-05-02T02:22:32.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 47.0 in stage 34.0 (TID 410) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:32.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 47.0 in stage 34.0 (TID 410)
[2025-05-02T02:22:32.042+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 46.0 in stage 34.0 (TID 409) in 22 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:32.055+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManager: Found block rdd_77_47 locally
[2025-05-02T02:22:32.056+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 47.0 in stage 34.0 (TID 410). 4666 bytes result sent to driver
[2025-05-02T02:22:32.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 48.0 in stage 34.0 (TID 411) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:32.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 48.0 in stage 34.0 (TID 411)
[2025-05-02T02:22:32.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 47.0 in stage 34.0 (TID 410) in 19 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:32.071+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManager: Found block rdd_77_48 locally
[2025-05-02T02:22:32.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 48.0 in stage 34.0 (TID 411). 4709 bytes result sent to driver
[2025-05-02T02:22:32.081+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 49.0 in stage 34.0 (TID 412) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:32.082+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 49.0 in stage 34.0 (TID 412)
[2025-05-02T02:22:32.083+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 48.0 in stage 34.0 (TID 411) in 24 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:32.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManager: Found block rdd_77_49 locally
[2025-05-02T02:22:32.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 49.0 in stage 34.0 (TID 412). 4666 bytes result sent to driver
[2025-05-02T02:22:32.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 49.0 in stage 34.0 (TID 412) in 16 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:32.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2025-05-02T02:22:32.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: ResultStage 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.973 s
[2025-05-02T02:22:32.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:32.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
[2025-05-02T02:22:32.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Job 18 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.979449 s
[2025-05-02T02:22:32.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:32.137+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Key),EqualTo(Allergy_Key,0000000000000000000000000000000000000000000000000000000000000000),IsNotNull(Allergy_Group_Key)
[2025-05-02T02:22:32.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Key#2092),(Allergy_Key#2092 = 0000000000000000000000000000000000000000000000000000000000000000),isnotnull(Allergy_Group_Key#2091)
[2025-05-02T02:22:32.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:32.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(sha2(cast(ENCOUNTER#35 as binary), 256))
[2025-05-02T02:22:32.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:32.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(sha2(cast(ID#0 as binary), 256))
[2025-05-02T02:22:32.147+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ENCOUNTER)
[2025-05-02T02:22:32.148+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ENCOUNTER#2075)
[2025-05-02T02:22:32.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 206.5 KiB, free 431.4 MiB)
[2025-05-02T02:22:32.205+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 431.4 MiB)
[2025-05-02T02:22:32.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on ***-scheduler:33063 (size: 36.3 KiB, free: 433.9 MiB)
[2025-05-02T02:22:32.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 30 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:32.208+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4206010 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:32.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:32.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Got job 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-02T02:22:32.224+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Final stage: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:32.225+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 37.153733 ms
[2025-05-02T02:22:32.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:32.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:32.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[102] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:32.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 18.6 KiB, free 431.3 MiB)
[2025-05-02T02:22:32.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 431.3 MiB)
[2025-05-02T02:22:32.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on ***-scheduler:33063 (size: 8.0 KiB, free: 433.9 MiB)
[2025-05-02T02:22:32.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:32.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[102] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:32.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
[2025-05-02T02:22:32.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 413) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10919 bytes)
[2025-05-02T02:22:32.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 0.0 in stage 35.0 (TID 413)
[2025-05-02T02:22:32.236+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet, range: 0-11706, partition values: [empty row]
[2025-05-02T02:22:32.236+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 206.9 KiB, free 431.1 MiB)
[2025-05-02T02:22:32.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 431.1 MiB)
[2025-05-02T02:22:32.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on ***-scheduler:33063 (size: 36.5 KiB, free: 433.9 MiB)
[2025-05-02T02:22:32.256+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 32 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:32.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4206010 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:32.269+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Registering RDD 106 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 8
[2025-05-02T02:22:32.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Got map stage job 20 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:32.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Final stage: ShuffleMapStage 36 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:32.272+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:32.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:32.274+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[106] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:32.275+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 52.7 KiB, free 431.1 MiB)
[2025-05-02T02:22:32.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 431.0 MiB)
[2025-05-02T02:22:32.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on ***-scheduler:33063 (size: 22.0 KiB, free: 433.8 MiB)
[2025-05-02T02:22:32.277+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:32.278+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[106] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:32.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-02T02:22:32.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:32.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FilterCompat: Filtering using predicate: noteq(ENCOUNTER, null)
[2025-05-02T02:22:32.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:32.409+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 0.0 in stage 35.0 (TID 413). 2722 bytes result sent to driver
[2025-05-02T02:22:32.410+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 414) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10908 bytes)
[2025-05-02T02:22:32.411+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 0.0 in stage 36.0 (TID 414)
[2025-05-02T02:22:32.412+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 413) in 182 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:32.413+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool
[2025-05-02T02:22:32.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.187 s
[2025-05-02T02:22:32.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:32.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
[2025-05-02T02:22:32.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Job 19 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.190869 s
[2025-05-02T02:22:32.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 16.0 MiB, free 415.0 MiB)
[2025-05-02T02:22:32.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 1814.0 B, free 415.0 MiB)
[2025-05-02T02:22:32.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on ***-scheduler:33063 (size: 1814.0 B, free: 433.8 MiB)
[2025-05-02T02:22:32.425+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:32.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Key),EqualTo(Allergy_Key,0000000000000000000000000000000000000000000000000000000000000000),IsNotNull(Allergy_Group_Key)
[2025-05-02T02:22:32.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Key#2092),(Allergy_Key#2092 = 0000000000000000000000000000000000000000000000000000000000000000),isnotnull(Allergy_Group_Key#2091)
[2025-05-02T02:22:32.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:32.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(sha2(cast(ID#0 as binary), 256))
[2025-05-02T02:22:32.468+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 50.792622 ms
[2025-05-02T02:22:32.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 9.423763 ms
[2025-05-02T02:22:32.497+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 6.676839 ms
[2025-05-02T02:22:32.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet, range: 0-11706, partition values: [empty row]
[2025-05-02T02:22:32.502+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 38.528305 ms
[2025-05-02T02:22:32.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 206.5 KiB, free 398.6 MiB)
[2025-05-02T02:22:32.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 398.5 MiB)
[2025-05-02T02:22:32.533+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on ***-scheduler:33063 (size: 36.3 KiB, free: 433.8 MiB)
[2025-05-02T02:22:32.534+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 35 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:32.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5664674 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:32.546+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Registering RDD 110 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 9
[2025-05-02T02:22:32.547+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Got map stage job 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:32.548+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Final stage: ShuffleMapStage 37 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:32.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:32.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:32.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[110] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:32.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 56.4 KiB, free 398.5 MiB)
[2025-05-02T02:22:32.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 398.5 MiB)
[2025-05-02T02:22:32.555+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on ***-scheduler:33063 (size: 24.2 KiB, free: 433.8 MiB)
[2025-05-02T02:22:32.555+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:32.556+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:32.557+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[110] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:32.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-05-02T02:22:32.667+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Finished task 0.0 in stage 36.0 (TID 414). 2991 bytes result sent to driver
[2025-05-02T02:22:32.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 415) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10909 bytes)
[2025-05-02T02:22:32.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 414) in 260 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:32.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO Executor: Running task 0.0 in stage 37.0 (TID 415)
[2025-05-02T02:22:32.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-02T02:22:32.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: ShuffleMapStage 36 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.400 s
[2025-05-02T02:22:32.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:32.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: running: Set(ShuffleMapStage 37)
[2025-05-02T02:22:32.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:32.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:32.678+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Key),EqualTo(Allergy_Key,0000000000000000000000000000000000000000000000000000000000000000),IsNotNull(Allergy_Group_Key)
[2025-05-02T02:22:32.679+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Key#2092),(Allergy_Key#2092 = 0000000000000000000000000000000000000000000000000000000000000000),isnotnull(Allergy_Group_Key#2091)
[2025-05-02T02:22:32.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 31.333059 ms
[2025-05-02T02:22:32.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO CodeGenerator: Code generated in 11.805185 ms
[2025-05-02T02:22:32.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/part-00000-ea7425f2-9107-4d6c-bddb-e4d1ec24a4da-c000.snappy.parquet, range: 0-1470370, partition values: [empty row]
[2025-05-02T02:22:32.800+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:32 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:33.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: Finished task 0.0 in stage 37.0 (TID 415). 3888 bytes result sent to driver
[2025-05-02T02:22:33.122+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 415) in 453 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:33.123+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-05-02T02:22:33.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: ShuffleMapStage 37 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.575 s
[2025-05-02T02:22:33.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:33.126+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:33.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:33.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:33.129+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Key),EqualTo(Allergy_Key,0000000000000000000000000000000000000000000000000000000000000000),IsNotNull(Allergy_Group_Key)
[2025-05-02T02:22:33.130+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Key#2092),(Allergy_Key#2092 = 0000000000000000000000000000000000000000000000000000000000000000),isnotnull(Allergy_Group_Key#2091)
[2025-05-02T02:22:33.132+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:33.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:33.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 20.732129 ms
[2025-05-02T02:22:33.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 18.611426 ms
[2025-05-02T02:22:33.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:33.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Got job 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-05-02T02:22:33.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Final stage: ResultStage 40 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:33.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38, ShuffleMapStage 39)
[2025-05-02T02:22:33.224+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:33.225+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[116] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:33.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 78.6 KiB, free 414.6 MiB)
[2025-05-02T02:22:33.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 414.6 MiB)
[2025-05-02T02:22:33.236+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on ***-scheduler:33063 (size: 33.5 KiB, free: 433.7 MiB)
[2025-05-02T02:22:33.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:33.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[116] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-02T02:22:33.240+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks resource profile 0
[2025-05-02T02:22:33.241+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 416) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10315 bytes)
[2025-05-02T02:22:33.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: Running task 0.0 in stage 40.0 (TID 416)
[2025-05-02T02:22:33.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO ShuffleBlockFetcherIterator: Getting 1 (17.1 KiB) non-empty blocks including 1 (17.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:33.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:33.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 19.712994 ms
[2025-05-02T02:22:33.277+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: Finished task 0.0 in stage 40.0 (TID 416). 10056 bytes result sent to driver
[2025-05-02T02:22:33.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 417) (***-scheduler, executor driver, partition 1, NODE_LOCAL, 10315 bytes)
[2025-05-02T02:22:33.280+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 416) in 41 ms on ***-scheduler (executor driver) (1/2)
[2025-05-02T02:22:33.281+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: Running task 1.0 in stage 40.0 (TID 417)
[2025-05-02T02:22:33.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO ShuffleBlockFetcherIterator: Getting 1 (523.7 KiB) non-empty blocks including 1 (523.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:33.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:33.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 19.426648 ms
[2025-05-02T02:22:33.356+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: Finished task 1.0 in stage 40.0 (TID 417). 463670 bytes result sent to driver
[2025-05-02T02:22:33.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 417) in 79 ms on ***-scheduler (executor driver) (2/2)
[2025-05-02T02:22:33.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-02T02:22:33.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: ResultStage 40 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.129 s
[2025-05-02T02:22:33.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:33.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
[2025-05-02T02:22:33.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Job 22 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.140078 s
[2025-05-02T02:22:33.367+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 4.874361 ms
[2025-05-02T02:22:33.387+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 16.3 MiB, free 398.3 MiB)
[2025-05-02T02:22:33.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Removed broadcast_37_piece0 on ***-scheduler:33063 in memory (size: 33.5 KiB, free: 433.8 MiB)
[2025-05-02T02:22:33.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Removed broadcast_33_piece0 on ***-scheduler:33063 in memory (size: 22.0 KiB, free: 433.8 MiB)
[2025-05-02T02:22:33.410+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Removed broadcast_36_piece0 on ***-scheduler:33063 in memory (size: 24.2 KiB, free: 433.8 MiB)
[2025-05-02T02:22:33.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 531.9 KiB, free 398.1 MiB)
[2025-05-02T02:22:33.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Removed broadcast_31_piece0 on ***-scheduler:33063 in memory (size: 8.0 KiB, free: 433.8 MiB)
[2025-05-02T02:22:33.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on ***-scheduler:33063 (size: 531.9 KiB, free: 433.3 MiB)
[2025-05-02T02:22:33.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO SparkContext: Created broadcast 38 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:33.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Key),EqualTo(Allergy_Key,0000000000000000000000000000000000000000000000000000000000000000),IsNotNull(Allergy_Group_Key)
[2025-05-02T02:22:33.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Key#2092),(Allergy_Key#2092 = 0000000000000000000000000000000000000000000000000000000000000000),isnotnull(Allergy_Group_Key#2091)
[2025-05-02T02:22:33.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 9.525835 ms
[2025-05-02T02:22:33.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 206.6 KiB, free 397.9 MiB)
[2025-05-02T02:22:33.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 397.9 MiB)
[2025-05-02T02:22:33.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 433.3 MiB)
[2025-05-02T02:22:33.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO SparkContext: Created broadcast 39 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:33.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4637540 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:33.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:33.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Got job 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:33.543+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Final stage: ResultStage 41 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:33.544+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:33.545+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:33.546+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[121] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:33.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 21.5 KiB, free 397.9 MiB)
[2025-05-02T02:22:33.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 397.8 MiB)
[2025-05-02T02:22:33.564+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on ***-scheduler:33063 (size: 9.1 KiB, free: 433.3 MiB)
[2025-05-02T02:22:33.565+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:33.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[121] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:33.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-02T02:22:33.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 418) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10920 bytes)
[2025-05-02T02:22:33.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: Running task 0.0 in stage 41.0 (TID 418)
[2025-05-02T02:22:33.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO CodeGenerator: Code generated in 8.106807 ms
[2025-05-02T02:22:33.593+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/part-00000-ce72f691-2bbf-4528-b5d4-495c385509f4-c000.snappy.parquet, range: 0-443236, partition values: [empty row]
[2025-05-02T02:22:33.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:33.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO FilterCompat: Filtering using predicate: and(and(noteq(Allergy_Key, null), eq(Allergy_Key, Binary{"0000000000000000000000000000000000000000000000000000000000000000"})), noteq(Allergy_Group_Key, null))
[2025-05-02T02:22:33.807+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:33.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO BlockManagerInfo: Added rdd_120_0 on disk on ***-scheduler:33063 (size: 435.3 KiB)
[2025-05-02T02:22:33.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:33 INFO Executor: 1 block locks were not released by task 0.0 in stage 41.0 (TID 418)
[2025-05-02T02:22:33.997+0000] {spark_submit.py:649} INFO - [rdd_120_0]
[2025-05-02T02:22:34.007+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 0.0 in stage 41.0 (TID 418). 1722 bytes result sent to driver
[2025-05-02T02:22:34.008+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 418) in 443 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:34.010+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-02T02:22:34.011+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: ResultStage 41 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.465 s
[2025-05-02T02:22:34.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:34.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
[2025-05-02T02:22:34.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Job 23 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.471849 s
[2025-05-02T02:22:34.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:34.016+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO MergeIntoCommand: DELTA: MERGE operation - scanning files for matches
[2025-05-02T02:22:34.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Snapshot: DELTA: Compute snapshot for version: 0
[2025-05-02T02:22:34.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Registering RDD 125 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 10
[2025-05-02T02:22:34.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Got map stage job 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:34.118+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Final stage: ShuffleMapStage 43 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:34.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
[2025-05-02T02:22:34.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:34.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[125] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:34.129+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 605.6 KiB, free 397.3 MiB)
[2025-05-02T02:22:34.140+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManagerInfo: Removed broadcast_40_piece0 on ***-scheduler:33063 in memory (size: 9.1 KiB, free: 433.3 MiB)
[2025-05-02T02:22:34.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 138.9 KiB, free 397.2 MiB)
[2025-05-02T02:22:34.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on ***-scheduler:33063 (size: 138.9 KiB, free: 433.1 MiB)
[2025-05-02T02:22:34.144+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:34.145+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[125] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:34.146+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSchedulerImpl: Adding task set 43.0 with 50 tasks resource profile 0
[2025-05-02T02:22:34.147+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 419) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.148+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 0.0 in stage 43.0 (TID 419)
[2025-05-02T02:22:34.159+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_0 locally
[2025-05-02T02:22:34.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO CodeGenerator: Code generated in 15.272457 ms
[2025-05-02T02:22:34.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO CodeGenerator: Code generated in 6.619072 ms
[2025-05-02T02:22:34.217+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 0.0 in stage 43.0 (TID 419). 4663 bytes result sent to driver
[2025-05-02T02:22:34.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 420) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 419) in 73 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:34.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 1.0 in stage 43.0 (TID 420)
[2025-05-02T02:22:34.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_1 locally
[2025-05-02T02:22:34.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 1.0 in stage 43.0 (TID 420). 4577 bytes result sent to driver
[2025-05-02T02:22:34.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 421) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.256+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 420) in 38 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:34.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 2.0 in stage 43.0 (TID 421)
[2025-05-02T02:22:34.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_2 locally
[2025-05-02T02:22:34.290+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 2.0 in stage 43.0 (TID 421). 4577 bytes result sent to driver
[2025-05-02T02:22:34.291+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 422) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.293+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 421) in 37 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:34.294+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 3.0 in stage 43.0 (TID 422)
[2025-05-02T02:22:34.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_3 locally
[2025-05-02T02:22:34.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 3.0 in stage 43.0 (TID 422). 4577 bytes result sent to driver
[2025-05-02T02:22:34.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 4.0 in stage 43.0 (TID 423) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 4.0 in stage 43.0 (TID 423)
[2025-05-02T02:22:34.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 422) in 38 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:34.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_4 locally
[2025-05-02T02:22:34.369+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 4.0 in stage 43.0 (TID 423). 4577 bytes result sent to driver
[2025-05-02T02:22:34.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 5.0 in stage 43.0 (TID 424) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.372+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 5.0 in stage 43.0 (TID 424)
[2025-05-02T02:22:34.373+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 4.0 in stage 43.0 (TID 423) in 42 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:34.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_5 locally
[2025-05-02T02:22:34.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 5.0 in stage 43.0 (TID 424). 4577 bytes result sent to driver
[2025-05-02T02:22:34.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 6.0 in stage 43.0 (TID 425) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 5.0 in stage 43.0 (TID 424) in 50 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:34.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 6.0 in stage 43.0 (TID 425)
[2025-05-02T02:22:34.443+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_6 locally
[2025-05-02T02:22:34.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 6.0 in stage 43.0 (TID 425). 4620 bytes result sent to driver
[2025-05-02T02:22:34.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 7.0 in stage 43.0 (TID 426) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 6.0 in stage 43.0 (TID 425) in 59 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:34.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 7.0 in stage 43.0 (TID 426)
[2025-05-02T02:22:34.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_7 locally
[2025-05-02T02:22:34.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 7.0 in stage 43.0 (TID 426). 4577 bytes result sent to driver
[2025-05-02T02:22:34.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 8.0 in stage 43.0 (TID 427) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 8.0 in stage 43.0 (TID 427)
[2025-05-02T02:22:34.521+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 7.0 in stage 43.0 (TID 426) in 43 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:34.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_8 locally
[2025-05-02T02:22:34.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 8.0 in stage 43.0 (TID 427). 4577 bytes result sent to driver
[2025-05-02T02:22:34.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 9.0 in stage 43.0 (TID 428) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 8.0 in stage 43.0 (TID 427) in 44 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:34.564+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 9.0 in stage 43.0 (TID 428)
[2025-05-02T02:22:34.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_9 locally
[2025-05-02T02:22:34.617+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 9.0 in stage 43.0 (TID 428). 4577 bytes result sent to driver
[2025-05-02T02:22:34.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 10.0 in stage 43.0 (TID 429) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 9.0 in stage 43.0 (TID 428) in 57 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:34.620+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 10.0 in stage 43.0 (TID 429)
[2025-05-02T02:22:34.642+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_10 locally
[2025-05-02T02:22:34.666+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 10.0 in stage 43.0 (TID 429). 4620 bytes result sent to driver
[2025-05-02T02:22:34.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 11.0 in stage 43.0 (TID 430) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 10.0 in stage 43.0 (TID 429) in 51 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:34.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 11.0 in stage 43.0 (TID 430)
[2025-05-02T02:22:34.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_11 locally
[2025-05-02T02:22:34.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 11.0 in stage 43.0 (TID 430). 4620 bytes result sent to driver
[2025-05-02T02:22:34.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 12.0 in stage 43.0 (TID 431) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 12.0 in stage 43.0 (TID 431)
[2025-05-02T02:22:34.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 11.0 in stage 43.0 (TID 430) in 41 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:34.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_12 locally
[2025-05-02T02:22:34.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 12.0 in stage 43.0 (TID 431). 4663 bytes result sent to driver
[2025-05-02T02:22:34.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 13.0 in stage 43.0 (TID 432) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.771+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 12.0 in stage 43.0 (TID 431) in 62 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:34.772+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 13.0 in stage 43.0 (TID 432)
[2025-05-02T02:22:34.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_13 locally
[2025-05-02T02:22:34.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 13.0 in stage 43.0 (TID 432). 4663 bytes result sent to driver
[2025-05-02T02:22:34.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 14.0 in stage 43.0 (TID 433) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 13.0 in stage 43.0 (TID 432) in 58 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:34.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 14.0 in stage 43.0 (TID 433)
[2025-05-02T02:22:34.841+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_14 locally
[2025-05-02T02:22:34.877+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 14.0 in stage 43.0 (TID 433). 4577 bytes result sent to driver
[2025-05-02T02:22:34.879+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 15.0 in stage 43.0 (TID 434) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 14.0 in stage 43.0 (TID 433) in 54 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:34.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 15.0 in stage 43.0 (TID 434)
[2025-05-02T02:22:34.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_15 locally
[2025-05-02T02:22:34.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 15.0 in stage 43.0 (TID 434). 4577 bytes result sent to driver
[2025-05-02T02:22:34.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 16.0 in stage 43.0 (TID 435) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:34.927+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 15.0 in stage 43.0 (TID 434) in 47 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:34.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 16.0 in stage 43.0 (TID 435)
[2025-05-02T02:22:34.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO BlockManager: Found block rdd_67_16 locally
[2025-05-02T02:22:34.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Finished task 16.0 in stage 43.0 (TID 435). 4620 bytes result sent to driver
[2025-05-02T02:22:34.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Starting task 17.0 in stage 43.0 (TID 436) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO TaskSetManager: Finished task 16.0 in stage 43.0 (TID 435) in 74 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:35.001+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:34 INFO Executor: Running task 17.0 in stage 43.0 (TID 436)
[2025-05-02T02:22:35.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_17 locally
[2025-05-02T02:22:35.054+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 17.0 in stage 43.0 (TID 436). 4577 bytes result sent to driver
[2025-05-02T02:22:35.056+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 18.0 in stage 43.0 (TID 437) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 17.0 in stage 43.0 (TID 436) in 59 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:35.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 18.0 in stage 43.0 (TID 437)
[2025-05-02T02:22:35.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_18 locally
[2025-05-02T02:22:35.105+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 18.0 in stage 43.0 (TID 437). 4577 bytes result sent to driver
[2025-05-02T02:22:35.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 19.0 in stage 43.0 (TID 438) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.108+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 19.0 in stage 43.0 (TID 438)
[2025-05-02T02:22:35.109+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 18.0 in stage 43.0 (TID 437) in 52 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:35.129+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_19 locally
[2025-05-02T02:22:35.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 19.0 in stage 43.0 (TID 438). 4577 bytes result sent to driver
[2025-05-02T02:22:35.165+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 20.0 in stage 43.0 (TID 439) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 19.0 in stage 43.0 (TID 438) in 59 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:35.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 20.0 in stage 43.0 (TID 439)
[2025-05-02T02:22:35.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_20 locally
[2025-05-02T02:22:35.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 20.0 in stage 43.0 (TID 439). 4663 bytes result sent to driver
[2025-05-02T02:22:35.224+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 21.0 in stage 43.0 (TID 440) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 20.0 in stage 43.0 (TID 439) in 60 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:35.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 21.0 in stage 43.0 (TID 440)
[2025-05-02T02:22:35.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_21 locally
[2025-05-02T02:22:35.263+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 21.0 in stage 43.0 (TID 440). 4577 bytes result sent to driver
[2025-05-02T02:22:35.264+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 22.0 in stage 43.0 (TID 441) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 22.0 in stage 43.0 (TID 441)
[2025-05-02T02:22:35.266+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 21.0 in stage 43.0 (TID 440) in 41 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:35.278+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_22 locally
[2025-05-02T02:22:35.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 22.0 in stage 43.0 (TID 441). 4577 bytes result sent to driver
[2025-05-02T02:22:35.304+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 23.0 in stage 43.0 (TID 442) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 22.0 in stage 43.0 (TID 441) in 41 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:35.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 23.0 in stage 43.0 (TID 442)
[2025-05-02T02:22:35.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_23 locally
[2025-05-02T02:22:35.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 23.0 in stage 43.0 (TID 442). 4620 bytes result sent to driver
[2025-05-02T02:22:35.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 24.0 in stage 43.0 (TID 443) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 23.0 in stage 43.0 (TID 442) in 49 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:35.355+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 24.0 in stage 43.0 (TID 443)
[2025-05-02T02:22:35.367+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_24 locally
[2025-05-02T02:22:35.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 24.0 in stage 43.0 (TID 443). 4577 bytes result sent to driver
[2025-05-02T02:22:35.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 25.0 in stage 43.0 (TID 444) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 24.0 in stage 43.0 (TID 443) in 40 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:35.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 25.0 in stage 43.0 (TID 444)
[2025-05-02T02:22:35.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_25 locally
[2025-05-02T02:22:35.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 25.0 in stage 43.0 (TID 444). 4663 bytes result sent to driver
[2025-05-02T02:22:35.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 26.0 in stage 43.0 (TID 445) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 26.0 in stage 43.0 (TID 445)
[2025-05-02T02:22:35.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 25.0 in stage 43.0 (TID 444) in 47 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:35.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_26 locally
[2025-05-02T02:22:35.481+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 26.0 in stage 43.0 (TID 445). 4663 bytes result sent to driver
[2025-05-02T02:22:35.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 27.0 in stage 43.0 (TID 446) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 26.0 in stage 43.0 (TID 445) in 45 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:35.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 27.0 in stage 43.0 (TID 446)
[2025-05-02T02:22:35.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_27 locally
[2025-05-02T02:22:35.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 27.0 in stage 43.0 (TID 446). 4577 bytes result sent to driver
[2025-05-02T02:22:35.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 28.0 in stage 43.0 (TID 447) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.521+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 27.0 in stage 43.0 (TID 446) in 37 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:35.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 28.0 in stage 43.0 (TID 447)
[2025-05-02T02:22:35.532+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_28 locally
[2025-05-02T02:22:35.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 28.0 in stage 43.0 (TID 447). 4577 bytes result sent to driver
[2025-05-02T02:22:35.556+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 29.0 in stage 43.0 (TID 448) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.557+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 28.0 in stage 43.0 (TID 447) in 38 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:35.558+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 29.0 in stage 43.0 (TID 448)
[2025-05-02T02:22:35.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_29 locally
[2025-05-02T02:22:35.594+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 29.0 in stage 43.0 (TID 448). 4577 bytes result sent to driver
[2025-05-02T02:22:35.595+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 30.0 in stage 43.0 (TID 449) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.596+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 29.0 in stage 43.0 (TID 448) in 40 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:35.597+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 30.0 in stage 43.0 (TID 449)
[2025-05-02T02:22:35.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_30 locally
[2025-05-02T02:22:35.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 30.0 in stage 43.0 (TID 449). 4577 bytes result sent to driver
[2025-05-02T02:22:35.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 31.0 in stage 43.0 (TID 450) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 30.0 in stage 43.0 (TID 449) in 43 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:35.639+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 31.0 in stage 43.0 (TID 450)
[2025-05-02T02:22:35.654+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_31 locally
[2025-05-02T02:22:35.697+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 31.0 in stage 43.0 (TID 450). 4663 bytes result sent to driver
[2025-05-02T02:22:35.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 32.0 in stage 43.0 (TID 451) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 32.0 in stage 43.0 (TID 451)
[2025-05-02T02:22:35.700+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 31.0 in stage 43.0 (TID 450) in 62 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:35.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_32 locally
[2025-05-02T02:22:35.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 32.0 in stage 43.0 (TID 451). 4577 bytes result sent to driver
[2025-05-02T02:22:35.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 33.0 in stage 43.0 (TID 452) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 32.0 in stage 43.0 (TID 451) in 36 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:35.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 33.0 in stage 43.0 (TID 452)
[2025-05-02T02:22:35.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_33 locally
[2025-05-02T02:22:35.782+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 33.0 in stage 43.0 (TID 452). 4577 bytes result sent to driver
[2025-05-02T02:22:35.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 34.0 in stage 43.0 (TID 453) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.784+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 33.0 in stage 43.0 (TID 452) in 51 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:35.785+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 34.0 in stage 43.0 (TID 453)
[2025-05-02T02:22:35.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_34 locally
[2025-05-02T02:22:35.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 34.0 in stage 43.0 (TID 453). 4577 bytes result sent to driver
[2025-05-02T02:22:35.830+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 35.0 in stage 43.0 (TID 454) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 34.0 in stage 43.0 (TID 453) in 48 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:35.833+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 35.0 in stage 43.0 (TID 454)
[2025-05-02T02:22:35.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_35 locally
[2025-05-02T02:22:35.877+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 35.0 in stage 43.0 (TID 454). 4620 bytes result sent to driver
[2025-05-02T02:22:35.878+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 36.0 in stage 43.0 (TID 455) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.879+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 36.0 in stage 43.0 (TID 455)
[2025-05-02T02:22:35.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 35.0 in stage 43.0 (TID 454) in 49 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:35.889+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_36 locally
[2025-05-02T02:22:35.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 36.0 in stage 43.0 (TID 455). 4577 bytes result sent to driver
[2025-05-02T02:22:35.911+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 37.0 in stage 43.0 (TID 456) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.911+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 36.0 in stage 43.0 (TID 455) in 34 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:35.912+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 37.0 in stage 43.0 (TID 456)
[2025-05-02T02:22:35.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_37 locally
[2025-05-02T02:22:35.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 37.0 in stage 43.0 (TID 456). 4577 bytes result sent to driver
[2025-05-02T02:22:35.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 38.0 in stage 43.0 (TID 457) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.945+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 38.0 in stage 43.0 (TID 457)
[2025-05-02T02:22:35.946+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 37.0 in stage 43.0 (TID 456) in 33 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:35.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_38 locally
[2025-05-02T02:22:35.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Finished task 38.0 in stage 43.0 (TID 457). 4663 bytes result sent to driver
[2025-05-02T02:22:35.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Starting task 39.0 in stage 43.0 (TID 458) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:35.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO TaskSetManager: Finished task 38.0 in stage 43.0 (TID 457) in 39 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:35.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO Executor: Running task 39.0 in stage 43.0 (TID 458)
[2025-05-02T02:22:35.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:35 INFO BlockManager: Found block rdd_67_39 locally
[2025-05-02T02:22:36.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 39.0 in stage 43.0 (TID 458). 4577 bytes result sent to driver
[2025-05-02T02:22:36.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 40.0 in stage 43.0 (TID 459) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.028+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 39.0 in stage 43.0 (TID 458) in 46 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:36.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 40.0 in stage 43.0 (TID 459)
[2025-05-02T02:22:36.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_40 locally
[2025-05-02T02:22:36.064+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 40.0 in stage 43.0 (TID 459). 4663 bytes result sent to driver
[2025-05-02T02:22:36.065+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 41.0 in stage 43.0 (TID 460) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 40.0 in stage 43.0 (TID 459) in 39 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:36.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 41.0 in stage 43.0 (TID 460)
[2025-05-02T02:22:36.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_41 locally
[2025-05-02T02:22:36.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 41.0 in stage 43.0 (TID 460). 4577 bytes result sent to driver
[2025-05-02T02:22:36.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 42.0 in stage 43.0 (TID 461) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 41.0 in stage 43.0 (TID 460) in 32 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:36.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 42.0 in stage 43.0 (TID 461)
[2025-05-02T02:22:36.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_42 locally
[2025-05-02T02:22:36.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 42.0 in stage 43.0 (TID 461). 4663 bytes result sent to driver
[2025-05-02T02:22:36.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 43.0 in stage 43.0 (TID 462) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.140+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 42.0 in stage 43.0 (TID 461) in 43 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:36.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 43.0 in stage 43.0 (TID 462)
[2025-05-02T02:22:36.154+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_43 locally
[2025-05-02T02:22:36.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 43.0 in stage 43.0 (TID 462). 4663 bytes result sent to driver
[2025-05-02T02:22:36.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 44.0 in stage 43.0 (TID 463) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.191+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 43.0 in stage 43.0 (TID 462) in 51 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:36.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 44.0 in stage 43.0 (TID 463)
[2025-05-02T02:22:36.201+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_44 locally
[2025-05-02T02:22:36.225+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 44.0 in stage 43.0 (TID 463). 4577 bytes result sent to driver
[2025-05-02T02:22:36.226+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 45.0 in stage 43.0 (TID 464) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.227+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 45.0 in stage 43.0 (TID 464)
[2025-05-02T02:22:36.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 44.0 in stage 43.0 (TID 463) in 37 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:36.238+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_45 locally
[2025-05-02T02:22:36.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 45.0 in stage 43.0 (TID 464). 4577 bytes result sent to driver
[2025-05-02T02:22:36.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 46.0 in stage 43.0 (TID 465) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.262+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 46.0 in stage 43.0 (TID 465)
[2025-05-02T02:22:36.263+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 45.0 in stage 43.0 (TID 464) in 35 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:36.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_46 locally
[2025-05-02T02:22:36.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 46.0 in stage 43.0 (TID 465). 4620 bytes result sent to driver
[2025-05-02T02:22:36.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 47.0 in stage 43.0 (TID 466) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 46.0 in stage 43.0 (TID 465) in 39 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:36.301+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 47.0 in stage 43.0 (TID 466)
[2025-05-02T02:22:36.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_47 locally
[2025-05-02T02:22:36.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 47.0 in stage 43.0 (TID 466). 4577 bytes result sent to driver
[2025-05-02T02:22:36.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 48.0 in stage 43.0 (TID 467) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 48.0 in stage 43.0 (TID 467)
[2025-05-02T02:22:36.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 47.0 in stage 43.0 (TID 466) in 31 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:36.341+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_48 locally
[2025-05-02T02:22:36.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 48.0 in stage 43.0 (TID 467). 4577 bytes result sent to driver
[2025-05-02T02:22:36.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 49.0 in stage 43.0 (TID 468) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:36.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 49.0 in stage 43.0 (TID 468)
[2025-05-02T02:22:36.365+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 48.0 in stage 43.0 (TID 467) in 35 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:36.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_67_49 locally
[2025-05-02T02:22:36.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 49.0 in stage 43.0 (TID 468). 4620 bytes result sent to driver
[2025-05-02T02:22:36.401+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 49.0 in stage 43.0 (TID 468) in 38 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:36.402+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-02T02:22:36.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: ShuffleMapStage 43 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.281 s
[2025-05-02T02:22:36.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:36.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:36.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:36.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:36.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:36.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Got job 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:36.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:36.435+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-05-02T02:22:36.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:36.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[128] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:36.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 537.2 KiB, free 396.6 MiB)
[2025-05-02T02:22:36.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 125.5 KiB, free 396.5 MiB)
[2025-05-02T02:22:36.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on ***-scheduler:33063 (size: 125.5 KiB, free: 433.0 MiB)
[2025-05-02T02:22:36.451+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:36.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[128] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:36.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-05-02T02:22:36.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 469) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 0.0 in stage 46.0 (TID 469)
[2025-05-02T02:22:36.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO ShuffleBlockFetcherIterator: Getting 50 (4.6 KiB) non-empty blocks including 50 (4.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:36.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:36.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO CodeGenerator: Code generated in 5.647138 ms
[2025-05-02T02:22:36.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 0.0 in stage 46.0 (TID 469). 6918 bytes result sent to driver
[2025-05-02T02:22:36.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 469) in 64 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:36.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-05-02T02:22:36.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: ResultStage 46 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.083 s
[2025-05-02T02:22:36.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:36.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-05-02T02:22:36.521+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Job 25 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.086951 s
[2025-05-02T02:22:36.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Snapshot: DELTA: Done
[2025-05-02T02:22:36.564+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO CodeGenerator: Code generated in 11.982883 ms
[2025-05-02T02:22:36.586+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:36.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Got job 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:36.589+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:36.590+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-02T02:22:36.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:36.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[131] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:36.603+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 707.2 KiB, free 395.8 MiB)
[2025-05-02T02:22:36.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 161.7 KiB, free 395.7 MiB)
[2025-05-02T02:22:36.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on ***-scheduler:33063 (size: 161.7 KiB, free: 432.9 MiB)
[2025-05-02T02:22:36.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:36.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 48 (MapPartitionsRDD[131] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:36.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSchedulerImpl: Adding task set 48.0 with 50 tasks resource profile 0
[2025-05-02T02:22:36.612+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 470) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.613+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 0.0 in stage 48.0 (TID 470)
[2025-05-02T02:22:36.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_0 locally
[2025-05-02T02:22:36.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO CodeGenerator: Code generated in 20.728416 ms
[2025-05-02T02:22:36.666+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO CodeGenerator: Code generated in 12.292069 ms
[2025-05-02T02:22:36.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 0.0 in stage 48.0 (TID 470). 4293 bytes result sent to driver
[2025-05-02T02:22:36.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 471) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 470) in 59 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:36.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 1.0 in stage 48.0 (TID 471)
[2025-05-02T02:22:36.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_1 locally
[2025-05-02T02:22:36.693+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 1.0 in stage 48.0 (TID 471). 4293 bytes result sent to driver
[2025-05-02T02:22:36.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 472) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 2.0 in stage 48.0 (TID 472)
[2025-05-02T02:22:36.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 471) in 26 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:36.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_2 locally
[2025-05-02T02:22:36.711+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 2.0 in stage 48.0 (TID 472). 4293 bytes result sent to driver
[2025-05-02T02:22:36.712+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 473) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.713+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 472) in 20 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:36.714+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 3.0 in stage 48.0 (TID 473)
[2025-05-02T02:22:36.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_3 locally
[2025-05-02T02:22:36.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 3.0 in stage 48.0 (TID 473). 4293 bytes result sent to driver
[2025-05-02T02:22:36.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 4.0 in stage 48.0 (TID 474) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 4.0 in stage 48.0 (TID 474)
[2025-05-02T02:22:36.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 473) in 22 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:36.746+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_4 locally
[2025-05-02T02:22:36.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 4.0 in stage 48.0 (TID 474). 4293 bytes result sent to driver
[2025-05-02T02:22:36.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 5.0 in stage 48.0 (TID 475) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 5.0 in stage 48.0 (TID 475)
[2025-05-02T02:22:36.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 4.0 in stage 48.0 (TID 474) in 19 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:36.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_5 locally
[2025-05-02T02:22:36.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 5.0 in stage 48.0 (TID 475). 4293 bytes result sent to driver
[2025-05-02T02:22:36.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 6.0 in stage 48.0 (TID 476) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 5.0 in stage 48.0 (TID 475) in 17 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:36.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 6.0 in stage 48.0 (TID 476)
[2025-05-02T02:22:36.779+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_6 locally
[2025-05-02T02:22:36.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 6.0 in stage 48.0 (TID 476). 4293 bytes result sent to driver
[2025-05-02T02:22:36.784+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 7.0 in stage 48.0 (TID 477) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.785+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 6.0 in stage 48.0 (TID 476) in 18 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:36.786+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 7.0 in stage 48.0 (TID 477)
[2025-05-02T02:22:36.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_7 locally
[2025-05-02T02:22:36.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 7.0 in stage 48.0 (TID 477). 4293 bytes result sent to driver
[2025-05-02T02:22:36.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 8.0 in stage 48.0 (TID 478) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 7.0 in stage 48.0 (TID 477) in 18 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:36.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 8.0 in stage 48.0 (TID 478)
[2025-05-02T02:22:36.813+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_8 locally
[2025-05-02T02:22:36.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 8.0 in stage 48.0 (TID 478). 4293 bytes result sent to driver
[2025-05-02T02:22:36.819+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 9.0 in stage 48.0 (TID 479) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.820+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 8.0 in stage 48.0 (TID 478) in 17 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:36.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 9.0 in stage 48.0 (TID 479)
[2025-05-02T02:22:36.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_9 locally
[2025-05-02T02:22:36.834+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 9.0 in stage 48.0 (TID 479). 4293 bytes result sent to driver
[2025-05-02T02:22:36.835+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 10.0 in stage 48.0 (TID 480) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 9.0 in stage 48.0 (TID 479) in 17 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:36.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 10.0 in stage 48.0 (TID 480)
[2025-05-02T02:22:36.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_10 locally
[2025-05-02T02:22:36.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 10.0 in stage 48.0 (TID 480). 4293 bytes result sent to driver
[2025-05-02T02:22:36.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 11.0 in stage 48.0 (TID 481) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 11.0 in stage 48.0 (TID 481)
[2025-05-02T02:22:36.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 10.0 in stage 48.0 (TID 480) in 22 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:36.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_11 locally
[2025-05-02T02:22:36.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 11.0 in stage 48.0 (TID 481). 4582 bytes result sent to driver
[2025-05-02T02:22:36.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 12.0 in stage 48.0 (TID 482) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManagerInfo: Removed broadcast_42_piece0 on ***-scheduler:33063 in memory (size: 125.5 KiB, free: 433.0 MiB)
[2025-05-02T02:22:36.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 12.0 in stage 48.0 (TID 482)
[2025-05-02T02:22:36.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 11.0 in stage 48.0 (TID 481) in 25 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:36.891+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_12 locally
[2025-05-02T02:22:36.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 12.0 in stage 48.0 (TID 482). 4293 bytes result sent to driver
[2025-05-02T02:22:36.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 13.0 in stage 48.0 (TID 483) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 12.0 in stage 48.0 (TID 482) in 17 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:36.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 13.0 in stage 48.0 (TID 483)
[2025-05-02T02:22:36.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_13 locally
[2025-05-02T02:22:36.912+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 13.0 in stage 48.0 (TID 483). 4293 bytes result sent to driver
[2025-05-02T02:22:36.913+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 14.0 in stage 48.0 (TID 484) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.914+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 13.0 in stage 48.0 (TID 483) in 17 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:36.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 14.0 in stage 48.0 (TID 484)
[2025-05-02T02:22:36.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_14 locally
[2025-05-02T02:22:36.928+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 14.0 in stage 48.0 (TID 484). 4293 bytes result sent to driver
[2025-05-02T02:22:36.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 15.0 in stage 48.0 (TID 485) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 14.0 in stage 48.0 (TID 484) in 17 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:36.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 15.0 in stage 48.0 (TID 485)
[2025-05-02T02:22:36.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_15 locally
[2025-05-02T02:22:36.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 15.0 in stage 48.0 (TID 485). 4293 bytes result sent to driver
[2025-05-02T02:22:36.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 16.0 in stage 48.0 (TID 486) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 16.0 in stage 48.0 (TID 486)
[2025-05-02T02:22:36.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 15.0 in stage 48.0 (TID 485) in 22 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:36.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_16 locally
[2025-05-02T02:22:36.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 16.0 in stage 48.0 (TID 486). 4293 bytes result sent to driver
[2025-05-02T02:22:36.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 17.0 in stage 48.0 (TID 487) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 17.0 in stage 48.0 (TID 487)
[2025-05-02T02:22:36.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 16.0 in stage 48.0 (TID 486) in 17 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:36.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_17 locally
[2025-05-02T02:22:36.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 17.0 in stage 48.0 (TID 487). 4293 bytes result sent to driver
[2025-05-02T02:22:36.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 18.0 in stage 48.0 (TID 488) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:36.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 18.0 in stage 48.0 (TID 488)
[2025-05-02T02:22:36.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 17.0 in stage 48.0 (TID 487) in 17 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:36.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO BlockManager: Found block rdd_71_18 locally
[2025-05-02T02:22:36.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Finished task 18.0 in stage 48.0 (TID 488). 4293 bytes result sent to driver
[2025-05-02T02:22:36.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Starting task 19.0 in stage 48.0 (TID 489) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO Executor: Running task 19.0 in stage 48.0 (TID 489)
[2025-05-02T02:22:37.001+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:36 INFO TaskSetManager: Finished task 18.0 in stage 48.0 (TID 488) in 16 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:37.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_19 locally
[2025-05-02T02:22:37.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 19.0 in stage 48.0 (TID 489). 4293 bytes result sent to driver
[2025-05-02T02:22:37.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 20.0 in stage 48.0 (TID 490) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 20.0 in stage 48.0 (TID 490)
[2025-05-02T02:22:37.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 19.0 in stage 48.0 (TID 489) in 23 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:37.034+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_20 locally
[2025-05-02T02:22:37.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 20.0 in stage 48.0 (TID 490). 4293 bytes result sent to driver
[2025-05-02T02:22:37.042+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 21.0 in stage 48.0 (TID 491) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.042+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 21.0 in stage 48.0 (TID 491)
[2025-05-02T02:22:37.043+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 20.0 in stage 48.0 (TID 490) in 22 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:37.052+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_21 locally
[2025-05-02T02:22:37.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 21.0 in stage 48.0 (TID 491). 4293 bytes result sent to driver
[2025-05-02T02:22:37.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 22.0 in stage 48.0 (TID 492) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 22.0 in stage 48.0 (TID 492)
[2025-05-02T02:22:37.060+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 21.0 in stage 48.0 (TID 491) in 17 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:37.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_22 locally
[2025-05-02T02:22:37.072+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 22.0 in stage 48.0 (TID 492). 4293 bytes result sent to driver
[2025-05-02T02:22:37.073+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 23.0 in stage 48.0 (TID 493) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 23.0 in stage 48.0 (TID 493)
[2025-05-02T02:22:37.075+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 22.0 in stage 48.0 (TID 492) in 16 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:37.083+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_23 locally
[2025-05-02T02:22:37.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 23.0 in stage 48.0 (TID 493). 4293 bytes result sent to driver
[2025-05-02T02:22:37.088+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 24.0 in stage 48.0 (TID 494) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 23.0 in stage 48.0 (TID 493) in 16 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:37.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 24.0 in stage 48.0 (TID 494)
[2025-05-02T02:22:37.104+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_24 locally
[2025-05-02T02:22:37.109+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 24.0 in stage 48.0 (TID 494). 4336 bytes result sent to driver
[2025-05-02T02:22:37.110+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 25.0 in stage 48.0 (TID 495) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.111+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 25.0 in stage 48.0 (TID 495)
[2025-05-02T02:22:37.112+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 24.0 in stage 48.0 (TID 494) in 23 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:37.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_25 locally
[2025-05-02T02:22:37.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 25.0 in stage 48.0 (TID 495). 4293 bytes result sent to driver
[2025-05-02T02:22:37.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 26.0 in stage 48.0 (TID 496) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.126+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 25.0 in stage 48.0 (TID 495) in 16 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:37.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 26.0 in stage 48.0 (TID 496)
[2025-05-02T02:22:37.135+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_26 locally
[2025-05-02T02:22:37.140+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 26.0 in stage 48.0 (TID 496). 4293 bytes result sent to driver
[2025-05-02T02:22:37.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 27.0 in stage 48.0 (TID 497) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 27.0 in stage 48.0 (TID 497)
[2025-05-02T02:22:37.143+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 26.0 in stage 48.0 (TID 496) in 17 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:37.151+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_27 locally
[2025-05-02T02:22:37.155+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 27.0 in stage 48.0 (TID 497). 4293 bytes result sent to driver
[2025-05-02T02:22:37.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 28.0 in stage 48.0 (TID 498) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 28.0 in stage 48.0 (TID 498)
[2025-05-02T02:22:37.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 27.0 in stage 48.0 (TID 497) in 16 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:37.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_28 locally
[2025-05-02T02:22:37.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 28.0 in stage 48.0 (TID 498). 4293 bytes result sent to driver
[2025-05-02T02:22:37.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 29.0 in stage 48.0 (TID 499) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.172+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 29.0 in stage 48.0 (TID 499)
[2025-05-02T02:22:37.172+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 28.0 in stage 48.0 (TID 498) in 16 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:37.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_29 locally
[2025-05-02T02:22:37.186+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 29.0 in stage 48.0 (TID 499). 4293 bytes result sent to driver
[2025-05-02T02:22:37.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 30.0 in stage 48.0 (TID 500) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 29.0 in stage 48.0 (TID 499) in 17 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:37.188+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 30.0 in stage 48.0 (TID 500)
[2025-05-02T02:22:37.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_30 locally
[2025-05-02T02:22:37.201+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 30.0 in stage 48.0 (TID 500). 4293 bytes result sent to driver
[2025-05-02T02:22:37.202+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 31.0 in stage 48.0 (TID 501) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 31.0 in stage 48.0 (TID 501)
[2025-05-02T02:22:37.204+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 30.0 in stage 48.0 (TID 500) in 16 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:37.212+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_31 locally
[2025-05-02T02:22:37.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 31.0 in stage 48.0 (TID 501). 4293 bytes result sent to driver
[2025-05-02T02:22:37.217+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 32.0 in stage 48.0 (TID 502) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 32.0 in stage 48.0 (TID 502)
[2025-05-02T02:22:37.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 31.0 in stage 48.0 (TID 501) in 16 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:37.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_32 locally
[2025-05-02T02:22:37.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 32.0 in stage 48.0 (TID 502). 4293 bytes result sent to driver
[2025-05-02T02:22:37.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 33.0 in stage 48.0 (TID 503) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 33.0 in stage 48.0 (TID 503)
[2025-05-02T02:22:37.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 32.0 in stage 48.0 (TID 502) in 16 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:37.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_33 locally
[2025-05-02T02:22:37.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 33.0 in stage 48.0 (TID 503). 4293 bytes result sent to driver
[2025-05-02T02:22:37.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 34.0 in stage 48.0 (TID 504) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 34.0 in stage 48.0 (TID 504)
[2025-05-02T02:22:37.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 33.0 in stage 48.0 (TID 503) in 16 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:37.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_34 locally
[2025-05-02T02:22:37.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 34.0 in stage 48.0 (TID 504). 4336 bytes result sent to driver
[2025-05-02T02:22:37.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 35.0 in stage 48.0 (TID 505) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.272+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 35.0 in stage 48.0 (TID 505)
[2025-05-02T02:22:37.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 34.0 in stage 48.0 (TID 504) in 23 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:37.281+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_35 locally
[2025-05-02T02:22:37.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 35.0 in stage 48.0 (TID 505). 4293 bytes result sent to driver
[2025-05-02T02:22:37.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 36.0 in stage 48.0 (TID 506) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 35.0 in stage 48.0 (TID 505) in 16 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:37.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 36.0 in stage 48.0 (TID 506)
[2025-05-02T02:22:37.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_36 locally
[2025-05-02T02:22:37.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 36.0 in stage 48.0 (TID 506). 4293 bytes result sent to driver
[2025-05-02T02:22:37.304+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 37.0 in stage 48.0 (TID 507) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 37.0 in stage 48.0 (TID 507)
[2025-05-02T02:22:37.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 36.0 in stage 48.0 (TID 506) in 19 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:37.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_37 locally
[2025-05-02T02:22:37.319+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 37.0 in stage 48.0 (TID 507). 4293 bytes result sent to driver
[2025-05-02T02:22:37.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 38.0 in stage 48.0 (TID 508) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 38.0 in stage 48.0 (TID 508)
[2025-05-02T02:22:37.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 37.0 in stage 48.0 (TID 507) in 16 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:37.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_38 locally
[2025-05-02T02:22:37.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 38.0 in stage 48.0 (TID 508). 4293 bytes result sent to driver
[2025-05-02T02:22:37.335+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 39.0 in stage 48.0 (TID 509) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 38.0 in stage 48.0 (TID 508) in 16 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:37.337+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 39.0 in stage 48.0 (TID 509)
[2025-05-02T02:22:37.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_39 locally
[2025-05-02T02:22:37.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 39.0 in stage 48.0 (TID 509). 4293 bytes result sent to driver
[2025-05-02T02:22:37.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 40.0 in stage 48.0 (TID 510) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 39.0 in stage 48.0 (TID 509) in 16 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:37.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 40.0 in stage 48.0 (TID 510)
[2025-05-02T02:22:37.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_40 locally
[2025-05-02T02:22:37.365+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 40.0 in stage 48.0 (TID 510). 4293 bytes result sent to driver
[2025-05-02T02:22:37.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 41.0 in stage 48.0 (TID 511) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.367+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 40.0 in stage 48.0 (TID 510) in 17 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:37.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 41.0 in stage 48.0 (TID 511)
[2025-05-02T02:22:37.378+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_41 locally
[2025-05-02T02:22:37.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 41.0 in stage 48.0 (TID 511). 4293 bytes result sent to driver
[2025-05-02T02:22:37.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 42.0 in stage 48.0 (TID 512) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 42.0 in stage 48.0 (TID 512)
[2025-05-02T02:22:37.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 41.0 in stage 48.0 (TID 511) in 18 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:37.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_42 locally
[2025-05-02T02:22:37.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 42.0 in stage 48.0 (TID 512). 4293 bytes result sent to driver
[2025-05-02T02:22:37.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 43.0 in stage 48.0 (TID 513) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.401+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 43.0 in stage 48.0 (TID 513)
[2025-05-02T02:22:37.402+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 42.0 in stage 48.0 (TID 512) in 17 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:37.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_43 locally
[2025-05-02T02:22:37.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 43.0 in stage 48.0 (TID 513). 4336 bytes result sent to driver
[2025-05-02T02:22:37.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 44.0 in stage 48.0 (TID 514) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 44.0 in stage 48.0 (TID 514)
[2025-05-02T02:22:37.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 43.0 in stage 48.0 (TID 513) in 22 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:37.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_44 locally
[2025-05-02T02:22:37.435+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 44.0 in stage 48.0 (TID 514). 4293 bytes result sent to driver
[2025-05-02T02:22:37.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 45.0 in stage 48.0 (TID 515) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 45.0 in stage 48.0 (TID 515)
[2025-05-02T02:22:37.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 44.0 in stage 48.0 (TID 514) in 16 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:37.447+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_45 locally
[2025-05-02T02:22:37.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 45.0 in stage 48.0 (TID 515). 4293 bytes result sent to driver
[2025-05-02T02:22:37.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 46.0 in stage 48.0 (TID 516) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 45.0 in stage 48.0 (TID 515) in 17 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:37.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 46.0 in stage 48.0 (TID 516)
[2025-05-02T02:22:37.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_46 locally
[2025-05-02T02:22:37.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 46.0 in stage 48.0 (TID 516). 4293 bytes result sent to driver
[2025-05-02T02:22:37.468+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 47.0 in stage 48.0 (TID 517) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 47.0 in stage 48.0 (TID 517)
[2025-05-02T02:22:37.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 46.0 in stage 48.0 (TID 516) in 16 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:37.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_47 locally
[2025-05-02T02:22:37.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 47.0 in stage 48.0 (TID 517). 4293 bytes result sent to driver
[2025-05-02T02:22:37.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 48.0 in stage 48.0 (TID 518) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 48.0 in stage 48.0 (TID 518)
[2025-05-02T02:22:37.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 47.0 in stage 48.0 (TID 517) in 17 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:37.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_48 locally
[2025-05-02T02:22:37.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 48.0 in stage 48.0 (TID 518). 4293 bytes result sent to driver
[2025-05-02T02:22:37.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 49.0 in stage 48.0 (TID 519) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:37.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 48.0 in stage 48.0 (TID 518) in 16 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:37.502+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 49.0 in stage 48.0 (TID 519)
[2025-05-02T02:22:37.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_71_49 locally
[2025-05-02T02:22:37.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 49.0 in stage 48.0 (TID 519). 4293 bytes result sent to driver
[2025-05-02T02:22:37.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 49.0 in stage 48.0 (TID 519) in 16 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:37.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-02T02:22:37.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: ResultStage 48 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.924 s
[2025-05-02T02:22:37.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:37.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-02T02:22:37.521+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Job 26 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.930383 s
[2025-05-02T02:22:37.678+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:37.679+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:37.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO CodeGenerator: Code generated in 5.054049 ms
[2025-05-02T02:22:37.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:37.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Got job 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-02T02:22:37.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Final stage: ResultStage 49 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:37.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:37.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:37.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[133] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:37.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 9.2 KiB, free 396.3 MiB)
[2025-05-02T02:22:37.731+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 396.3 MiB)
[2025-05-02T02:22:37.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on ***-scheduler:33063 (size: 4.5 KiB, free: 433.0 MiB)
[2025-05-02T02:22:37.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:37.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManagerInfo: Removed broadcast_43_piece0 on ***-scheduler:33063 in memory (size: 161.7 KiB, free: 433.1 MiB)
[2025-05-02T02:22:37.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[133] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:37.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-05-02T02:22:37.738+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 520) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10016 bytes)
[2025-05-02T02:22:37.739+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 0.0 in stage 49.0 (TID 520)
[2025-05-02T02:22:37.740+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManager: Found block rdd_120_0 locally
[2025-05-02T02:22:37.744+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO CodeGenerator: Code generated in 4.834258 ms
[2025-05-02T02:22:37.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Finished task 0.0 in stage 49.0 (TID 520). 447320 bytes result sent to driver
[2025-05-02T02:22:37.765+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 520) in 31 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:37.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-05-02T02:22:37.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: ResultStage 49 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.043 s
[2025-05-02T02:22:37.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:37.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
[2025-05-02T02:22:37.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Job 27 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.047425 s
[2025-05-02T02:22:37.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 16.3 MiB, free 380.9 MiB)
[2025-05-02T02:22:37.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 515.4 KiB, free 380.4 MiB)
[2025-05-02T02:22:37.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on ***-scheduler:33063 (size: 515.4 KiB, free: 432.6 MiB)
[2025-05-02T02:22:37.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:37.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:37.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:37.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO CodeGenerator: Code generated in 24.714337 ms
[2025-05-02T02:22:37.860+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 206.5 KiB, free 380.2 MiB)
[2025-05-02T02:22:37.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 380.1 MiB)
[2025-05-02T02:22:37.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 432.6 MiB)
[2025-05-02T02:22:37.873+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO SparkContext: Created broadcast 46 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:37.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO CodeGenerator: Code generated in 12.735026 ms
[2025-05-02T02:22:37.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4637540 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:37.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Registering RDD 137 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 11
[2025-05-02T02:22:37.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Got map stage job 28 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:37.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Final stage: ShuffleMapStage 50 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:37.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:37.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:37.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[137] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:37.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 61.4 KiB, free 380.1 MiB)
[2025-05-02T02:22:37.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 380.1 MiB)
[2025-05-02T02:22:37.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on ***-scheduler:33063 (size: 27.2 KiB, free: 432.6 MiB)
[2025-05-02T02:22:37.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:37.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[137] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:37.960+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
[2025-05-02T02:22:37.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 521) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10909 bytes)
[2025-05-02T02:22:37.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO Executor: Running task 0.0 in stage 50.0 (TID 521)
[2025-05-02T02:22:37.992+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:37 INFO CodeGenerator: Code generated in 19.59634 ms
[2025-05-02T02:22:38.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 5.644202 ms
[2025-05-02T02:22:38.007+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 3.732474 ms
[2025-05-02T02:22:38.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Removed broadcast_44_piece0 on ***-scheduler:33063 in memory (size: 4.5 KiB, free: 432.6 MiB)
[2025-05-02T02:22:38.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 5.312181 ms
[2025-05-02T02:22:38.030+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/part-00000-ce72f691-2bbf-4528-b5d4-495c385509f4-c000.snappy.parquet, range: 0-443236, partition values: [empty row]
[2025-05-02T02:22:38.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:38.256+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Finished task 0.0 in stage 50.0 (TID 521). 4153 bytes result sent to driver
[2025-05-02T02:22:38.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 521) in 300 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:38.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool
[2025-05-02T02:22:38.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: ShuffleMapStage 50 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.306 s
[2025-05-02T02:22:38.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:38.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:38.262+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:38.263+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:38.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:38.275+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-02T02:22:38.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 10.028724 ms
[2025-05-02T02:22:38.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Registering RDD 140 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 12
[2025-05-02T02:22:38.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Got map stage job 29 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:38.315+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Final stage: ShuffleMapStage 52 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:38.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
[2025-05-02T02:22:38.317+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:38.318+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[140] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:38.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 65.0 KiB, free 380.0 MiB)
[2025-05-02T02:22:38.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 380.0 MiB)
[2025-05-02T02:22:38.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on ***-scheduler:33063 (size: 29.0 KiB, free: 432.5 MiB)
[2025-05-02T02:22:38.325+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:38.326+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[140] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:38.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-05-02T02:22:38.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 522) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:38.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Running task 0.0 in stage 52.0 (TID 522)
[2025-05-02T02:22:38.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO ShuffleBlockFetcherIterator: Getting 1 (64.8 KiB) non-empty blocks including 1 (64.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:38.343+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:38.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 10.253641 ms
[2025-05-02T02:22:38.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Finished task 0.0 in stage 52.0 (TID 522). 6885 bytes result sent to driver
[2025-05-02T02:22:38.378+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 522) in 51 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:38.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-05-02T02:22:38.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: ShuffleMapStage 52 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.060 s
[2025-05-02T02:22:38.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:38.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:38.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:38.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:38.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 8.60115 ms
[2025-05-02T02:22:38.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:38.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Got job 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:38.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:38.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
[2025-05-02T02:22:38.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:38.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[143] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:38.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 14.5 KiB, free 380.0 MiB)
[2025-05-02T02:22:38.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 380.0 MiB)
[2025-05-02T02:22:38.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on ***-scheduler:33063 (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-02T02:22:38.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:38.425+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[143] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:38.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-05-02T02:22:38.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 523) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:38.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Running task 0.0 in stage 55.0 (TID 523)
[2025-05-02T02:22:38.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:38.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:38.435+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 6.62565 ms
[2025-05-02T02:22:38.446+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Finished task 0.0 in stage 55.0 (TID 523). 4075 bytes result sent to driver
[2025-05-02T02:22:38.447+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Removed broadcast_47_piece0 on ***-scheduler:33063 in memory (size: 27.2 KiB, free: 432.6 MiB)
[2025-05-02T02:22:38.448+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 523) in 24 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:38.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-02T02:22:38.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: ResultStage 55 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.029 s
[2025-05-02T02:22:38.451+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:38.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-02T02:22:38.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Job 30 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.032405 s
[2025-05-02T02:22:38.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Removed broadcast_48_piece0 on ***-scheduler:33063 in memory (size: 29.0 KiB, free: 432.6 MiB)
[2025-05-02T02:22:38.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 5.435442 ms
[2025-05-02T02:22:38.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:38.471+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MergeIntoCommand: DELTA: Writing modified data
[2025-05-02T02:22:38.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MergeIntoCommand: DELTA: MERGE operation - Rewriting 1 files
[2025-05-02T02:22:38.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:38.658+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:38.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:22:38.688+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 5.281911 ms
[2025-05-02T02:22:38.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:38.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Got job 31 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-02T02:22:38.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Final stage: ResultStage 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:38.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:38.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:38.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[145] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:38.705+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 9.2 KiB, free 380.1 MiB)
[2025-05-02T02:22:38.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 380.1 MiB)
[2025-05-02T02:22:38.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on ***-scheduler:33063 (size: 4.5 KiB, free: 432.6 MiB)
[2025-05-02T02:22:38.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:38.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[145] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:38.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
[2025-05-02T02:22:38.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 524) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10016 bytes)
[2025-05-02T02:22:38.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Running task 0.0 in stage 56.0 (TID 524)
[2025-05-02T02:22:38.713+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManager: Found block rdd_120_0 locally
[2025-05-02T02:22:38.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 7.650556 ms
[2025-05-02T02:22:38.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO Executor: Finished task 0.0 in stage 56.0 (TID 524). 448484 bytes result sent to driver
[2025-05-02T02:22:38.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 524) in 41 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:38.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool
[2025-05-02T02:22:38.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: ResultStage 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.049 s
[2025-05-02T02:22:38.754+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:38.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
[2025-05-02T02:22:38.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Job 31 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.054463 s
[2025-05-02T02:22:38.770+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 16.3 MiB, free 363.9 MiB)
[2025-05-02T02:22:38.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 503.7 KiB, free 363.4 MiB)
[2025-05-02T02:22:38.784+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on ***-scheduler:33063 (size: 503.7 KiB, free: 432.1 MiB)
[2025-05-02T02:22:38.785+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Created broadcast 51 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:38.789+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:38.790+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:38.815+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO CodeGenerator: Code generated in 9.613846 ms
[2025-05-02T02:22:38.820+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 206.6 KiB, free 363.2 MiB)
[2025-05-02T02:22:38.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 363.1 MiB)
[2025-05-02T02:22:38.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 432.1 MiB)
[2025-05-02T02:22:38.839+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Created broadcast 52 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:38.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4637540 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:38.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:38.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Got job 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:38.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Final stage: ResultStage 57 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:38.960+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:38.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:38.962+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:38 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[148] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:39.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 351.5 KiB, free 362.8 MiB)
[2025-05-02T02:22:39.018+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO BlockManagerInfo: Removed broadcast_46_piece0 on ***-scheduler:33063 in memory (size: 36.4 KiB, free: 432.1 MiB)
[2025-05-02T02:22:39.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 126.2 KiB, free 362.9 MiB)
[2025-05-02T02:22:39.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on ***-scheduler:33063 (size: 126.2 KiB, free: 432.0 MiB)
[2025-05-02T02:22:39.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:39.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[148] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:39.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-05-02T02:22:39.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO BlockManagerInfo: Removed broadcast_49_piece0 on ***-scheduler:33063 in memory (size: 6.6 KiB, free: 432.0 MiB)
[2025-05-02T02:22:39.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 525) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10920 bytes)
[2025-05-02T02:22:39.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO Executor: Running task 0.0 in stage 57.0 (TID 525)
[2025-05-02T02:22:39.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO BlockManagerInfo: Removed broadcast_50_piece0 on ***-scheduler:33063 in memory (size: 4.5 KiB, free: 432.0 MiB)
[2025-05-02T02:22:39.034+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO BlockManagerInfo: Removed broadcast_45_piece0 on ***-scheduler:33063 in memory (size: 515.4 KiB, free: 432.5 MiB)
[2025-05-02T02:22:39.071+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO CodeGenerator: Code generated in 10.881995 ms
[2025-05-02T02:22:39.086+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO CodeGenerator: Code generated in 8.582646 ms
[2025-05-02T02:22:39.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO CodeGenerator: Code generated in 10.7552 ms
[2025-05-02T02:22:39.111+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:22:39.112+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:22:39.115+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-05-02T02:22:39.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-05-02T02:22:39.118+0000] {spark_submit.py:649} INFO - {
[2025-05-02T02:22:39.119+0000] {spark_submit.py:649} INFO - "type" : "struct",
[2025-05-02T02:22:39.120+0000] {spark_submit.py:649} INFO - "fields" : [ {
[2025-05-02T02:22:39.121+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Group_Key",
[2025-05-02T02:22:39.121+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:39.122+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:39.123+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:39.124+0000] {spark_submit.py:649} INFO - }, {
[2025-05-02T02:22:39.125+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Key",
[2025-05-02T02:22:39.125+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:39.126+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:39.127+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:39.128+0000] {spark_submit.py:649} INFO - } ]
[2025-05-02T02:22:39.129+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:22:39.130+0000] {spark_submit.py:649} INFO - and corresponding Parquet message type:
[2025-05-02T02:22:39.131+0000] {spark_submit.py:649} INFO - message spark_schema {
[2025-05-02T02:22:39.132+0000] {spark_submit.py:649} INFO - optional binary Allergy_Group_Key (STRING);
[2025-05-02T02:22:39.133+0000] {spark_submit.py:649} INFO - optional binary Allergy_Key (STRING);
[2025-05-02T02:22:39.134+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:22:39.135+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:22:39.136+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:22:39.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/part-00000-ce72f691-2bbf-4528-b5d4-495c385509f4-c000.snappy.parquet, range: 0-443236, partition values: [empty row]
[2025-05-02T02:22:39.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:39.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO Executor: Finished task 0.0 in stage 57.0 (TID 525). 4302 bytes result sent to driver
[2025-05-02T02:22:39.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 525) in 912 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:39.940+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-02T02:22:39.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DAGScheduler: ResultStage 57 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.977 s
[2025-05-02T02:22:39.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:39.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-05-02T02:22:39.945+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DAGScheduler: Job 32 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.980666 s
[2025-05-02T02:22:39.946+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DeltaFileFormatWriter: Start to commit write Job 9ab7908f-4999-4e84-babf-c76c3c9fdf5f.
[2025-05-02T02:22:39.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DeltaFileFormatWriter: Write Job 9ab7908f-4999-4e84-babf-c76c3c9fdf5f committed. Elapsed time: 0 ms.
[2025-05-02T02:22:39.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO DeltaFileFormatWriter: Finished processing stats for write job 9ab7908f-4999-4e84-babf-c76c3c9fdf5f.
[2025-05-02T02:22:39.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:39.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:39.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:39 INFO OptimisticTransaction: [tableId=0822c19b,txnId=66003954] Attempting to commit version 1 with 3 actions with Serializable isolation level
[2025-05-02T02:22:40.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO OptimisticTransaction: Incremental commit: starting with snapshot version 0
[2025-05-02T02:22:40.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO DeltaLog: Creating a new snapshot v1 for commit version 1
[2025-05-02T02:22:40.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO DeltaLog: Loading version 1.
[2025-05-02T02:22:40.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO Snapshot: [tableId=0822c19b-6cc0-4149-b022-d7dcd20fd2b6] Created snapshot Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=1, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,1,ArrayBuffer(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json; isDirectory=false; length=1896; replication=1; blocksize=33554432; modification_time=1746152560000; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c8bea37cd7c519106867602e55f00f0b versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746152560000), checksumOpt=Some(VersionChecksum(Some(66003954-5fd8-41f3-b8fe-ea173f8c834f),3575,1,None,None,1,1,None,Some(Stream()),Some(Stream()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(Stream(AddFile(part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet,Map(),3575,1746152559000,false,{"numRecords":92,"minValues":{"Allergy_Group_Key":"05b319200754a18a85d0d6c33e1949ea","Allergy_Key":"11f8b98734e642fcc35a6842475de9f6"},"maxValues":{"Allergy_Group_Key":"ee675f9cb730effe647251fabb7c8af8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:22:40.491+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=1, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,1,ArrayBuffer(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json; isDirectory=false; length=1896; replication=1; blocksize=33554432; modification_time=1746152560000; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c8bea37cd7c519106867602e55f00f0b versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746152560000), checksumOpt=Some(VersionChecksum(Some(66003954-5fd8-41f3-b8fe-ea173f8c834f),3575,1,None,None,1,1,None,Some(Stream()),Some(Stream()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(Stream(AddFile(part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet,Map(),3575,1746152559000,false,{"numRecords":92,"minValues":{"Allergy_Group_Key":"05b319200754a18a85d0d6c33e1949ea","Allergy_Key":"11f8b98734e642fcc35a6842475de9f6"},"maxValues":{"Allergy_Group_Key":"ee675f9cb730effe647251fabb7c8af8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:22:40.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO MapPartitionsRDD: Removing RDD 67 from persistence list
[2025-05-02T02:22:40.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO BlockManager: Removing RDD 67
[2025-05-02T02:22:40.508+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO MapPartitionsRDD: Removing RDD 71 from persistence list
[2025-05-02T02:22:40.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO BlockManager: Removing RDD 71
[2025-05-02T02:22:40.533+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 3312)
[2025-05-02T02:22:40.587+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO OptimisticTransaction: [tableId=0822c19b,txnId=66003954] Committed delta #1 to s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log
[2025-05-02T02:22:40.589+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO ChecksumHook: Writing checksum file for table path s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log version 1
[2025-05-02T02:22:40.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO deprecation: org.apache.hadoop.shaded.io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[2025-05-02T02:22:40.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:40 INFO CheckpointFileManager: Writing atomically to s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.crc using temp file s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/.00000000000000000001.crc.52c1b15b-66a1-495a-a291-d529af3cd07a.tmp
[2025-05-02T02:22:41.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:41 INFO CheckpointFileManager: Renamed temp file s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/.00000000000000000001.crc.52c1b15b-66a1-495a-a291-d529af3cd07a.tmp to s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.crc
[2025-05-02T02:22:41.902+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:41 INFO MapPartitionsRDD: Removing RDD 120 from persistence list
[2025-05-02T02:22:41.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:41 INFO BlockManager: Removing RDD 120
[2025-05-02T02:22:42.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DeltaLog: Loading version 1.
[2025-05-02T02:22:42.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO Snapshot: [tableId=0822c19b-6cc0-4149-b022-d7dcd20fd2b6] Created snapshot Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=1, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,1,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json; isDirectory=false; length=1896; replication=1; blocksize=33554432; modification_time=1746152560262; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c8bea37cd7c519106867602e55f00f0b versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746152560262), checksumOpt=Some(VersionChecksum(Some(66003954-5fd8-41f3-b8fe-ea173f8c834f),3575,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet,Map(),3575,1746152559000,false,{"numRecords":92,"minValues":{"Allergy_Group_Key":"05b319200754a18a85d0d6c33e1949ea","Allergy_Key":"11f8b98734e642fcc35a6842475de9f6"},"maxValues":{"Allergy_Group_Key":"ee675f9cb730effe647251fabb7c8af8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:22:42.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=1, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,1,WrappedArray(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json; isDirectory=false; length=1896; replication=1; blocksize=33554432; modification_time=1746152560262; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c8bea37cd7c519106867602e55f00f0b versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746152560262), checksumOpt=Some(VersionChecksum(Some(66003954-5fd8-41f3-b8fe-ea173f8c834f),3575,1,None,None,1,1,None,Some(List()),Some(List()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet,Map(),3575,1746152559000,false,{"numRecords":92,"minValues":{"Allergy_Group_Key":"05b319200754a18a85d0d6c33e1949ea","Allergy_Key":"11f8b98734e642fcc35a6842475de9f6"},"maxValues":{"Allergy_Group_Key":"ee675f9cb730effe647251fabb7c8af8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:22:42.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MergeIntoCommand: DELTA: MERGE operation - materialize source
[2025-05-02T02:22:42.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:42.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MergeIntoCommand: DELTA: MERGE operation - writing new files for only inserts
[2025-05-02T02:22:42.484+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO Snapshot: DELTA: Compute snapshot for version: 1
[2025-05-02T02:22:42.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 204.9 KiB, free 379.5 MiB)
[2025-05-02T02:22:42.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 379.5 MiB)
[2025-05-02T02:22:42.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on ***-scheduler:33063 (size: 35.9 KiB, free: 432.5 MiB)
[2025-05-02T02:22:42.530+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO SparkContext: Created broadcast 54 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:42.531+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 3312)
[2025-05-02T02:22:42.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DataSourceStrategy: Pruning directories with:
[2025-05-02T02:22:42.785+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:42.786+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:42.847+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 205.2 KiB, free 379.3 MiB)
[2025-05-02T02:22:42.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 36.0 KiB, free 379.2 MiB)
[2025-05-02T02:22:42.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on ***-scheduler:33063 (size: 36.0 KiB, free: 432.4 MiB)
[2025-05-02T02:22:42.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO SparkContext: Created broadcast 55 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:42.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8391920 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:42.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Registering RDD 152 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 13
[2025-05-02T02:22:42.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Got map stage job 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:42.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Final stage: ShuffleMapStage 58 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:42.889+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:42.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:42.891+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[152] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:42.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 105.9 KiB, free 379.1 MiB)
[2025-05-02T02:22:42.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 379.1 MiB)
[2025-05-02T02:22:42.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on ***-scheduler:33063 (size: 32.7 KiB, free: 432.4 MiB)
[2025-05-02T02:22:42.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:42.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[152] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:42.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-05-02T02:22:42.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 526) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 11094 bytes)
[2025-05-02T02:22:42.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO Executor: Running task 0.0 in stage 58.0 (TID 526)
[2025-05-02T02:22:42.910+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:42 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json, range: 0-1896, partition values: [1]
[2025-05-02T02:22:43.326+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json, range: 0-1416, partition values: [0]
[2025-05-02T02:22:43.433+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO Executor: Finished task 0.0 in stage 58.0 (TID 526). 1927 bytes result sent to driver
[2025-05-02T02:22:43.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Removed broadcast_53_piece0 on ***-scheduler:33063 in memory (size: 126.2 KiB, free: 432.5 MiB)
[2025-05-02T02:22:43.437+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 526) in 539 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:43.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-05-02T02:22:43.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: ShuffleMapStage 58 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.548 s
[2025-05-02T02:22:43.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:43.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:43.444+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:43.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:43.446+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Removed broadcast_52_piece0 on ***-scheduler:33063 in memory (size: 36.4 KiB, free: 432.5 MiB)
[2025-05-02T02:22:43.447+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Removed broadcast_51_piece0 on ***-scheduler:33063 in memory (size: 503.7 KiB, free: 433.0 MiB)
[2025-05-02T02:22:43.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Registering RDD 162 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 14
[2025-05-02T02:22:43.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Got map stage job 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:43.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 60 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:43.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-02T02:22:43.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:43.727+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[162] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:43.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 605.6 KiB, free 396.0 MiB)
[2025-05-02T02:22:43.744+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 139.0 KiB, free 395.8 MiB)
[2025-05-02T02:22:43.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on ***-scheduler:33063 (size: 139.0 KiB, free: 432.9 MiB)
[2025-05-02T02:22:43.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:43.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[162] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:43.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSchedulerImpl: Adding task set 60.0 with 50 tasks resource profile 0
[2025-05-02T02:22:43.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 527) (***-scheduler, executor driver, partition 11, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:43.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO Executor: Running task 11.0 in stage 60.0 (TID 527)
[2025-05-02T02:22:43.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:43.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:43.834+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Removed broadcast_56_piece0 on ***-scheduler:33063 in memory (size: 32.7 KiB, free: 432.9 MiB)
[2025-05-02T02:22:43.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO MemoryStore: Block rdd_159_11 stored as values in memory (estimated size 333.0 B, free 396.0 MiB)
[2025-05-02T02:22:43.839+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Added rdd_159_11 in memory on ***-scheduler:33063 (size: 333.0 B, free: 432.9 MiB)
[2025-05-02T02:22:43.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO Executor: Finished task 11.0 in stage 60.0 (TID 527). 5351 bytes result sent to driver
[2025-05-02T02:22:43.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSetManager: Starting task 25.0 in stage 60.0 (TID 528) (***-scheduler, executor driver, partition 25, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:43.873+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO Executor: Running task 25.0 in stage 60.0 (TID 528)
[2025-05-02T02:22:43.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 527) in 124 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:43.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:43.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:43.939+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO MemoryStore: Block rdd_159_25 stored as values in memory (estimated size 542.0 B, free 396.0 MiB)
[2025-05-02T02:22:43.941+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO BlockManagerInfo: Added rdd_159_25 in memory on ***-scheduler:33063 (size: 542.0 B, free: 432.9 MiB)
[2025-05-02T02:22:43.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO Executor: Finished task 25.0 in stage 60.0 (TID 528). 5308 bytes result sent to driver
[2025-05-02T02:22:43.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSetManager: Starting task 42.0 in stage 60.0 (TID 529) (***-scheduler, executor driver, partition 42, NODE_LOCAL, 10195 bytes)
[2025-05-02T02:22:43.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO TaskSetManager: Finished task 25.0 in stage 60.0 (TID 528) in 113 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:43.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:43 INFO Executor: Running task 42.0 in stage 60.0 (TID 529)
[2025-05-02T02:22:44.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 1 (1862.0 B) non-empty blocks including 1 (1862.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.004+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.048+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_42 stored as values in memory (estimated size 465.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.049+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_42 in memory on ***-scheduler:33063 (size: 465.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 42.0 in stage 60.0 (TID 529). 5308 bytes result sent to driver
[2025-05-02T02:22:44.092+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 530) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 42.0 in stage 60.0 (TID 529) in 110 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:44.095+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 0.0 in stage 60.0 (TID 530)
[2025-05-02T02:22:44.114+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_0 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_0 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 0.0 in stage 60.0 (TID 530). 5308 bytes result sent to driver
[2025-05-02T02:22:44.208+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 531) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.210+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 1.0 in stage 60.0 (TID 531)
[2025-05-02T02:22:44.211+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 530) in 118 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:44.265+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.267+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:44.339+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_1 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.341+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_1 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 1.0 in stage 60.0 (TID 531). 5351 bytes result sent to driver
[2025-05-02T02:22:44.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 532) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 2.0 in stage 60.0 (TID 532)
[2025-05-02T02:22:44.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 531) in 175 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:44.402+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_2 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_2 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.497+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 2.0 in stage 60.0 (TID 532). 5308 bytes result sent to driver
[2025-05-02T02:22:44.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 533) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 532) in 119 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:44.502+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 3.0 in stage 60.0 (TID 533)
[2025-05-02T02:22:44.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.523+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_3 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_3 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.628+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 3.0 in stage 60.0 (TID 533). 5308 bytes result sent to driver
[2025-05-02T02:22:44.630+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 534) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 533) in 133 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:44.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 4.0 in stage 60.0 (TID 534)
[2025-05-02T02:22:44.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.649+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_4 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_4 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.731+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 4.0 in stage 60.0 (TID 534). 5308 bytes result sent to driver
[2025-05-02T02:22:44.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 535) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 534) in 105 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:44.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 5.0 in stage 60.0 (TID 535)
[2025-05-02T02:22:44.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.757+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.820+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_5 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.822+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_5 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:44.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Finished task 5.0 in stage 60.0 (TID 535). 5394 bytes result sent to driver
[2025-05-02T02:22:44.900+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 536) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:44.902+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO Executor: Running task 6.0 in stage 60.0 (TID 536)
[2025-05-02T02:22:44.903+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 535) in 168 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:44.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:44.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:44.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO MemoryStore: Block rdd_159_6 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:44.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:44 INFO BlockManagerInfo: Added rdd_159_6 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.003+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 6.0 in stage 60.0 (TID 536). 5308 bytes result sent to driver
[2025-05-02T02:22:45.005+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 537) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.006+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 536) in 106 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:45.007+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 7.0 in stage 60.0 (TID 537)
[2025-05-02T02:22:45.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_7 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_7 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 7.0 in stage 60.0 (TID 537). 5308 bytes result sent to driver
[2025-05-02T02:22:45.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 538) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.103+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 537) in 97 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:45.104+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 8.0 in stage 60.0 (TID 538)
[2025-05-02T02:22:45.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.162+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_8 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.163+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_8 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 8.0 in stage 60.0 (TID 538). 5308 bytes result sent to driver
[2025-05-02T02:22:45.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 539) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 538) in 90 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:45.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 9.0 in stage 60.0 (TID 539)
[2025-05-02T02:22:45.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.262+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_9 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.263+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_9 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 9.0 in stage 60.0 (TID 539). 5351 bytes result sent to driver
[2025-05-02T02:22:45.290+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 540) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 539) in 101 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:45.293+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 10.0 in stage 60.0 (TID 540)
[2025-05-02T02:22:45.306+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_10 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_10 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 10.0 in stage 60.0 (TID 540). 5308 bytes result sent to driver
[2025-05-02T02:22:45.378+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 12.0 in stage 60.0 (TID 541) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 540) in 87 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:45.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 12.0 in stage 60.0 (TID 541)
[2025-05-02T02:22:45.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_12 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_12 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.461+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 12.0 in stage 60.0 (TID 541). 5308 bytes result sent to driver
[2025-05-02T02:22:45.462+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 13.0 in stage 60.0 (TID 542) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 12.0 in stage 60.0 (TID 541) in 85 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:45.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 13.0 in stage 60.0 (TID 542)
[2025-05-02T02:22:45.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_13 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_13 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 13.0 in stage 60.0 (TID 542). 5308 bytes result sent to driver
[2025-05-02T02:22:45.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 14.0 in stage 60.0 (TID 543) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 13.0 in stage 60.0 (TID 542) in 89 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:45.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 14.0 in stage 60.0 (TID 543)
[2025-05-02T02:22:45.578+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.617+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_14 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_14 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.655+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 14.0 in stage 60.0 (TID 543). 5351 bytes result sent to driver
[2025-05-02T02:22:45.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 15.0 in stage 60.0 (TID 544) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.658+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 14.0 in stage 60.0 (TID 543) in 107 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:45.659+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 15.0 in stage 60.0 (TID 544)
[2025-05-02T02:22:45.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.717+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_15 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_15 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 15.0 in stage 60.0 (TID 544). 5308 bytes result sent to driver
[2025-05-02T02:22:45.744+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 16.0 in stage 60.0 (TID 545) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 15.0 in stage 60.0 (TID 544) in 88 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:45.746+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 16.0 in stage 60.0 (TID 545)
[2025-05-02T02:22:45.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_16 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_16 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 16.0 in stage 60.0 (TID 545). 5308 bytes result sent to driver
[2025-05-02T02:22:45.828+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 17.0 in stage 60.0 (TID 546) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 16.0 in stage 60.0 (TID 545) in 85 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:45.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 17.0 in stage 60.0 (TID 546)
[2025-05-02T02:22:45.842+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.844+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_17 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_17 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:45.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Finished task 17.0 in stage 60.0 (TID 546). 5351 bytes result sent to driver
[2025-05-02T02:22:45.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Starting task 18.0 in stage 60.0 (TID 547) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:45.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO TaskSetManager: Finished task 17.0 in stage 60.0 (TID 546) in 96 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:45.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO Executor: Running task 18.0 in stage 60.0 (TID 547)
[2025-05-02T02:22:45.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:45.939+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:45.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO MemoryStore: Block rdd_159_18 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:45.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:45 INFO BlockManagerInfo: Added rdd_159_18 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 18.0 in stage 60.0 (TID 547). 5308 bytes result sent to driver
[2025-05-02T02:22:46.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 19.0 in stage 60.0 (TID 548) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 18.0 in stage 60.0 (TID 547) in 91 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:46.016+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 19.0 in stage 60.0 (TID 548)
[2025-05-02T02:22:46.028+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_19 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_19 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.103+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 19.0 in stage 60.0 (TID 548). 5308 bytes result sent to driver
[2025-05-02T02:22:46.104+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 20.0 in stage 60.0 (TID 549) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.106+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 19.0 in stage 60.0 (TID 548) in 91 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:46.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 20.0 in stage 60.0 (TID 549)
[2025-05-02T02:22:46.131+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_20 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_20 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 20.0 in stage 60.0 (TID 549). 5351 bytes result sent to driver
[2025-05-02T02:22:46.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 21.0 in stage 60.0 (TID 550) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 20.0 in stage 60.0 (TID 549) in 90 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:46.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 21.0 in stage 60.0 (TID 550)
[2025-05-02T02:22:46.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.208+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_21 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_21 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 21.0 in stage 60.0 (TID 550). 5308 bytes result sent to driver
[2025-05-02T02:22:46.280+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 22.0 in stage 60.0 (TID 551) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.282+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 21.0 in stage 60.0 (TID 550) in 89 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:46.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 22.0 in stage 60.0 (TID 551)
[2025-05-02T02:22:46.296+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_22 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_22 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 22.0 in stage 60.0 (TID 551). 5308 bytes result sent to driver
[2025-05-02T02:22:46.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 23.0 in stage 60.0 (TID 552) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.365+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 22.0 in stage 60.0 (TID 551) in 84 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:46.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 23.0 in stage 60.0 (TID 552)
[2025-05-02T02:22:46.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.446+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_23 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.448+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_23 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 23.0 in stage 60.0 (TID 552). 5351 bytes result sent to driver
[2025-05-02T02:22:46.481+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 24.0 in stage 60.0 (TID 553) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 23.0 in stage 60.0 (TID 552) in 117 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:46.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 24.0 in stage 60.0 (TID 553)
[2025-05-02T02:22:46.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.534+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_24 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_24 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 24.0 in stage 60.0 (TID 553). 5308 bytes result sent to driver
[2025-05-02T02:22:46.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 26.0 in stage 60.0 (TID 554) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 24.0 in stage 60.0 (TID 553) in 88 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:46.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 26.0 in stage 60.0 (TID 554)
[2025-05-02T02:22:46.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.628+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_26 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_26 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 26.0 in stage 60.0 (TID 554). 5394 bytes result sent to driver
[2025-05-02T02:22:46.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 27.0 in stage 60.0 (TID 555) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 26.0 in stage 60.0 (TID 554) in 103 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:46.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 27.0 in stage 60.0 (TID 555)
[2025-05-02T02:22:46.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.687+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_27 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_27 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 27.0 in stage 60.0 (TID 555). 5308 bytes result sent to driver
[2025-05-02T02:22:46.752+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 28.0 in stage 60.0 (TID 556) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 27.0 in stage 60.0 (TID 555) in 83 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:46.754+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 28.0 in stage 60.0 (TID 556)
[2025-05-02T02:22:46.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_28 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_28 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 28.0 in stage 60.0 (TID 556). 5308 bytes result sent to driver
[2025-05-02T02:22:46.830+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 29.0 in stage 60.0 (TID 557) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 28.0 in stage 60.0 (TID 556) in 79 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:46.833+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 29.0 in stage 60.0 (TID 557)
[2025-05-02T02:22:46.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.904+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_29 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_29 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:46.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Finished task 29.0 in stage 60.0 (TID 557). 5351 bytes result sent to driver
[2025-05-02T02:22:46.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Starting task 30.0 in stage 60.0 (TID 558) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:46.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO TaskSetManager: Finished task 29.0 in stage 60.0 (TID 557) in 105 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:46.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO Executor: Running task 30.0 in stage 60.0 (TID 558)
[2025-05-02T02:22:46.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:46.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:46.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO MemoryStore: Block rdd_159_30 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:46.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:46 INFO BlockManagerInfo: Added rdd_159_30 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 30.0 in stage 60.0 (TID 558). 5308 bytes result sent to driver
[2025-05-02T02:22:47.016+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 31.0 in stage 60.0 (TID 559) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.018+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 30.0 in stage 60.0 (TID 558) in 83 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:47.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 31.0 in stage 60.0 (TID 559)
[2025-05-02T02:22:47.033+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.034+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.072+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_31 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_31 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 31.0 in stage 60.0 (TID 559). 5308 bytes result sent to driver
[2025-05-02T02:22:47.099+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 32.0 in stage 60.0 (TID 560) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 32.0 in stage 60.0 (TID 560)
[2025-05-02T02:22:47.102+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 31.0 in stage 60.0 (TID 559) in 83 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:47.132+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.133+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:47.178+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_32 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_32 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 32.0 in stage 60.0 (TID 560). 5351 bytes result sent to driver
[2025-05-02T02:22:47.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 33.0 in stage 60.0 (TID 561) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 32.0 in stage 60.0 (TID 560) in 120 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:47.222+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 33.0 in stage 60.0 (TID 561)
[2025-05-02T02:22:47.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.240+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_33 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_33 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 33.0 in stage 60.0 (TID 561). 5308 bytes result sent to driver
[2025-05-02T02:22:47.317+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 34.0 in stage 60.0 (TID 562) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.318+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 33.0 in stage 60.0 (TID 561) in 100 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:47.319+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 34.0 in stage 60.0 (TID 562)
[2025-05-02T02:22:47.333+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_34 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_34 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 34.0 in stage 60.0 (TID 562). 5394 bytes result sent to driver
[2025-05-02T02:22:47.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 35.0 in stage 60.0 (TID 563) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 35.0 in stage 60.0 (TID 563)
[2025-05-02T02:22:47.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 34.0 in stage 60.0 (TID 562) in 102 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:47.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.435+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_35 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_35 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.497+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 35.0 in stage 60.0 (TID 563). 5308 bytes result sent to driver
[2025-05-02T02:22:47.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 36.0 in stage 60.0 (TID 564) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 35.0 in stage 60.0 (TID 563) in 81 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:47.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 36.0 in stage 60.0 (TID 564)
[2025-05-02T02:22:47.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_36 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_36 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 36.0 in stage 60.0 (TID 564). 5308 bytes result sent to driver
[2025-05-02T02:22:47.577+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 37.0 in stage 60.0 (TID 565) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 37.0 in stage 60.0 (TID 565)
[2025-05-02T02:22:47.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 36.0 in stage 60.0 (TID 564) in 80 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:47.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.593+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.641+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_37 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.643+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_37 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 37.0 in stage 60.0 (TID 565). 5351 bytes result sent to driver
[2025-05-02T02:22:47.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 38.0 in stage 60.0 (TID 566) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 37.0 in stage 60.0 (TID 565) in 93 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:47.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 38.0 in stage 60.0 (TID 566)
[2025-05-02T02:22:47.684+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_38 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_38 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 38.0 in stage 60.0 (TID 566). 5308 bytes result sent to driver
[2025-05-02T02:22:47.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 39.0 in stage 60.0 (TID 567) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 38.0 in stage 60.0 (TID 566) in 79 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:47.751+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 39.0 in stage 60.0 (TID 567)
[2025-05-02T02:22:47.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.800+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_39 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_39 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 39.0 in stage 60.0 (TID 567). 5308 bytes result sent to driver
[2025-05-02T02:22:47.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 40.0 in stage 60.0 (TID 568) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 40.0 in stage 60.0 (TID 568)
[2025-05-02T02:22:47.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 39.0 in stage 60.0 (TID 567) in 77 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:47.839+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_40 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_40 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 40.0 in stage 60.0 (TID 568). 5351 bytes result sent to driver
[2025-05-02T02:22:47.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 41.0 in stage 60.0 (TID 569) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 40.0 in stage 60.0 (TID 568) in 92 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:47.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 41.0 in stage 60.0 (TID 569)
[2025-05-02T02:22:47.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:47.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:47.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO MemoryStore: Block rdd_159_41 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:47.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO BlockManagerInfo: Added rdd_159_41 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:47.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Finished task 41.0 in stage 60.0 (TID 569). 5308 bytes result sent to driver
[2025-05-02T02:22:47.992+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Starting task 43.0 in stage 60.0 (TID 570) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:47.993+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO TaskSetManager: Finished task 41.0 in stage 60.0 (TID 569) in 77 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:47.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:47 INFO Executor: Running task 43.0 in stage 60.0 (TID 570)
[2025-05-02T02:22:48.008+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.010+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:48.048+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_43 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.050+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_43 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.074+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 43.0 in stage 60.0 (TID 570). 5308 bytes result sent to driver
[2025-05-02T02:22:48.075+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 44.0 in stage 60.0 (TID 571) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:48.077+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 43.0 in stage 60.0 (TID 570) in 84 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:48.078+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 44.0 in stage 60.0 (TID 571)
[2025-05-02T02:22:48.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.091+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_44 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_44 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 44.0 in stage 60.0 (TID 571). 5351 bytes result sent to driver
[2025-05-02T02:22:48.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 45.0 in stage 60.0 (TID 572) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:48.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 45.0 in stage 60.0 (TID 572)
[2025-05-02T02:22:48.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 44.0 in stage 60.0 (TID 571) in 93 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:48.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_45 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_45 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 45.0 in stage 60.0 (TID 572). 5308 bytes result sent to driver
[2025-05-02T02:22:48.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 46.0 in stage 60.0 (TID 573) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:48.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 45.0 in stage 60.0 (TID 572) in 78 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:48.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 46.0 in stage 60.0 (TID 573)
[2025-05-02T02:22:48.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.296+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_46 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_46 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 46.0 in stage 60.0 (TID 573). 5308 bytes result sent to driver
[2025-05-02T02:22:48.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 47.0 in stage 60.0 (TID 574) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:48.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 46.0 in stage 60.0 (TID 573) in 77 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:48.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 47.0 in stage 60.0 (TID 574)
[2025-05-02T02:22:48.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_47 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_47 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 47.0 in stage 60.0 (TID 574). 5351 bytes result sent to driver
[2025-05-02T02:22:48.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 48.0 in stage 60.0 (TID 575) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:48.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 47.0 in stage 60.0 (TID 574) in 94 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:48.418+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 48.0 in stage 60.0 (TID 575)
[2025-05-02T02:22:48.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_48 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_48 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.497+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 48.0 in stage 60.0 (TID 575). 5308 bytes result sent to driver
[2025-05-02T02:22:48.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 49.0 in stage 60.0 (TID 576) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:48.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 48.0 in stage 60.0 (TID 575) in 84 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:48.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 49.0 in stage 60.0 (TID 576)
[2025-05-02T02:22:48.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.547+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block rdd_159_49 stored as values in memory (estimated size 46.0 B, free 396.0 MiB)
[2025-05-02T02:22:48.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added rdd_159_49 in memory on ***-scheduler:33063 (size: 46.0 B, free: 432.9 MiB)
[2025-05-02T02:22:48.576+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 49.0 in stage 60.0 (TID 576). 5394 bytes result sent to driver
[2025-05-02T02:22:48.577+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 49.0 in stage 60.0 (TID 576) in 79 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:48.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-02T02:22:48.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: ShuffleMapStage 60 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 4.851 s
[2025-05-02T02:22:48.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:48.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:48.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:48.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:48.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:48.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Got job 35 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:48.626+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Final stage: ResultStage 63 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:48.627+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
[2025-05-02T02:22:48.628+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:48.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[165] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:48.635+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 537.2 KiB, free 395.4 MiB)
[2025-05-02T02:22:48.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 125.5 KiB, free 395.3 MiB)
[2025-05-02T02:22:48.639+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on ***-scheduler:33063 (size: 125.5 KiB, free: 432.8 MiB)
[2025-05-02T02:22:48.640+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:48.641+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[165] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:48.642+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
[2025-05-02T02:22:48.643+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 577) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:48.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 0.0 in stage 63.0 (TID 577)
[2025-05-02T02:22:48.655+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Getting 50 (4.6 KiB) non-empty blocks including 50 (4.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:48.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:48.728+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 0.0 in stage 63.0 (TID 577). 6915 bytes result sent to driver
[2025-05-02T02:22:48.729+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 577) in 89 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:48.730+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool
[2025-05-02T02:22:48.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: ResultStage 63 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.104 s
[2025-05-02T02:22:48.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:48.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
[2025-05-02T02:22:48.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Job 35 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.107823 s
[2025-05-02T02:22:48.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Snapshot: DELTA: Done
[2025-05-02T02:22:48.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:48.921+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Got job 36 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:48.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Final stage: ResultStage 65 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:48.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
[2025-05-02T02:22:48.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:48.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[167] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:48.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 687.3 KiB, free 394.6 MiB)
[2025-05-02T02:22:48.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 155.5 KiB, free 394.5 MiB)
[2025-05-02T02:22:48.935+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on ***-scheduler:33063 (size: 155.5 KiB, free: 432.7 MiB)
[2025-05-02T02:22:48.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:48.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 65 (MapPartitionsRDD[167] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:48.937+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSchedulerImpl: Adding task set 65.0 with 50 tasks resource profile 0
[2025-05-02T02:22:48.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 578) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:48.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 0.0 in stage 65.0 (TID 578)
[2025-05-02T02:22:48.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManager: Found block rdd_159_0 locally
[2025-05-02T02:22:48.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 0.0 in stage 65.0 (TID 578). 4181 bytes result sent to driver
[2025-05-02T02:22:48.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 579) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:48.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 1.0 in stage 65.0 (TID 579)
[2025-05-02T02:22:48.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 578) in 15 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:48.963+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManager: Found block rdd_159_1 locally
[2025-05-02T02:22:48.965+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 1.0 in stage 65.0 (TID 579). 4181 bytes result sent to driver
[2025-05-02T02:22:48.965+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 580) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:48.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 2.0 in stage 65.0 (TID 580)
[2025-05-02T02:22:48.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 579) in 14 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:48.977+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManager: Found block rdd_159_2 locally
[2025-05-02T02:22:48.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 2.0 in stage 65.0 (TID 580). 4181 bytes result sent to driver
[2025-05-02T02:22:48.979+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 581) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:48.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 580) in 14 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:48.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 3.0 in stage 65.0 (TID 581)
[2025-05-02T02:22:48.994+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO BlockManager: Found block rdd_159_3 locally
[2025-05-02T02:22:48.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Finished task 3.0 in stage 65.0 (TID 581). 4181 bytes result sent to driver
[2025-05-02T02:22:48.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Starting task 4.0 in stage 65.0 (TID 582) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:48.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO Executor: Running task 4.0 in stage 65.0 (TID 582)
[2025-05-02T02:22:48.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:48 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 581) in 19 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:49.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_4 locally
[2025-05-02T02:22:49.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 4.0 in stage 65.0 (TID 582). 4224 bytes result sent to driver
[2025-05-02T02:22:49.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManagerInfo: Removed broadcast_58_piece0 on ***-scheduler:33063 in memory (size: 125.5 KiB, free: 432.8 MiB)
[2025-05-02T02:22:49.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 5.0 in stage 65.0 (TID 583) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 5.0 in stage 65.0 (TID 583)
[2025-05-02T02:22:49.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 4.0 in stage 65.0 (TID 582) in 26 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:49.035+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_5 locally
[2025-05-02T02:22:49.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 5.0 in stage 65.0 (TID 583). 4181 bytes result sent to driver
[2025-05-02T02:22:49.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 6.0 in stage 65.0 (TID 584) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.039+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 5.0 in stage 65.0 (TID 583) in 15 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:49.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 6.0 in stage 65.0 (TID 584)
[2025-05-02T02:22:49.049+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_6 locally
[2025-05-02T02:22:49.051+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 6.0 in stage 65.0 (TID 584). 4181 bytes result sent to driver
[2025-05-02T02:22:49.052+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 7.0 in stage 65.0 (TID 585) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.053+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 6.0 in stage 65.0 (TID 584) in 15 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:49.054+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 7.0 in stage 65.0 (TID 585)
[2025-05-02T02:22:49.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_7 locally
[2025-05-02T02:22:49.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 7.0 in stage 65.0 (TID 585). 4181 bytes result sent to driver
[2025-05-02T02:22:49.070+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 8.0 in stage 65.0 (TID 586) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.071+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 7.0 in stage 65.0 (TID 585) in 20 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:49.072+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 8.0 in stage 65.0 (TID 586)
[2025-05-02T02:22:49.085+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_8 locally
[2025-05-02T02:22:49.087+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 8.0 in stage 65.0 (TID 586). 4181 bytes result sent to driver
[2025-05-02T02:22:49.088+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 9.0 in stage 65.0 (TID 587) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.089+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 8.0 in stage 65.0 (TID 586) in 18 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:49.090+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 9.0 in stage 65.0 (TID 587)
[2025-05-02T02:22:49.102+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_9 locally
[2025-05-02T02:22:49.104+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 9.0 in stage 65.0 (TID 587). 4181 bytes result sent to driver
[2025-05-02T02:22:49.106+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 10.0 in stage 65.0 (TID 588) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.107+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 10.0 in stage 65.0 (TID 588)
[2025-05-02T02:22:49.108+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 9.0 in stage 65.0 (TID 587) in 18 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:49.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_10 locally
[2025-05-02T02:22:49.118+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 10.0 in stage 65.0 (TID 588). 4181 bytes result sent to driver
[2025-05-02T02:22:49.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 11.0 in stage 65.0 (TID 589) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.120+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 10.0 in stage 65.0 (TID 588) in 14 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:49.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 11.0 in stage 65.0 (TID 589)
[2025-05-02T02:22:49.130+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_11 locally
[2025-05-02T02:22:49.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 11.0 in stage 65.0 (TID 589). 4267 bytes result sent to driver
[2025-05-02T02:22:49.140+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 12.0 in stage 65.0 (TID 590) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 11.0 in stage 65.0 (TID 589) in 22 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:49.142+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 12.0 in stage 65.0 (TID 590)
[2025-05-02T02:22:49.150+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_12 locally
[2025-05-02T02:22:49.152+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 12.0 in stage 65.0 (TID 590). 4181 bytes result sent to driver
[2025-05-02T02:22:49.153+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 13.0 in stage 65.0 (TID 591) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.154+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 13.0 in stage 65.0 (TID 591)
[2025-05-02T02:22:49.155+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 12.0 in stage 65.0 (TID 590) in 14 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:49.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_13 locally
[2025-05-02T02:22:49.165+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 13.0 in stage 65.0 (TID 591). 4181 bytes result sent to driver
[2025-05-02T02:22:49.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 14.0 in stage 65.0 (TID 592) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 14.0 in stage 65.0 (TID 592)
[2025-05-02T02:22:49.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 13.0 in stage 65.0 (TID 591) in 13 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:49.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_14 locally
[2025-05-02T02:22:49.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 14.0 in stage 65.0 (TID 592). 4181 bytes result sent to driver
[2025-05-02T02:22:49.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 15.0 in stage 65.0 (TID 593) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 15.0 in stage 65.0 (TID 593)
[2025-05-02T02:22:49.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 14.0 in stage 65.0 (TID 592) in 14 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:49.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_15 locally
[2025-05-02T02:22:49.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 15.0 in stage 65.0 (TID 593). 4181 bytes result sent to driver
[2025-05-02T02:22:49.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 16.0 in stage 65.0 (TID 594) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 15.0 in stage 65.0 (TID 593) in 14 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:49.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 16.0 in stage 65.0 (TID 594)
[2025-05-02T02:22:49.204+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_16 locally
[2025-05-02T02:22:49.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 16.0 in stage 65.0 (TID 594). 4181 bytes result sent to driver
[2025-05-02T02:22:49.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 17.0 in stage 65.0 (TID 595) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.208+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 17.0 in stage 65.0 (TID 595)
[2025-05-02T02:22:49.209+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 16.0 in stage 65.0 (TID 594) in 15 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:49.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_17 locally
[2025-05-02T02:22:49.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 17.0 in stage 65.0 (TID 595). 4267 bytes result sent to driver
[2025-05-02T02:22:49.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 18.0 in stage 65.0 (TID 596) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 17.0 in stage 65.0 (TID 595) in 25 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:49.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 18.0 in stage 65.0 (TID 596)
[2025-05-02T02:22:49.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_18 locally
[2025-05-02T02:22:49.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 18.0 in stage 65.0 (TID 596). 4181 bytes result sent to driver
[2025-05-02T02:22:49.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 19.0 in stage 65.0 (TID 597) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.247+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 19.0 in stage 65.0 (TID 597)
[2025-05-02T02:22:49.248+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 18.0 in stage 65.0 (TID 596) in 16 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:49.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_19 locally
[2025-05-02T02:22:49.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 19.0 in stage 65.0 (TID 597). 4181 bytes result sent to driver
[2025-05-02T02:22:49.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 20.0 in stage 65.0 (TID 598) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.262+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 20.0 in stage 65.0 (TID 598)
[2025-05-02T02:22:49.263+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 19.0 in stage 65.0 (TID 597) in 15 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:49.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_20 locally
[2025-05-02T02:22:49.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 20.0 in stage 65.0 (TID 598). 4181 bytes result sent to driver
[2025-05-02T02:22:49.274+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 21.0 in stage 65.0 (TID 599) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.275+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 21.0 in stage 65.0 (TID 599)
[2025-05-02T02:22:49.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 20.0 in stage 65.0 (TID 598) in 14 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:49.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_21 locally
[2025-05-02T02:22:49.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 21.0 in stage 65.0 (TID 599). 4181 bytes result sent to driver
[2025-05-02T02:22:49.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 22.0 in stage 65.0 (TID 600) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 22.0 in stage 65.0 (TID 600)
[2025-05-02T02:22:49.290+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 21.0 in stage 65.0 (TID 599) in 15 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:49.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_22 locally
[2025-05-02T02:22:49.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 22.0 in stage 65.0 (TID 600). 4181 bytes result sent to driver
[2025-05-02T02:22:49.301+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 23.0 in stage 65.0 (TID 601) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.302+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 23.0 in stage 65.0 (TID 601)
[2025-05-02T02:22:49.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 22.0 in stage 65.0 (TID 600) in 13 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:49.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_23 locally
[2025-05-02T02:22:49.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 23.0 in stage 65.0 (TID 601). 4267 bytes result sent to driver
[2025-05-02T02:22:49.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 24.0 in stage 65.0 (TID 602) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 24.0 in stage 65.0 (TID 602)
[2025-05-02T02:22:49.324+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 23.0 in stage 65.0 (TID 601) in 22 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:49.332+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_24 locally
[2025-05-02T02:22:49.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 24.0 in stage 65.0 (TID 602). 4181 bytes result sent to driver
[2025-05-02T02:22:49.335+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 25.0 in stage 65.0 (TID 603) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 24.0 in stage 65.0 (TID 602) in 14 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:49.337+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 25.0 in stage 65.0 (TID 603)
[2025-05-02T02:22:49.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_25 locally
[2025-05-02T02:22:49.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 25.0 in stage 65.0 (TID 603). 4349 bytes result sent to driver
[2025-05-02T02:22:49.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 26.0 in stage 65.0 (TID 604) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 26.0 in stage 65.0 (TID 604)
[2025-05-02T02:22:49.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 25.0 in stage 65.0 (TID 603) in 14 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:49.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_26 locally
[2025-05-02T02:22:49.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 26.0 in stage 65.0 (TID 604). 4181 bytes result sent to driver
[2025-05-02T02:22:49.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 27.0 in stage 65.0 (TID 605) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 26.0 in stage 65.0 (TID 604) in 14 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:49.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 27.0 in stage 65.0 (TID 605)
[2025-05-02T02:22:49.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_27 locally
[2025-05-02T02:22:49.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 27.0 in stage 65.0 (TID 605). 4181 bytes result sent to driver
[2025-05-02T02:22:49.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 28.0 in stage 65.0 (TID 606) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 27.0 in stage 65.0 (TID 605) in 18 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:49.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 28.0 in stage 65.0 (TID 606)
[2025-05-02T02:22:49.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_28 locally
[2025-05-02T02:22:49.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 28.0 in stage 65.0 (TID 606). 4181 bytes result sent to driver
[2025-05-02T02:22:49.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 29.0 in stage 65.0 (TID 607) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 28.0 in stage 65.0 (TID 606) in 14 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:49.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 29.0 in stage 65.0 (TID 607)
[2025-05-02T02:22:49.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_29 locally
[2025-05-02T02:22:49.412+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 29.0 in stage 65.0 (TID 607). 4224 bytes result sent to driver
[2025-05-02T02:22:49.414+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 30.0 in stage 65.0 (TID 608) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.415+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 30.0 in stage 65.0 (TID 608)
[2025-05-02T02:22:49.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 29.0 in stage 65.0 (TID 607) in 20 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:49.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_30 locally
[2025-05-02T02:22:49.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 30.0 in stage 65.0 (TID 608). 4181 bytes result sent to driver
[2025-05-02T02:22:49.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 31.0 in stage 65.0 (TID 609) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 31.0 in stage 65.0 (TID 609)
[2025-05-02T02:22:49.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 30.0 in stage 65.0 (TID 608) in 14 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:49.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_31 locally
[2025-05-02T02:22:49.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 31.0 in stage 65.0 (TID 609). 4181 bytes result sent to driver
[2025-05-02T02:22:49.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 32.0 in stage 65.0 (TID 610) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 32.0 in stage 65.0 (TID 610)
[2025-05-02T02:22:49.443+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 31.0 in stage 65.0 (TID 609) in 15 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:49.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_32 locally
[2025-05-02T02:22:49.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 32.0 in stage 65.0 (TID 610). 4181 bytes result sent to driver
[2025-05-02T02:22:49.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 33.0 in stage 65.0 (TID 611) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.459+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 33.0 in stage 65.0 (TID 611)
[2025-05-02T02:22:49.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 32.0 in stage 65.0 (TID 610) in 19 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:49.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_33 locally
[2025-05-02T02:22:49.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 33.0 in stage 65.0 (TID 611). 4181 bytes result sent to driver
[2025-05-02T02:22:49.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 34.0 in stage 65.0 (TID 612) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 33.0 in stage 65.0 (TID 611) in 18 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:49.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 34.0 in stage 65.0 (TID 612)
[2025-05-02T02:22:49.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_34 locally
[2025-05-02T02:22:49.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 34.0 in stage 65.0 (TID 612). 4267 bytes result sent to driver
[2025-05-02T02:22:49.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 35.0 in stage 65.0 (TID 613) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 35.0 in stage 65.0 (TID 613)
[2025-05-02T02:22:49.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 34.0 in stage 65.0 (TID 612) in 24 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:49.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_35 locally
[2025-05-02T02:22:49.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 35.0 in stage 65.0 (TID 613). 4181 bytes result sent to driver
[2025-05-02T02:22:49.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 36.0 in stage 65.0 (TID 614) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.514+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 35.0 in stage 65.0 (TID 613) in 14 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:49.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 36.0 in stage 65.0 (TID 614)
[2025-05-02T02:22:49.524+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_36 locally
[2025-05-02T02:22:49.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 36.0 in stage 65.0 (TID 614). 4181 bytes result sent to driver
[2025-05-02T02:22:49.526+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 37.0 in stage 65.0 (TID 615) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.527+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 36.0 in stage 65.0 (TID 614) in 14 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:49.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 37.0 in stage 65.0 (TID 615)
[2025-05-02T02:22:49.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_37 locally
[2025-05-02T02:22:49.539+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 37.0 in stage 65.0 (TID 615). 4181 bytes result sent to driver
[2025-05-02T02:22:49.540+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 38.0 in stage 65.0 (TID 616) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.541+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 38.0 in stage 65.0 (TID 616)
[2025-05-02T02:22:49.542+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 37.0 in stage 65.0 (TID 615) in 14 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:49.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_38 locally
[2025-05-02T02:22:49.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 38.0 in stage 65.0 (TID 616). 4181 bytes result sent to driver
[2025-05-02T02:22:49.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 39.0 in stage 65.0 (TID 617) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.554+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 39.0 in stage 65.0 (TID 617)
[2025-05-02T02:22:49.555+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 38.0 in stage 65.0 (TID 616) in 14 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:49.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_39 locally
[2025-05-02T02:22:49.571+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 39.0 in stage 65.0 (TID 617). 4267 bytes result sent to driver
[2025-05-02T02:22:49.572+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 40.0 in stage 65.0 (TID 618) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 40.0 in stage 65.0 (TID 618)
[2025-05-02T02:22:49.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 39.0 in stage 65.0 (TID 617) in 20 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:49.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_40 locally
[2025-05-02T02:22:49.585+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 40.0 in stage 65.0 (TID 618). 4181 bytes result sent to driver
[2025-05-02T02:22:49.586+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 41.0 in stage 65.0 (TID 619) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.587+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 41.0 in stage 65.0 (TID 619)
[2025-05-02T02:22:49.587+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 40.0 in stage 65.0 (TID 618) in 14 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:49.596+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_41 locally
[2025-05-02T02:22:49.598+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 41.0 in stage 65.0 (TID 619). 4181 bytes result sent to driver
[2025-05-02T02:22:49.599+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 42.0 in stage 65.0 (TID 620) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.600+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 41.0 in stage 65.0 (TID 619) in 14 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:49.601+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 42.0 in stage 65.0 (TID 620)
[2025-05-02T02:22:49.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_42 locally
[2025-05-02T02:22:49.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 42.0 in stage 65.0 (TID 620). 4224 bytes result sent to driver
[2025-05-02T02:22:49.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 43.0 in stage 65.0 (TID 621) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.612+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 43.0 in stage 65.0 (TID 621)
[2025-05-02T02:22:49.613+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 42.0 in stage 65.0 (TID 620) in 14 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:49.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_43 locally
[2025-05-02T02:22:49.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 43.0 in stage 65.0 (TID 621). 4181 bytes result sent to driver
[2025-05-02T02:22:49.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 44.0 in stage 65.0 (TID 622) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 43.0 in stage 65.0 (TID 621) in 13 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:49.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 44.0 in stage 65.0 (TID 622)
[2025-05-02T02:22:49.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_44 locally
[2025-05-02T02:22:49.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 44.0 in stage 65.0 (TID 622). 4267 bytes result sent to driver
[2025-05-02T02:22:49.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 45.0 in stage 65.0 (TID 623) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 45.0 in stage 65.0 (TID 623)
[2025-05-02T02:22:49.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 44.0 in stage 65.0 (TID 622) in 23 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:49.657+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_45 locally
[2025-05-02T02:22:49.658+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 45.0 in stage 65.0 (TID 623). 4181 bytes result sent to driver
[2025-05-02T02:22:49.659+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 46.0 in stage 65.0 (TID 624) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 45.0 in stage 65.0 (TID 623) in 13 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:49.661+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 46.0 in stage 65.0 (TID 624)
[2025-05-02T02:22:49.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_46 locally
[2025-05-02T02:22:49.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 46.0 in stage 65.0 (TID 624). 4181 bytes result sent to driver
[2025-05-02T02:22:49.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 47.0 in stage 65.0 (TID 625) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 46.0 in stage 65.0 (TID 624) in 14 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:49.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 47.0 in stage 65.0 (TID 625)
[2025-05-02T02:22:49.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_47 locally
[2025-05-02T02:22:49.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 47.0 in stage 65.0 (TID 625). 4181 bytes result sent to driver
[2025-05-02T02:22:49.684+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 48.0 in stage 65.0 (TID 626) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 47.0 in stage 65.0 (TID 625) in 13 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:49.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 48.0 in stage 65.0 (TID 626)
[2025-05-02T02:22:49.694+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_48 locally
[2025-05-02T02:22:49.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 48.0 in stage 65.0 (TID 626). 4181 bytes result sent to driver
[2025-05-02T02:22:49.700+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Starting task 49.0 in stage 65.0 (TID 627) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:49.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 48.0 in stage 65.0 (TID 626) in 14 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:49.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Running task 49.0 in stage 65.0 (TID 627)
[2025-05-02T02:22:49.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO BlockManager: Found block rdd_159_49 locally
[2025-05-02T02:22:49.716+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO Executor: Finished task 49.0 in stage 65.0 (TID 627). 4224 bytes result sent to driver
[2025-05-02T02:22:49.717+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSetManager: Finished task 49.0 in stage 65.0 (TID 627) in 20 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:49.717+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-05-02T02:22:49.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO DAGScheduler: ResultStage 65 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.794 s
[2025-05-02T02:22:49.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:49.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
[2025-05-02T02:22:49.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:49 INFO DAGScheduler: Job 36 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.797807 s
[2025-05-02T02:22:50.045+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:50.202+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:50.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Got job 37 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:50.204+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Final stage: ResultStage 67 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:50.205+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
[2025-05-02T02:22:50.206+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:50.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[169] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:50.212+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 687.2 KiB, free 394.5 MiB)
[2025-05-02T02:22:50.215+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 155.3 KiB, free 394.3 MiB)
[2025-05-02T02:22:50.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on ***-scheduler:33063 (size: 155.3 KiB, free: 432.6 MiB)
[2025-05-02T02:22:50.217+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:50.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 67 (MapPartitionsRDD[169] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:50.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSchedulerImpl: Adding task set 67.0 with 50 tasks resource profile 0
[2025-05-02T02:22:50.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 628) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 0.0 in stage 67.0 (TID 628)
[2025-05-02T02:22:50.229+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_0 locally
[2025-05-02T02:22:50.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 0.0 in stage 67.0 (TID 628). 4181 bytes result sent to driver
[2025-05-02T02:22:50.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 629) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.233+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 628) in 14 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:50.234+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 1.0 in stage 67.0 (TID 629)
[2025-05-02T02:22:50.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_1 locally
[2025-05-02T02:22:50.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 1.0 in stage 67.0 (TID 629). 4181 bytes result sent to driver
[2025-05-02T02:22:50.249+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 630) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 629) in 18 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:50.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 2.0 in stage 67.0 (TID 630)
[2025-05-02T02:22:50.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManagerInfo: Removed broadcast_59_piece0 on ***-scheduler:33063 in memory (size: 155.5 KiB, free: 432.8 MiB)
[2025-05-02T02:22:50.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_2 locally
[2025-05-02T02:22:50.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 2.0 in stage 67.0 (TID 630). 4224 bytes result sent to driver
[2025-05-02T02:22:50.274+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 631) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.275+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 630) in 25 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:50.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 3.0 in stage 67.0 (TID 631)
[2025-05-02T02:22:50.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_3 locally
[2025-05-02T02:22:50.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 3.0 in stage 67.0 (TID 631). 4181 bytes result sent to driver
[2025-05-02T02:22:50.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 632) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 631) in 13 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:50.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 4.0 in stage 67.0 (TID 632)
[2025-05-02T02:22:50.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_4 locally
[2025-05-02T02:22:50.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 4.0 in stage 67.0 (TID 632). 4349 bytes result sent to driver
[2025-05-02T02:22:50.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 633) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 632) in 13 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:50.301+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 5.0 in stage 67.0 (TID 633)
[2025-05-02T02:22:50.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_5 locally
[2025-05-02T02:22:50.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 5.0 in stage 67.0 (TID 633). 4181 bytes result sent to driver
[2025-05-02T02:22:50.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 634) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 633) in 13 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:50.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 6.0 in stage 67.0 (TID 634)
[2025-05-02T02:22:50.325+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_6 locally
[2025-05-02T02:22:50.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 6.0 in stage 67.0 (TID 634). 4181 bytes result sent to driver
[2025-05-02T02:22:50.328+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 635) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 634) in 17 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:50.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 7.0 in stage 67.0 (TID 635)
[2025-05-02T02:22:50.339+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_7 locally
[2025-05-02T02:22:50.347+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 7.0 in stage 67.0 (TID 635). 4224 bytes result sent to driver
[2025-05-02T02:22:50.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 8.0 in stage 67.0 (TID 636) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 635) in 20 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:50.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 8.0 in stage 67.0 (TID 636)
[2025-05-02T02:22:50.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_8 locally
[2025-05-02T02:22:50.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 8.0 in stage 67.0 (TID 636). 4181 bytes result sent to driver
[2025-05-02T02:22:50.360+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 9.0 in stage 67.0 (TID 637) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.361+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 9.0 in stage 67.0 (TID 637)
[2025-05-02T02:22:50.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 8.0 in stage 67.0 (TID 636) in 13 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:50.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_9 locally
[2025-05-02T02:22:50.372+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 9.0 in stage 67.0 (TID 637). 4181 bytes result sent to driver
[2025-05-02T02:22:50.373+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 10.0 in stage 67.0 (TID 638) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.374+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 9.0 in stage 67.0 (TID 637) in 14 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:50.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 10.0 in stage 67.0 (TID 638)
[2025-05-02T02:22:50.387+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_10 locally
[2025-05-02T02:22:50.389+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 10.0 in stage 67.0 (TID 638). 4181 bytes result sent to driver
[2025-05-02T02:22:50.390+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 11.0 in stage 67.0 (TID 639) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 10.0 in stage 67.0 (TID 638) in 17 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:50.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 11.0 in stage 67.0 (TID 639)
[2025-05-02T02:22:50.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_11 locally
[2025-05-02T02:22:50.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 11.0 in stage 67.0 (TID 639). 4181 bytes result sent to driver
[2025-05-02T02:22:50.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 12.0 in stage 67.0 (TID 640) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 11.0 in stage 67.0 (TID 639) in 18 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:50.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 12.0 in stage 67.0 (TID 640)
[2025-05-02T02:22:50.417+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_12 locally
[2025-05-02T02:22:50.425+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 12.0 in stage 67.0 (TID 640). 4224 bytes result sent to driver
[2025-05-02T02:22:50.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 13.0 in stage 67.0 (TID 641) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 12.0 in stage 67.0 (TID 640) in 20 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:50.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 13.0 in stage 67.0 (TID 641)
[2025-05-02T02:22:50.436+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_13 locally
[2025-05-02T02:22:50.438+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 13.0 in stage 67.0 (TID 641). 4181 bytes result sent to driver
[2025-05-02T02:22:50.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 14.0 in stage 67.0 (TID 642) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 13.0 in stage 67.0 (TID 641) in 14 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:50.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 14.0 in stage 67.0 (TID 642)
[2025-05-02T02:22:50.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_14 locally
[2025-05-02T02:22:50.451+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 14.0 in stage 67.0 (TID 642). 4181 bytes result sent to driver
[2025-05-02T02:22:50.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 15.0 in stage 67.0 (TID 643) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 15.0 in stage 67.0 (TID 643)
[2025-05-02T02:22:50.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 14.0 in stage 67.0 (TID 642) in 14 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:50.462+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_15 locally
[2025-05-02T02:22:50.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 15.0 in stage 67.0 (TID 643). 4181 bytes result sent to driver
[2025-05-02T02:22:50.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 16.0 in stage 67.0 (TID 644) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.465+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 16.0 in stage 67.0 (TID 644)
[2025-05-02T02:22:50.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 15.0 in stage 67.0 (TID 643) in 13 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:50.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_16 locally
[2025-05-02T02:22:50.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 16.0 in stage 67.0 (TID 644). 4181 bytes result sent to driver
[2025-05-02T02:22:50.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 17.0 in stage 67.0 (TID 645) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 16.0 in stage 67.0 (TID 644) in 13 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:50.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 17.0 in stage 67.0 (TID 645)
[2025-05-02T02:22:50.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_17 locally
[2025-05-02T02:22:50.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 17.0 in stage 67.0 (TID 645). 4224 bytes result sent to driver
[2025-05-02T02:22:50.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 18.0 in stage 67.0 (TID 646) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.500+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 17.0 in stage 67.0 (TID 645) in 23 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:50.501+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 18.0 in stage 67.0 (TID 646)
[2025-05-02T02:22:50.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_18 locally
[2025-05-02T02:22:50.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 18.0 in stage 67.0 (TID 646). 4181 bytes result sent to driver
[2025-05-02T02:22:50.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 19.0 in stage 67.0 (TID 647) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 19.0 in stage 67.0 (TID 647)
[2025-05-02T02:22:50.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 18.0 in stage 67.0 (TID 646) in 13 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:50.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_19 locally
[2025-05-02T02:22:50.523+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 19.0 in stage 67.0 (TID 647). 4181 bytes result sent to driver
[2025-05-02T02:22:50.524+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 20.0 in stage 67.0 (TID 648) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 20.0 in stage 67.0 (TID 648)
[2025-05-02T02:22:50.526+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 19.0 in stage 67.0 (TID 647) in 13 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:50.534+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_20 locally
[2025-05-02T02:22:50.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 20.0 in stage 67.0 (TID 648). 4181 bytes result sent to driver
[2025-05-02T02:22:50.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 21.0 in stage 67.0 (TID 649) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 21.0 in stage 67.0 (TID 649)
[2025-05-02T02:22:50.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 20.0 in stage 67.0 (TID 648) in 13 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:50.546+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_21 locally
[2025-05-02T02:22:50.548+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 21.0 in stage 67.0 (TID 649). 4181 bytes result sent to driver
[2025-05-02T02:22:50.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 22.0 in stage 67.0 (TID 650) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 22.0 in stage 67.0 (TID 650)
[2025-05-02T02:22:50.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 21.0 in stage 67.0 (TID 649) in 13 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:50.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_22 locally
[2025-05-02T02:22:50.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 22.0 in stage 67.0 (TID 650). 4224 bytes result sent to driver
[2025-05-02T02:22:50.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 23.0 in stage 67.0 (TID 651) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.569+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 22.0 in stage 67.0 (TID 650) in 20 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:50.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 23.0 in stage 67.0 (TID 651)
[2025-05-02T02:22:50.578+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_23 locally
[2025-05-02T02:22:50.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 23.0 in stage 67.0 (TID 651). 4181 bytes result sent to driver
[2025-05-02T02:22:50.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 24.0 in stage 67.0 (TID 652) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 23.0 in stage 67.0 (TID 651) in 13 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:50.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 24.0 in stage 67.0 (TID 652)
[2025-05-02T02:22:50.590+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_24 locally
[2025-05-02T02:22:50.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 24.0 in stage 67.0 (TID 652). 4181 bytes result sent to driver
[2025-05-02T02:22:50.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 25.0 in stage 67.0 (TID 653) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.593+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 24.0 in stage 67.0 (TID 652) in 13 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:50.594+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 25.0 in stage 67.0 (TID 653)
[2025-05-02T02:22:50.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_25 locally
[2025-05-02T02:22:50.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 25.0 in stage 67.0 (TID 653). 4181 bytes result sent to driver
[2025-05-02T02:22:50.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 26.0 in stage 67.0 (TID 654) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 26.0 in stage 67.0 (TID 654)
[2025-05-02T02:22:50.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 25.0 in stage 67.0 (TID 653) in 17 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:50.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_26 locally
[2025-05-02T02:22:50.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 26.0 in stage 67.0 (TID 654). 4181 bytes result sent to driver
[2025-05-02T02:22:50.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 27.0 in stage 67.0 (TID 655) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 27.0 in stage 67.0 (TID 655)
[2025-05-02T02:22:50.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 26.0 in stage 67.0 (TID 654) in 13 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:50.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_27 locally
[2025-05-02T02:22:50.643+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 27.0 in stage 67.0 (TID 655). 4224 bytes result sent to driver
[2025-05-02T02:22:50.644+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 28.0 in stage 67.0 (TID 656) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 27.0 in stage 67.0 (TID 655) in 23 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:50.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 28.0 in stage 67.0 (TID 656)
[2025-05-02T02:22:50.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_28 locally
[2025-05-02T02:22:50.658+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 28.0 in stage 67.0 (TID 656). 4181 bytes result sent to driver
[2025-05-02T02:22:50.659+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 29.0 in stage 67.0 (TID 657) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 28.0 in stage 67.0 (TID 656) in 16 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:50.661+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 29.0 in stage 67.0 (TID 657)
[2025-05-02T02:22:50.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_29 locally
[2025-05-02T02:22:50.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 29.0 in stage 67.0 (TID 657). 4181 bytes result sent to driver
[2025-05-02T02:22:50.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 30.0 in stage 67.0 (TID 658) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 30.0 in stage 67.0 (TID 658)
[2025-05-02T02:22:50.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 29.0 in stage 67.0 (TID 657) in 17 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:50.690+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_30 locally
[2025-05-02T02:22:50.693+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 30.0 in stage 67.0 (TID 658). 4181 bytes result sent to driver
[2025-05-02T02:22:50.694+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 31.0 in stage 67.0 (TID 659) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.695+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 31.0 in stage 67.0 (TID 659)
[2025-05-02T02:22:50.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 30.0 in stage 67.0 (TID 658) in 19 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:50.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_31 locally
[2025-05-02T02:22:50.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 31.0 in stage 67.0 (TID 659). 4181 bytes result sent to driver
[2025-05-02T02:22:50.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 32.0 in stage 67.0 (TID 660) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 31.0 in stage 67.0 (TID 659) in 15 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:50.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 32.0 in stage 67.0 (TID 660)
[2025-05-02T02:22:50.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_32 locally
[2025-05-02T02:22:50.731+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 32.0 in stage 67.0 (TID 660). 4267 bytes result sent to driver
[2025-05-02T02:22:50.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 33.0 in stage 67.0 (TID 661) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 32.0 in stage 67.0 (TID 660) in 23 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:50.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 33.0 in stage 67.0 (TID 661)
[2025-05-02T02:22:50.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_33 locally
[2025-05-02T02:22:50.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 33.0 in stage 67.0 (TID 661). 4181 bytes result sent to driver
[2025-05-02T02:22:50.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 34.0 in stage 67.0 (TID 662) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 33.0 in stage 67.0 (TID 661) in 17 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:50.750+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 34.0 in stage 67.0 (TID 662)
[2025-05-02T02:22:50.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_34 locally
[2025-05-02T02:22:50.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 34.0 in stage 67.0 (TID 662). 4181 bytes result sent to driver
[2025-05-02T02:22:50.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 35.0 in stage 67.0 (TID 663) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 35.0 in stage 67.0 (TID 663)
[2025-05-02T02:22:50.765+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 34.0 in stage 67.0 (TID 662) in 15 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:50.773+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_35 locally
[2025-05-02T02:22:50.775+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 35.0 in stage 67.0 (TID 663). 4181 bytes result sent to driver
[2025-05-02T02:22:50.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 36.0 in stage 67.0 (TID 664) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.777+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 36.0 in stage 67.0 (TID 664)
[2025-05-02T02:22:50.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 35.0 in stage 67.0 (TID 663) in 14 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:50.787+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_36 locally
[2025-05-02T02:22:50.789+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 36.0 in stage 67.0 (TID 664). 4181 bytes result sent to driver
[2025-05-02T02:22:50.790+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 37.0 in stage 67.0 (TID 665) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 37.0 in stage 67.0 (TID 665)
[2025-05-02T02:22:50.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 36.0 in stage 67.0 (TID 664) in 15 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:50.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_37 locally
[2025-05-02T02:22:50.803+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 37.0 in stage 67.0 (TID 665). 4181 bytes result sent to driver
[2025-05-02T02:22:50.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 38.0 in stage 67.0 (TID 666) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.805+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 38.0 in stage 67.0 (TID 666)
[2025-05-02T02:22:50.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 37.0 in stage 67.0 (TID 665) in 15 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:50.822+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_38 locally
[2025-05-02T02:22:50.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 38.0 in stage 67.0 (TID 666). 4224 bytes result sent to driver
[2025-05-02T02:22:50.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 39.0 in stage 67.0 (TID 667) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 39.0 in stage 67.0 (TID 667)
[2025-05-02T02:22:50.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 38.0 in stage 67.0 (TID 666) in 21 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:50.836+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_39 locally
[2025-05-02T02:22:50.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 39.0 in stage 67.0 (TID 667). 4181 bytes result sent to driver
[2025-05-02T02:22:50.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 40.0 in stage 67.0 (TID 668) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.839+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 40.0 in stage 67.0 (TID 668)
[2025-05-02T02:22:50.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 39.0 in stage 67.0 (TID 667) in 14 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:50.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_40 locally
[2025-05-02T02:22:50.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 40.0 in stage 67.0 (TID 668). 4181 bytes result sent to driver
[2025-05-02T02:22:50.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 41.0 in stage 67.0 (TID 669) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 41.0 in stage 67.0 (TID 669)
[2025-05-02T02:22:50.853+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 40.0 in stage 67.0 (TID 668) in 13 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:50.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_41 locally
[2025-05-02T02:22:50.863+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 41.0 in stage 67.0 (TID 669). 4181 bytes result sent to driver
[2025-05-02T02:22:50.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 42.0 in stage 67.0 (TID 670) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.866+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 41.0 in stage 67.0 (TID 669) in 13 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:50.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 42.0 in stage 67.0 (TID 670)
[2025-05-02T02:22:50.875+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_42 locally
[2025-05-02T02:22:50.877+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 42.0 in stage 67.0 (TID 670). 4224 bytes result sent to driver
[2025-05-02T02:22:50.878+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 43.0 in stage 67.0 (TID 671) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.879+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 43.0 in stage 67.0 (TID 671)
[2025-05-02T02:22:50.879+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 42.0 in stage 67.0 (TID 670) in 14 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:50.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_43 locally
[2025-05-02T02:22:50.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 43.0 in stage 67.0 (TID 671). 4267 bytes result sent to driver
[2025-05-02T02:22:50.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 44.0 in stage 67.0 (TID 672) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 43.0 in stage 67.0 (TID 671) in 20 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:50.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 44.0 in stage 67.0 (TID 672)
[2025-05-02T02:22:50.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_44 locally
[2025-05-02T02:22:50.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 44.0 in stage 67.0 (TID 672). 4181 bytes result sent to driver
[2025-05-02T02:22:50.910+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 45.0 in stage 67.0 (TID 673) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.911+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 44.0 in stage 67.0 (TID 672) in 13 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:50.912+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 45.0 in stage 67.0 (TID 673)
[2025-05-02T02:22:50.921+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_45 locally
[2025-05-02T02:22:50.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 45.0 in stage 67.0 (TID 673). 4181 bytes result sent to driver
[2025-05-02T02:22:50.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 46.0 in stage 67.0 (TID 674) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 45.0 in stage 67.0 (TID 673) in 14 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:50.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 46.0 in stage 67.0 (TID 674)
[2025-05-02T02:22:50.938+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_46 locally
[2025-05-02T02:22:50.940+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 46.0 in stage 67.0 (TID 674). 4181 bytes result sent to driver
[2025-05-02T02:22:50.941+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 47.0 in stage 67.0 (TID 675) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.942+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 46.0 in stage 67.0 (TID 674) in 18 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:50.943+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 47.0 in stage 67.0 (TID 675)
[2025-05-02T02:22:50.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_47 locally
[2025-05-02T02:22:50.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 47.0 in stage 67.0 (TID 675). 4181 bytes result sent to driver
[2025-05-02T02:22:50.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 48.0 in stage 67.0 (TID 676) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 48.0 in stage 67.0 (TID 676)
[2025-05-02T02:22:50.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 47.0 in stage 67.0 (TID 675) in 14 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:50.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_48 locally
[2025-05-02T02:22:50.973+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 48.0 in stage 67.0 (TID 676). 4267 bytes result sent to driver
[2025-05-02T02:22:50.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Starting task 49.0 in stage 67.0 (TID 677) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:50.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Running task 49.0 in stage 67.0 (TID 677)
[2025-05-02T02:22:50.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 48.0 in stage 67.0 (TID 676) in 21 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:50.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO BlockManager: Found block rdd_29_49 locally
[2025-05-02T02:22:50.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO Executor: Finished task 49.0 in stage 67.0 (TID 677). 4181 bytes result sent to driver
[2025-05-02T02:22:50.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSetManager: Finished task 49.0 in stage 67.0 (TID 677) in 15 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:50.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-05-02T02:22:50.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: ResultStage 67 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.782 s
[2025-05-02T02:22:50.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:50.992+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
[2025-05-02T02:22:50.993+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO DAGScheduler: Job 37 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.787262 s
[2025-05-02T02:22:50.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:50 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:51.205+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:51.207+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Snapshot: DELTA: Compute snapshot for version: 0
[2025-05-02T02:22:51.282+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Registering RDD 172 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 15
[2025-05-02T02:22:51.283+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Got map stage job 38 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:51.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Final stage: ShuffleMapStage 69 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:51.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-05-02T02:22:51.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:51.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[172] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:51.293+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 605.6 KiB, free 394.5 MiB)
[2025-05-02T02:22:51.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 138.9 KiB, free 394.4 MiB)
[2025-05-02T02:22:51.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on ***-scheduler:33063 (size: 138.9 KiB, free: 432.6 MiB)
[2025-05-02T02:22:51.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:51.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[172] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:51.301+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSchedulerImpl: Adding task set 69.0 with 50 tasks resource profile 0
[2025-05-02T02:22:51.302+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 678) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 0.0 in stage 69.0 (TID 678)
[2025-05-02T02:22:51.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_0 locally
[2025-05-02T02:22:51.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 0.0 in stage 69.0 (TID 678). 4577 bytes result sent to driver
[2025-05-02T02:22:51.346+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 679) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.347+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 1.0 in stage 69.0 (TID 679)
[2025-05-02T02:22:51.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 678) in 46 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:51.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_1 locally
[2025-05-02T02:22:51.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 1.0 in stage 69.0 (TID 679). 4577 bytes result sent to driver
[2025-05-02T02:22:51.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 680) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 679) in 32 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:51.380+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 2.0 in stage 69.0 (TID 680)
[2025-05-02T02:22:51.388+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_2 locally
[2025-05-02T02:22:51.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 2.0 in stage 69.0 (TID 680). 4620 bytes result sent to driver
[2025-05-02T02:22:51.409+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 681) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.410+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 680) in 32 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:51.411+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 3.0 in stage 69.0 (TID 681)
[2025-05-02T02:22:51.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_3 locally
[2025-05-02T02:22:51.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 3.0 in stage 69.0 (TID 681). 4577 bytes result sent to driver
[2025-05-02T02:22:51.440+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 682) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 681) in 32 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:51.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 4.0 in stage 69.0 (TID 682)
[2025-05-02T02:22:51.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManagerInfo: Removed broadcast_60_piece0 on ***-scheduler:33063 in memory (size: 155.3 KiB, free: 432.8 MiB)
[2025-05-02T02:22:51.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_4 locally
[2025-05-02T02:22:51.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 4.0 in stage 69.0 (TID 682). 4620 bytes result sent to driver
[2025-05-02T02:22:51.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 683) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.481+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 682) in 41 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:51.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 5.0 in stage 69.0 (TID 683)
[2025-05-02T02:22:51.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_5 locally
[2025-05-02T02:22:51.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 5.0 in stage 69.0 (TID 683). 4577 bytes result sent to driver
[2025-05-02T02:22:51.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 684) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 683) in 32 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:51.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 6.0 in stage 69.0 (TID 684)
[2025-05-02T02:22:51.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_6 locally
[2025-05-02T02:22:51.540+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 6.0 in stage 69.0 (TID 684). 4577 bytes result sent to driver
[2025-05-02T02:22:51.541+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 685) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.543+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 7.0 in stage 69.0 (TID 685)
[2025-05-02T02:22:51.544+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 684) in 31 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:51.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_7 locally
[2025-05-02T02:22:51.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 7.0 in stage 69.0 (TID 685). 4577 bytes result sent to driver
[2025-05-02T02:22:51.571+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 686) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 8.0 in stage 69.0 (TID 686)
[2025-05-02T02:22:51.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 685) in 30 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:51.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_8 locally
[2025-05-02T02:22:51.600+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 8.0 in stage 69.0 (TID 686). 4577 bytes result sent to driver
[2025-05-02T02:22:51.601+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 687) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.602+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 686) in 30 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:51.603+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 9.0 in stage 69.0 (TID 687)
[2025-05-02T02:22:51.612+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_9 locally
[2025-05-02T02:22:51.631+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 9.0 in stage 69.0 (TID 687). 4577 bytes result sent to driver
[2025-05-02T02:22:51.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 10.0 in stage 69.0 (TID 688) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 687) in 32 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:51.633+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 10.0 in stage 69.0 (TID 688)
[2025-05-02T02:22:51.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_10 locally
[2025-05-02T02:22:51.669+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 10.0 in stage 69.0 (TID 688). 4577 bytes result sent to driver
[2025-05-02T02:22:51.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 11.0 in stage 69.0 (TID 689) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 10.0 in stage 69.0 (TID 688) in 39 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:51.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 11.0 in stage 69.0 (TID 689)
[2025-05-02T02:22:51.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_11 locally
[2025-05-02T02:22:51.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 11.0 in stage 69.0 (TID 689). 4577 bytes result sent to driver
[2025-05-02T02:22:51.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 12.0 in stage 69.0 (TID 690) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 12.0 in stage 69.0 (TID 690)
[2025-05-02T02:22:51.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 11.0 in stage 69.0 (TID 689) in 33 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:51.712+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_12 locally
[2025-05-02T02:22:51.731+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 12.0 in stage 69.0 (TID 690). 4577 bytes result sent to driver
[2025-05-02T02:22:51.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 13.0 in stage 69.0 (TID 691) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 13.0 in stage 69.0 (TID 691)
[2025-05-02T02:22:51.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 12.0 in stage 69.0 (TID 690) in 31 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:51.743+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_13 locally
[2025-05-02T02:22:51.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 13.0 in stage 69.0 (TID 691). 4577 bytes result sent to driver
[2025-05-02T02:22:51.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 14.0 in stage 69.0 (TID 692) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 13.0 in stage 69.0 (TID 691) in 31 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:51.765+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 14.0 in stage 69.0 (TID 692)
[2025-05-02T02:22:51.781+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_14 locally
[2025-05-02T02:22:51.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 14.0 in stage 69.0 (TID 692). 4620 bytes result sent to driver
[2025-05-02T02:22:51.799+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 15.0 in stage 69.0 (TID 693) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.800+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 14.0 in stage 69.0 (TID 692) in 37 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:51.801+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 15.0 in stage 69.0 (TID 693)
[2025-05-02T02:22:51.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_15 locally
[2025-05-02T02:22:51.828+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 15.0 in stage 69.0 (TID 693). 4577 bytes result sent to driver
[2025-05-02T02:22:51.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 16.0 in stage 69.0 (TID 694) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 15.0 in stage 69.0 (TID 693) in 30 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:51.832+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 16.0 in stage 69.0 (TID 694)
[2025-05-02T02:22:51.839+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_16 locally
[2025-05-02T02:22:51.857+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 16.0 in stage 69.0 (TID 694). 4577 bytes result sent to driver
[2025-05-02T02:22:51.858+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 17.0 in stage 69.0 (TID 695) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 16.0 in stage 69.0 (TID 694) in 29 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:51.860+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 17.0 in stage 69.0 (TID 695)
[2025-05-02T02:22:51.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_17 locally
[2025-05-02T02:22:51.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 17.0 in stage 69.0 (TID 695). 4577 bytes result sent to driver
[2025-05-02T02:22:51.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 18.0 in stage 69.0 (TID 696) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.889+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 18.0 in stage 69.0 (TID 696)
[2025-05-02T02:22:51.889+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 17.0 in stage 69.0 (TID 695) in 30 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:51.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_18 locally
[2025-05-02T02:22:51.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 18.0 in stage 69.0 (TID 696). 4577 bytes result sent to driver
[2025-05-02T02:22:51.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 19.0 in stage 69.0 (TID 697) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 18.0 in stage 69.0 (TID 696) in 31 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:51.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 19.0 in stage 69.0 (TID 697)
[2025-05-02T02:22:51.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_19 locally
[2025-05-02T02:22:51.958+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 19.0 in stage 69.0 (TID 697). 4577 bytes result sent to driver
[2025-05-02T02:22:51.959+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 20.0 in stage 69.0 (TID 698) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.960+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 19.0 in stage 69.0 (TID 697) in 40 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:51.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 20.0 in stage 69.0 (TID 698)
[2025-05-02T02:22:51.972+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO BlockManager: Found block rdd_90_20 locally
[2025-05-02T02:22:51.996+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Finished task 20.0 in stage 69.0 (TID 698). 4577 bytes result sent to driver
[2025-05-02T02:22:51.997+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Starting task 21.0 in stage 69.0 (TID 699) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:51.998+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO TaskSetManager: Finished task 20.0 in stage 69.0 (TID 698) in 39 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:51.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:51 INFO Executor: Running task 21.0 in stage 69.0 (TID 699)
[2025-05-02T02:22:52.008+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_21 locally
[2025-05-02T02:22:52.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 21.0 in stage 69.0 (TID 699). 4577 bytes result sent to driver
[2025-05-02T02:22:52.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 22.0 in stage 69.0 (TID 700) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 21.0 in stage 69.0 (TID 699) in 30 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:52.030+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 22.0 in stage 69.0 (TID 700)
[2025-05-02T02:22:52.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_22 locally
[2025-05-02T02:22:52.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 22.0 in stage 69.0 (TID 700). 4577 bytes result sent to driver
[2025-05-02T02:22:52.058+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 23.0 in stage 69.0 (TID 701) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.059+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 22.0 in stage 69.0 (TID 700) in 31 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:52.060+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 23.0 in stage 69.0 (TID 701)
[2025-05-02T02:22:52.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_23 locally
[2025-05-02T02:22:52.095+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 23.0 in stage 69.0 (TID 701). 4663 bytes result sent to driver
[2025-05-02T02:22:52.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 24.0 in stage 69.0 (TID 702) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.097+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 23.0 in stage 69.0 (TID 701) in 38 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:52.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 24.0 in stage 69.0 (TID 702)
[2025-05-02T02:22:52.106+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_24 locally
[2025-05-02T02:22:52.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 24.0 in stage 69.0 (TID 702). 4577 bytes result sent to driver
[2025-05-02T02:22:52.126+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 25.0 in stage 69.0 (TID 703) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 24.0 in stage 69.0 (TID 702) in 31 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:52.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 25.0 in stage 69.0 (TID 703)
[2025-05-02T02:22:52.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_25 locally
[2025-05-02T02:22:52.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 25.0 in stage 69.0 (TID 703). 4577 bytes result sent to driver
[2025-05-02T02:22:52.160+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 26.0 in stage 69.0 (TID 704) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.161+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 25.0 in stage 69.0 (TID 703) in 33 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:52.162+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 26.0 in stage 69.0 (TID 704)
[2025-05-02T02:22:52.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_26 locally
[2025-05-02T02:22:52.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 26.0 in stage 69.0 (TID 704). 4577 bytes result sent to driver
[2025-05-02T02:22:52.191+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 27.0 in stage 69.0 (TID 705) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 26.0 in stage 69.0 (TID 704) in 31 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:52.193+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 27.0 in stage 69.0 (TID 705)
[2025-05-02T02:22:52.201+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_27 locally
[2025-05-02T02:22:52.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 27.0 in stage 69.0 (TID 705). 4577 bytes result sent to driver
[2025-05-02T02:22:52.221+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 28.0 in stage 69.0 (TID 706) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 27.0 in stage 69.0 (TID 705) in 31 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:52.224+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 28.0 in stage 69.0 (TID 706)
[2025-05-02T02:22:52.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_28 locally
[2025-05-02T02:22:52.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 28.0 in stage 69.0 (TID 706). 4577 bytes result sent to driver
[2025-05-02T02:22:52.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 29.0 in stage 69.0 (TID 707) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 28.0 in stage 69.0 (TID 706) in 32 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:52.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 29.0 in stage 69.0 (TID 707)
[2025-05-02T02:22:52.263+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_29 locally
[2025-05-02T02:22:52.282+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 29.0 in stage 69.0 (TID 707). 4577 bytes result sent to driver
[2025-05-02T02:22:52.283+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 30.0 in stage 69.0 (TID 708) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.284+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 29.0 in stage 69.0 (TID 707) in 31 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:52.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 30.0 in stage 69.0 (TID 708)
[2025-05-02T02:22:52.298+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_30 locally
[2025-05-02T02:22:52.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 30.0 in stage 69.0 (TID 708). 4577 bytes result sent to driver
[2025-05-02T02:22:52.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 31.0 in stage 69.0 (TID 709) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 30.0 in stage 69.0 (TID 708) in 39 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:52.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 31.0 in stage 69.0 (TID 709)
[2025-05-02T02:22:52.332+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_31 locally
[2025-05-02T02:22:52.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 31.0 in stage 69.0 (TID 709). 4577 bytes result sent to driver
[2025-05-02T02:22:52.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 32.0 in stage 69.0 (TID 710) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 31.0 in stage 69.0 (TID 709) in 32 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:52.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 32.0 in stage 69.0 (TID 710)
[2025-05-02T02:22:52.363+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_32 locally
[2025-05-02T02:22:52.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 32.0 in stage 69.0 (TID 710). 4663 bytes result sent to driver
[2025-05-02T02:22:52.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 33.0 in stage 69.0 (TID 711) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 33.0 in stage 69.0 (TID 711)
[2025-05-02T02:22:52.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 32.0 in stage 69.0 (TID 710) in 42 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:52.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_33 locally
[2025-05-02T02:22:52.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 33.0 in stage 69.0 (TID 711). 4577 bytes result sent to driver
[2025-05-02T02:22:52.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 34.0 in stage 69.0 (TID 712) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 33.0 in stage 69.0 (TID 711) in 31 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:52.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 34.0 in stage 69.0 (TID 712)
[2025-05-02T02:22:52.434+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_34 locally
[2025-05-02T02:22:52.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 34.0 in stage 69.0 (TID 712). 4577 bytes result sent to driver
[2025-05-02T02:22:52.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 35.0 in stage 69.0 (TID 713) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 34.0 in stage 69.0 (TID 712) in 32 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:52.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 35.0 in stage 69.0 (TID 713)
[2025-05-02T02:22:52.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_35 locally
[2025-05-02T02:22:52.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 35.0 in stage 69.0 (TID 713). 4577 bytes result sent to driver
[2025-05-02T02:22:52.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 36.0 in stage 69.0 (TID 714) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.488+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 35.0 in stage 69.0 (TID 713) in 33 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:52.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 36.0 in stage 69.0 (TID 714)
[2025-05-02T02:22:52.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_36 locally
[2025-05-02T02:22:52.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 36.0 in stage 69.0 (TID 714). 4577 bytes result sent to driver
[2025-05-02T02:22:52.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 37.0 in stage 69.0 (TID 715) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 36.0 in stage 69.0 (TID 714) in 33 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:52.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 37.0 in stage 69.0 (TID 715)
[2025-05-02T02:22:52.528+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_37 locally
[2025-05-02T02:22:52.548+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 37.0 in stage 69.0 (TID 715). 4577 bytes result sent to driver
[2025-05-02T02:22:52.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 38.0 in stage 69.0 (TID 716) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 38.0 in stage 69.0 (TID 716)
[2025-05-02T02:22:52.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 37.0 in stage 69.0 (TID 715) in 32 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:52.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_38 locally
[2025-05-02T02:22:52.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 38.0 in stage 69.0 (TID 716). 4577 bytes result sent to driver
[2025-05-02T02:22:52.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 39.0 in stage 69.0 (TID 717) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 38.0 in stage 69.0 (TID 716) in 32 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:52.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 39.0 in stage 69.0 (TID 717)
[2025-05-02T02:22:52.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_39 locally
[2025-05-02T02:22:52.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 39.0 in stage 69.0 (TID 717). 4577 bytes result sent to driver
[2025-05-02T02:22:52.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 40.0 in stage 69.0 (TID 718) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.612+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 39.0 in stage 69.0 (TID 717) in 31 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:52.613+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 40.0 in stage 69.0 (TID 718)
[2025-05-02T02:22:52.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_40 locally
[2025-05-02T02:22:52.641+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 40.0 in stage 69.0 (TID 718). 4577 bytes result sent to driver
[2025-05-02T02:22:52.642+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 41.0 in stage 69.0 (TID 719) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.644+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 40.0 in stage 69.0 (TID 718) in 32 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:52.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 41.0 in stage 69.0 (TID 719)
[2025-05-02T02:22:52.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_41 locally
[2025-05-02T02:22:52.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 41.0 in stage 69.0 (TID 719). 4577 bytes result sent to driver
[2025-05-02T02:22:52.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 42.0 in stage 69.0 (TID 720) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.672+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 41.0 in stage 69.0 (TID 719) in 29 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:52.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 42.0 in stage 69.0 (TID 720)
[2025-05-02T02:22:52.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_42 locally
[2025-05-02T02:22:52.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 42.0 in stage 69.0 (TID 720). 4706 bytes result sent to driver
[2025-05-02T02:22:52.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 43.0 in stage 69.0 (TID 721) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 43.0 in stage 69.0 (TID 721)
[2025-05-02T02:22:52.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 42.0 in stage 69.0 (TID 720) in 38 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:52.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_43 locally
[2025-05-02T02:22:52.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 43.0 in stage 69.0 (TID 721). 4577 bytes result sent to driver
[2025-05-02T02:22:52.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 44.0 in stage 69.0 (TID 722) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.739+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 43.0 in stage 69.0 (TID 721) in 30 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:52.739+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 44.0 in stage 69.0 (TID 722)
[2025-05-02T02:22:52.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_44 locally
[2025-05-02T02:22:52.766+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 44.0 in stage 69.0 (TID 722). 4577 bytes result sent to driver
[2025-05-02T02:22:52.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 45.0 in stage 69.0 (TID 723) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 44.0 in stage 69.0 (TID 722) in 30 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:52.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 45.0 in stage 69.0 (TID 723)
[2025-05-02T02:22:52.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_45 locally
[2025-05-02T02:22:52.795+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 45.0 in stage 69.0 (TID 723). 4577 bytes result sent to driver
[2025-05-02T02:22:52.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 46.0 in stage 69.0 (TID 724) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 45.0 in stage 69.0 (TID 723) in 29 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:52.797+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 46.0 in stage 69.0 (TID 724)
[2025-05-02T02:22:52.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_46 locally
[2025-05-02T02:22:52.824+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 46.0 in stage 69.0 (TID 724). 4577 bytes result sent to driver
[2025-05-02T02:22:52.825+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 47.0 in stage 69.0 (TID 725) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 46.0 in stage 69.0 (TID 724) in 30 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:52.827+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 47.0 in stage 69.0 (TID 725)
[2025-05-02T02:22:52.838+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_47 locally
[2025-05-02T02:22:52.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 47.0 in stage 69.0 (TID 725). 4577 bytes result sent to driver
[2025-05-02T02:22:52.857+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 48.0 in stage 69.0 (TID 726) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 47.0 in stage 69.0 (TID 725) in 33 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:52.859+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 48.0 in stage 69.0 (TID 726)
[2025-05-02T02:22:52.867+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_48 locally
[2025-05-02T02:22:52.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 48.0 in stage 69.0 (TID 726). 4577 bytes result sent to driver
[2025-05-02T02:22:52.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 49.0 in stage 69.0 (TID 727) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10195 bytes)
[2025-05-02T02:22:52.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 48.0 in stage 69.0 (TID 726) in 29 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:52.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 49.0 in stage 69.0 (TID 727)
[2025-05-02T02:22:52.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManager: Found block rdd_90_49 locally
[2025-05-02T02:22:52.914+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Finished task 49.0 in stage 69.0 (TID 727). 4577 bytes result sent to driver
[2025-05-02T02:22:52.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Finished task 49.0 in stage 69.0 (TID 727) in 29 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:52.916+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-02T02:22:52.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: ShuffleMapStage 69 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.630 s
[2025-05-02T02:22:52.917+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:52.918+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:52.919+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:52.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:52.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:52.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: Got job 39 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:52.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: Final stage: ResultStage 72 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:52.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
[2025-05-02T02:22:52.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:52.957+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[175] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:52.961+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 537.2 KiB, free 394.7 MiB)
[2025-05-02T02:22:52.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 125.4 KiB, free 394.6 MiB)
[2025-05-02T02:22:52.965+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on ***-scheduler:33063 (size: 125.4 KiB, free: 432.7 MiB)
[2025-05-02T02:22:52.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:52.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[175] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:52.968+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-05-02T02:22:52.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 728) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:52.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO Executor: Running task 0.0 in stage 72.0 (TID 728)
[2025-05-02T02:22:52.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO BlockManagerInfo: Removed broadcast_61_piece0 on ***-scheduler:33063 in memory (size: 138.9 KiB, free: 432.8 MiB)
[2025-05-02T02:22:52.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO ShuffleBlockFetcherIterator: Getting 50 (4.8 KiB) non-empty blocks including 50 (4.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:52.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:53.010+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 0.0 in stage 72.0 (TID 728). 7100 bytes result sent to driver
[2025-05-02T02:22:53.011+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 728) in 45 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:53.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-02T02:22:53.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: ResultStage 72 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.057 s
[2025-05-02T02:22:53.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:53.015+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-05-02T02:22:53.016+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Job 39 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.059585 s
[2025-05-02T02:22:53.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Snapshot: DELTA: Done
[2025-05-02T02:22:53.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:53.158+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Got job 40 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:53.159+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Final stage: ResultStage 74 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:53.160+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-05-02T02:22:53.161+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:53.162+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[177] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:53.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 687.2 KiB, free 394.6 MiB)
[2025-05-02T02:22:53.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 155.3 KiB, free 394.5 MiB)
[2025-05-02T02:22:53.170+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on ***-scheduler:33063 (size: 155.3 KiB, free: 432.7 MiB)
[2025-05-02T02:22:53.171+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:53.172+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 74 (MapPartitionsRDD[177] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:53.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSchedulerImpl: Adding task set 74.0 with 50 tasks resource profile 0
[2025-05-02T02:22:53.174+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 729) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.175+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 0.0 in stage 74.0 (TID 729)
[2025-05-02T02:22:53.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_0 locally
[2025-05-02T02:22:53.183+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 0.0 in stage 74.0 (TID 729). 4181 bytes result sent to driver
[2025-05-02T02:22:53.184+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 730) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.185+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 729) in 13 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:53.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 1.0 in stage 74.0 (TID 730)
[2025-05-02T02:22:53.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_1 locally
[2025-05-02T02:22:53.200+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 1.0 in stage 74.0 (TID 730). 4181 bytes result sent to driver
[2025-05-02T02:22:53.201+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 731) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.202+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 730) in 17 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:53.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 2.0 in stage 74.0 (TID 731)
[2025-05-02T02:22:53.214+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_2 locally
[2025-05-02T02:22:53.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 2.0 in stage 74.0 (TID 731). 4349 bytes result sent to driver
[2025-05-02T02:22:53.217+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 732) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 731) in 17 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:53.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 3.0 in stage 74.0 (TID 732)
[2025-05-02T02:22:53.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_3 locally
[2025-05-02T02:22:53.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 3.0 in stage 74.0 (TID 732). 4224 bytes result sent to driver
[2025-05-02T02:22:53.240+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManagerInfo: Removed broadcast_62_piece0 on ***-scheduler:33063 in memory (size: 125.4 KiB, free: 432.8 MiB)
[2025-05-02T02:22:53.241+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 4.0 in stage 74.0 (TID 733) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 4.0 in stage 74.0 (TID 733)
[2025-05-02T02:22:53.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 732) in 23 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:53.250+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_4 locally
[2025-05-02T02:22:53.252+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 4.0 in stage 74.0 (TID 733). 4181 bytes result sent to driver
[2025-05-02T02:22:53.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 5.0 in stage 74.0 (TID 734) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 5.0 in stage 74.0 (TID 734)
[2025-05-02T02:22:53.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 4.0 in stage 74.0 (TID 733) in 14 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:53.266+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_5 locally
[2025-05-02T02:22:53.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 5.0 in stage 74.0 (TID 734). 4181 bytes result sent to driver
[2025-05-02T02:22:53.269+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 6.0 in stage 74.0 (TID 735) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 6.0 in stage 74.0 (TID 735)
[2025-05-02T02:22:53.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 5.0 in stage 74.0 (TID 734) in 17 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:53.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_6 locally
[2025-05-02T02:22:53.280+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 6.0 in stage 74.0 (TID 735). 4181 bytes result sent to driver
[2025-05-02T02:22:53.281+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 7.0 in stage 74.0 (TID 736) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.282+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 6.0 in stage 74.0 (TID 735) in 13 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:53.283+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 7.0 in stage 74.0 (TID 736)
[2025-05-02T02:22:53.294+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_7 locally
[2025-05-02T02:22:53.296+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 7.0 in stage 74.0 (TID 736). 4181 bytes result sent to driver
[2025-05-02T02:22:53.297+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 8.0 in stage 74.0 (TID 737) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 7.0 in stage 74.0 (TID 736) in 17 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:53.300+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 8.0 in stage 74.0 (TID 737)
[2025-05-02T02:22:53.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_8 locally
[2025-05-02T02:22:53.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 8.0 in stage 74.0 (TID 737). 4181 bytes result sent to driver
[2025-05-02T02:22:53.310+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 9.0 in stage 74.0 (TID 738) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 9.0 in stage 74.0 (TID 738)
[2025-05-02T02:22:53.312+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 8.0 in stage 74.0 (TID 737) in 13 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:53.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_9 locally
[2025-05-02T02:22:53.329+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 9.0 in stage 74.0 (TID 738). 4267 bytes result sent to driver
[2025-05-02T02:22:53.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 10.0 in stage 74.0 (TID 739) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 10.0 in stage 74.0 (TID 739)
[2025-05-02T02:22:53.332+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 9.0 in stage 74.0 (TID 738) in 21 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:53.340+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_10 locally
[2025-05-02T02:22:53.341+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 10.0 in stage 74.0 (TID 739). 4181 bytes result sent to driver
[2025-05-02T02:22:53.342+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 11.0 in stage 74.0 (TID 740) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.343+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 11.0 in stage 74.0 (TID 740)
[2025-05-02T02:22:53.344+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 10.0 in stage 74.0 (TID 739) in 13 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:53.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_11 locally
[2025-05-02T02:22:53.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 11.0 in stage 74.0 (TID 740). 4181 bytes result sent to driver
[2025-05-02T02:22:53.355+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 12.0 in stage 74.0 (TID 741) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.356+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 11.0 in stage 74.0 (TID 740) in 14 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:53.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 12.0 in stage 74.0 (TID 741)
[2025-05-02T02:22:53.367+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_12 locally
[2025-05-02T02:22:53.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 12.0 in stage 74.0 (TID 741). 4181 bytes result sent to driver
[2025-05-02T02:22:53.369+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 13.0 in stage 74.0 (TID 742) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 13.0 in stage 74.0 (TID 742)
[2025-05-02T02:22:53.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 12.0 in stage 74.0 (TID 741) in 15 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:53.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_13 locally
[2025-05-02T02:22:53.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 13.0 in stage 74.0 (TID 742). 4181 bytes result sent to driver
[2025-05-02T02:22:53.385+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 14.0 in stage 74.0 (TID 743) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.386+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 13.0 in stage 74.0 (TID 742) in 16 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:53.387+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 14.0 in stage 74.0 (TID 743)
[2025-05-02T02:22:53.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_14 locally
[2025-05-02T02:22:53.397+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 14.0 in stage 74.0 (TID 743). 4181 bytes result sent to driver
[2025-05-02T02:22:53.398+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 15.0 in stage 74.0 (TID 744) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 15.0 in stage 74.0 (TID 744)
[2025-05-02T02:22:53.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 14.0 in stage 74.0 (TID 743) in 13 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:53.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_15 locally
[2025-05-02T02:22:53.410+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 15.0 in stage 74.0 (TID 744). 4181 bytes result sent to driver
[2025-05-02T02:22:53.411+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 16.0 in stage 74.0 (TID 745) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.412+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 16.0 in stage 74.0 (TID 745)
[2025-05-02T02:22:53.413+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 15.0 in stage 74.0 (TID 744) in 13 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:53.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_16 locally
[2025-05-02T02:22:53.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 16.0 in stage 74.0 (TID 745). 4224 bytes result sent to driver
[2025-05-02T02:22:53.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 17.0 in stage 74.0 (TID 746) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 16.0 in stage 74.0 (TID 745) in 19 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:53.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 17.0 in stage 74.0 (TID 746)
[2025-05-02T02:22:53.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_17 locally
[2025-05-02T02:22:53.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 17.0 in stage 74.0 (TID 746). 4181 bytes result sent to driver
[2025-05-02T02:22:53.443+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 18.0 in stage 74.0 (TID 747) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.444+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 17.0 in stage 74.0 (TID 746) in 14 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:53.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 18.0 in stage 74.0 (TID 747)
[2025-05-02T02:22:53.453+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_18 locally
[2025-05-02T02:22:53.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 18.0 in stage 74.0 (TID 747). 4181 bytes result sent to driver
[2025-05-02T02:22:53.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 19.0 in stage 74.0 (TID 748) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 18.0 in stage 74.0 (TID 747) in 13 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:53.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 19.0 in stage 74.0 (TID 748)
[2025-05-02T02:22:53.466+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_19 locally
[2025-05-02T02:22:53.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 19.0 in stage 74.0 (TID 748). 4181 bytes result sent to driver
[2025-05-02T02:22:53.468+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 20.0 in stage 74.0 (TID 749) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 20.0 in stage 74.0 (TID 749)
[2025-05-02T02:22:53.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 19.0 in stage 74.0 (TID 748) in 13 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:53.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_20 locally
[2025-05-02T02:22:53.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 20.0 in stage 74.0 (TID 749). 4181 bytes result sent to driver
[2025-05-02T02:22:53.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 21.0 in stage 74.0 (TID 750) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.481+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 21.0 in stage 74.0 (TID 750)
[2025-05-02T02:22:53.482+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 20.0 in stage 74.0 (TID 749) in 13 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:53.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_21 locally
[2025-05-02T02:22:53.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 21.0 in stage 74.0 (TID 750). 4181 bytes result sent to driver
[2025-05-02T02:22:53.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 22.0 in stage 74.0 (TID 751) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 22.0 in stage 74.0 (TID 751)
[2025-05-02T02:22:53.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 21.0 in stage 74.0 (TID 750) in 13 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:53.503+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_22 locally
[2025-05-02T02:22:53.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 22.0 in stage 74.0 (TID 751). 4224 bytes result sent to driver
[2025-05-02T02:22:53.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 23.0 in stage 74.0 (TID 752) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 23.0 in stage 74.0 (TID 752)
[2025-05-02T02:22:53.514+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 22.0 in stage 74.0 (TID 751) in 20 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:53.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_23 locally
[2025-05-02T02:22:53.523+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 23.0 in stage 74.0 (TID 752). 4181 bytes result sent to driver
[2025-05-02T02:22:53.524+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 24.0 in stage 74.0 (TID 753) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 24.0 in stage 74.0 (TID 753)
[2025-05-02T02:22:53.526+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 23.0 in stage 74.0 (TID 752) in 13 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:53.534+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_24 locally
[2025-05-02T02:22:53.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 24.0 in stage 74.0 (TID 753). 4181 bytes result sent to driver
[2025-05-02T02:22:53.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 25.0 in stage 74.0 (TID 754) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 25.0 in stage 74.0 (TID 754)
[2025-05-02T02:22:53.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 24.0 in stage 74.0 (TID 753) in 13 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:53.547+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_25 locally
[2025-05-02T02:22:53.548+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 25.0 in stage 74.0 (TID 754). 4181 bytes result sent to driver
[2025-05-02T02:22:53.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 26.0 in stage 74.0 (TID 755) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.550+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 26.0 in stage 74.0 (TID 755)
[2025-05-02T02:22:53.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 25.0 in stage 74.0 (TID 754) in 13 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:53.559+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_26 locally
[2025-05-02T02:22:53.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 26.0 in stage 74.0 (TID 755). 4181 bytes result sent to driver
[2025-05-02T02:22:53.561+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 27.0 in stage 74.0 (TID 756) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.562+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 26.0 in stage 74.0 (TID 755) in 12 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:53.563+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 27.0 in stage 74.0 (TID 756)
[2025-05-02T02:22:53.571+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_27 locally
[2025-05-02T02:22:53.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 27.0 in stage 74.0 (TID 756). 4181 bytes result sent to driver
[2025-05-02T02:22:53.574+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 28.0 in stage 74.0 (TID 757) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 27.0 in stage 74.0 (TID 756) in 13 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:53.576+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 28.0 in stage 74.0 (TID 757)
[2025-05-02T02:22:53.584+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_28 locally
[2025-05-02T02:22:53.591+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 28.0 in stage 74.0 (TID 757). 4224 bytes result sent to driver
[2025-05-02T02:22:53.592+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 29.0 in stage 74.0 (TID 758) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.593+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 29.0 in stage 74.0 (TID 758)
[2025-05-02T02:22:53.594+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 28.0 in stage 74.0 (TID 757) in 19 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:53.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_29 locally
[2025-05-02T02:22:53.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 29.0 in stage 74.0 (TID 758). 4181 bytes result sent to driver
[2025-05-02T02:22:53.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 30.0 in stage 74.0 (TID 759) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 29.0 in stage 74.0 (TID 758) in 17 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:53.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 30.0 in stage 74.0 (TID 759)
[2025-05-02T02:22:53.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_30 locally
[2025-05-02T02:22:53.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 30.0 in stage 74.0 (TID 759). 4181 bytes result sent to driver
[2025-05-02T02:22:53.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 31.0 in stage 74.0 (TID 760) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 30.0 in stage 74.0 (TID 759) in 13 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:53.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 31.0 in stage 74.0 (TID 760)
[2025-05-02T02:22:53.634+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_31 locally
[2025-05-02T02:22:53.636+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 31.0 in stage 74.0 (TID 760). 4181 bytes result sent to driver
[2025-05-02T02:22:53.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 32.0 in stage 74.0 (TID 761) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 32.0 in stage 74.0 (TID 761)
[2025-05-02T02:22:53.639+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 31.0 in stage 74.0 (TID 760) in 16 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:53.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_32 locally
[2025-05-02T02:22:53.649+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 32.0 in stage 74.0 (TID 761). 4181 bytes result sent to driver
[2025-05-02T02:22:53.650+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 33.0 in stage 74.0 (TID 762) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.651+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 33.0 in stage 74.0 (TID 762)
[2025-05-02T02:22:53.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 32.0 in stage 74.0 (TID 761) in 13 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:53.663+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_33 locally
[2025-05-02T02:22:53.665+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 33.0 in stage 74.0 (TID 762). 4181 bytes result sent to driver
[2025-05-02T02:22:53.666+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 34.0 in stage 74.0 (TID 763) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.667+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 33.0 in stage 74.0 (TID 762) in 17 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:53.668+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 34.0 in stage 74.0 (TID 763)
[2025-05-02T02:22:53.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_34 locally
[2025-05-02T02:22:53.684+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 34.0 in stage 74.0 (TID 763). 4267 bytes result sent to driver
[2025-05-02T02:22:53.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 35.0 in stage 74.0 (TID 764) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 34.0 in stage 74.0 (TID 763) in 19 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:53.687+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 35.0 in stage 74.0 (TID 764)
[2025-05-02T02:22:53.695+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_35 locally
[2025-05-02T02:22:53.696+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 35.0 in stage 74.0 (TID 764). 4181 bytes result sent to driver
[2025-05-02T02:22:53.697+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 36.0 in stage 74.0 (TID 765) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.698+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 36.0 in stage 74.0 (TID 765)
[2025-05-02T02:22:53.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 35.0 in stage 74.0 (TID 764) in 13 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:53.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_36 locally
[2025-05-02T02:22:53.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 36.0 in stage 74.0 (TID 765). 4181 bytes result sent to driver
[2025-05-02T02:22:53.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 37.0 in stage 74.0 (TID 766) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 36.0 in stage 74.0 (TID 765) in 14 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:53.711+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 37.0 in stage 74.0 (TID 766)
[2025-05-02T02:22:53.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_37 locally
[2025-05-02T02:22:53.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 37.0 in stage 74.0 (TID 766). 4181 bytes result sent to driver
[2025-05-02T02:22:53.722+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 38.0 in stage 74.0 (TID 767) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 38.0 in stage 74.0 (TID 767)
[2025-05-02T02:22:53.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 37.0 in stage 74.0 (TID 766) in 13 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:53.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_38 locally
[2025-05-02T02:22:53.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 38.0 in stage 74.0 (TID 767). 4181 bytes result sent to driver
[2025-05-02T02:22:53.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 39.0 in stage 74.0 (TID 768) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 39.0 in stage 74.0 (TID 768)
[2025-05-02T02:22:53.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 38.0 in stage 74.0 (TID 767) in 13 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:53.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_39 locally
[2025-05-02T02:22:53.746+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 39.0 in stage 74.0 (TID 768). 4181 bytes result sent to driver
[2025-05-02T02:22:53.747+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 40.0 in stage 74.0 (TID 769) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.748+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 39.0 in stage 74.0 (TID 768) in 13 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:53.749+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 40.0 in stage 74.0 (TID 769)
[2025-05-02T02:22:53.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_40 locally
[2025-05-02T02:22:53.760+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 40.0 in stage 74.0 (TID 769). 4181 bytes result sent to driver
[2025-05-02T02:22:53.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 41.0 in stage 74.0 (TID 770) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 40.0 in stage 74.0 (TID 769) in 14 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:53.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 41.0 in stage 74.0 (TID 770)
[2025-05-02T02:22:53.778+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_41 locally
[2025-05-02T02:22:53.780+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 41.0 in stage 74.0 (TID 770). 4224 bytes result sent to driver
[2025-05-02T02:22:53.781+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 42.0 in stage 74.0 (TID 771) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.782+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 41.0 in stage 74.0 (TID 770) in 21 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:53.783+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 42.0 in stage 74.0 (TID 771)
[2025-05-02T02:22:53.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_42 locally
[2025-05-02T02:22:53.794+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 42.0 in stage 74.0 (TID 771). 4224 bytes result sent to driver
[2025-05-02T02:22:53.795+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 43.0 in stage 74.0 (TID 772) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 42.0 in stage 74.0 (TID 771) in 14 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:53.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 43.0 in stage 74.0 (TID 772)
[2025-05-02T02:22:53.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_43 locally
[2025-05-02T02:22:53.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 43.0 in stage 74.0 (TID 772). 4181 bytes result sent to driver
[2025-05-02T02:22:53.807+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 44.0 in stage 74.0 (TID 773) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.808+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 43.0 in stage 74.0 (TID 772) in 13 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:53.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 44.0 in stage 74.0 (TID 773)
[2025-05-02T02:22:53.817+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_44 locally
[2025-05-02T02:22:53.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 44.0 in stage 74.0 (TID 773). 4181 bytes result sent to driver
[2025-05-02T02:22:53.819+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 45.0 in stage 74.0 (TID 774) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.820+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 45.0 in stage 74.0 (TID 774)
[2025-05-02T02:22:53.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 44.0 in stage 74.0 (TID 773) in 13 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:53.829+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_45 locally
[2025-05-02T02:22:53.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 45.0 in stage 74.0 (TID 774). 4181 bytes result sent to driver
[2025-05-02T02:22:53.831+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 46.0 in stage 74.0 (TID 775) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.833+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 45.0 in stage 74.0 (TID 774) in 12 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:53.834+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 46.0 in stage 74.0 (TID 775)
[2025-05-02T02:22:53.841+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_46 locally
[2025-05-02T02:22:53.842+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 46.0 in stage 74.0 (TID 775). 4181 bytes result sent to driver
[2025-05-02T02:22:53.843+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 47.0 in stage 74.0 (TID 776) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.844+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 47.0 in stage 74.0 (TID 776)
[2025-05-02T02:22:53.845+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 46.0 in stage 74.0 (TID 775) in 12 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:53.853+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_47 locally
[2025-05-02T02:22:53.861+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 47.0 in stage 74.0 (TID 776). 4224 bytes result sent to driver
[2025-05-02T02:22:53.862+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 48.0 in stage 74.0 (TID 777) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.864+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 48.0 in stage 74.0 (TID 777)
[2025-05-02T02:22:53.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 47.0 in stage 74.0 (TID 776) in 19 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:53.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_48 locally
[2025-05-02T02:22:53.873+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 48.0 in stage 74.0 (TID 777). 4181 bytes result sent to driver
[2025-05-02T02:22:53.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 49.0 in stage 74.0 (TID 778) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.875+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 49.0 in stage 74.0 (TID 778)
[2025-05-02T02:22:53.876+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 48.0 in stage 74.0 (TID 777) in 12 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:53.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManager: Found block rdd_90_49 locally
[2025-05-02T02:22:53.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Finished task 49.0 in stage 74.0 (TID 778). 4181 bytes result sent to driver
[2025-05-02T02:22:53.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Finished task 49.0 in stage 74.0 (TID 778) in 12 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:53.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-05-02T02:22:53.887+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: ResultStage 74 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.726 s
[2025-05-02T02:22:53.888+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:53.889+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-05-02T02:22:53.890+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Job 40 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.729990 s
[2025-05-02T02:22:53.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:53.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:22:53.971+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:53.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Got job 41 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:22:53.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Final stage: ResultStage 76 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:53.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-05-02T02:22:53.977+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:53.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[179] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:53.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 744.4 KiB, free 394.4 MiB)
[2025-05-02T02:22:53.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 170.6 KiB, free 394.2 MiB)
[2025-05-02T02:22:53.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on ***-scheduler:33063 (size: 170.6 KiB, free: 432.6 MiB)
[2025-05-02T02:22:53.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:53.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 76 (MapPartitionsRDD[179] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:22:53.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSchedulerImpl: Adding task set 76.0 with 50 tasks resource profile 0
[2025-05-02T02:22:53.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 779) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:53.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:53 INFO Executor: Running task 0.0 in stage 76.0 (TID 779)
[2025-05-02T02:22:54.001+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_0 locally
[2025-05-02T02:22:54.009+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 0.0 in stage 76.0 (TID 779). 4752 bytes result sent to driver
[2025-05-02T02:22:54.010+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 780) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.011+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManagerInfo: Removed broadcast_63_piece0 on ***-scheduler:33063 in memory (size: 155.3 KiB, free: 432.8 MiB)
[2025-05-02T02:22:54.012+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 1.0 in stage 76.0 (TID 780)
[2025-05-02T02:22:54.013+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 779) in 22 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:22:54.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_1 locally
[2025-05-02T02:22:54.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 1.0 in stage 76.0 (TID 780). 4666 bytes result sent to driver
[2025-05-02T02:22:54.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 781) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 2.0 in stage 76.0 (TID 781)
[2025-05-02T02:22:54.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 780) in 14 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:22:54.034+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_2 locally
[2025-05-02T02:22:54.035+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 2.0 in stage 76.0 (TID 781). 4666 bytes result sent to driver
[2025-05-02T02:22:54.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 782) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 3.0 in stage 76.0 (TID 782)
[2025-05-02T02:22:54.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 781) in 14 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:22:54.047+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_3 locally
[2025-05-02T02:22:54.048+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 3.0 in stage 76.0 (TID 782). 4666 bytes result sent to driver
[2025-05-02T02:22:54.048+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 4.0 in stage 76.0 (TID 783) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.049+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 4.0 in stage 76.0 (TID 783)
[2025-05-02T02:22:54.050+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 782) in 13 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:22:54.060+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_4 locally
[2025-05-02T02:22:54.067+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 4.0 in stage 76.0 (TID 783). 4834 bytes result sent to driver
[2025-05-02T02:22:54.068+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 5.0 in stage 76.0 (TID 784) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.069+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 5.0 in stage 76.0 (TID 784)
[2025-05-02T02:22:54.070+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 4.0 in stage 76.0 (TID 783) in 20 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:22:54.079+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_5 locally
[2025-05-02T02:22:54.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 5.0 in stage 76.0 (TID 784). 4666 bytes result sent to driver
[2025-05-02T02:22:54.081+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 6.0 in stage 76.0 (TID 785) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.082+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 6.0 in stage 76.0 (TID 785)
[2025-05-02T02:22:54.083+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 5.0 in stage 76.0 (TID 784) in 14 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:22:54.092+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_6 locally
[2025-05-02T02:22:54.093+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 6.0 in stage 76.0 (TID 785). 4666 bytes result sent to driver
[2025-05-02T02:22:54.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 7.0 in stage 76.0 (TID 786) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.095+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 7.0 in stage 76.0 (TID 786)
[2025-05-02T02:22:54.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 6.0 in stage 76.0 (TID 785) in 13 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:22:54.105+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_7 locally
[2025-05-02T02:22:54.113+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 7.0 in stage 76.0 (TID 786). 4709 bytes result sent to driver
[2025-05-02T02:22:54.114+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 8.0 in stage 76.0 (TID 787) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.115+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 7.0 in stage 76.0 (TID 786) in 21 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:22:54.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 8.0 in stage 76.0 (TID 787)
[2025-05-02T02:22:54.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_8 locally
[2025-05-02T02:22:54.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 8.0 in stage 76.0 (TID 787). 4666 bytes result sent to driver
[2025-05-02T02:22:54.126+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 9.0 in stage 76.0 (TID 788) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 9.0 in stage 76.0 (TID 788)
[2025-05-02T02:22:54.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 8.0 in stage 76.0 (TID 787) in 13 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:22:54.136+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_9 locally
[2025-05-02T02:22:54.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 9.0 in stage 76.0 (TID 788). 4666 bytes result sent to driver
[2025-05-02T02:22:54.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 10.0 in stage 76.0 (TID 789) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 10.0 in stage 76.0 (TID 789)
[2025-05-02T02:22:54.140+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 9.0 in stage 76.0 (TID 788) in 13 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:22:54.149+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_10 locally
[2025-05-02T02:22:54.150+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 10.0 in stage 76.0 (TID 789). 4666 bytes result sent to driver
[2025-05-02T02:22:54.151+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 11.0 in stage 76.0 (TID 790) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.152+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 11.0 in stage 76.0 (TID 790)
[2025-05-02T02:22:54.153+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 10.0 in stage 76.0 (TID 789) in 13 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:22:54.164+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_11 locally
[2025-05-02T02:22:54.165+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 11.0 in stage 76.0 (TID 790). 4666 bytes result sent to driver
[2025-05-02T02:22:54.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 12.0 in stage 76.0 (TID 791) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 12.0 in stage 76.0 (TID 791)
[2025-05-02T02:22:54.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 11.0 in stage 76.0 (TID 790) in 15 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:22:54.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_12 locally
[2025-05-02T02:22:54.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 12.0 in stage 76.0 (TID 791). 4666 bytes result sent to driver
[2025-05-02T02:22:54.181+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 13.0 in stage 76.0 (TID 792) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.182+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 13.0 in stage 76.0 (TID 792)
[2025-05-02T02:22:54.183+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 12.0 in stage 76.0 (TID 791) in 15 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:22:54.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_13 locally
[2025-05-02T02:22:54.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 13.0 in stage 76.0 (TID 792). 4666 bytes result sent to driver
[2025-05-02T02:22:54.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 14.0 in stage 76.0 (TID 793) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 14.0 in stage 76.0 (TID 793)
[2025-05-02T02:22:54.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 13.0 in stage 76.0 (TID 792) in 17 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:22:54.215+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_14 locally
[2025-05-02T02:22:54.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 14.0 in stage 76.0 (TID 793). 4709 bytes result sent to driver
[2025-05-02T02:22:54.218+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 15.0 in stage 76.0 (TID 794) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.219+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 15.0 in stage 76.0 (TID 794)
[2025-05-02T02:22:54.220+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 14.0 in stage 76.0 (TID 793) in 21 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:22:54.228+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_15 locally
[2025-05-02T02:22:54.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 15.0 in stage 76.0 (TID 794). 4666 bytes result sent to driver
[2025-05-02T02:22:54.230+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 16.0 in stage 76.0 (TID 795) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.231+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 16.0 in stage 76.0 (TID 795)
[2025-05-02T02:22:54.232+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 15.0 in stage 76.0 (TID 794) in 13 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:22:54.242+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_16 locally
[2025-05-02T02:22:54.243+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 16.0 in stage 76.0 (TID 795). 4666 bytes result sent to driver
[2025-05-02T02:22:54.244+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 17.0 in stage 76.0 (TID 796) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.245+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 16.0 in stage 76.0 (TID 795) in 14 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:22:54.246+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 17.0 in stage 76.0 (TID 796)
[2025-05-02T02:22:54.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_17 locally
[2025-05-02T02:22:54.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 17.0 in stage 76.0 (TID 796). 4666 bytes result sent to driver
[2025-05-02T02:22:54.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 18.0 in stage 76.0 (TID 797) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.260+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 17.0 in stage 76.0 (TID 796) in 16 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:22:54.261+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 18.0 in stage 76.0 (TID 797)
[2025-05-02T02:22:54.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_18 locally
[2025-05-02T02:22:54.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 18.0 in stage 76.0 (TID 797). 4666 bytes result sent to driver
[2025-05-02T02:22:54.272+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 19.0 in stage 76.0 (TID 798) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 19.0 in stage 76.0 (TID 798)
[2025-05-02T02:22:54.274+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 18.0 in stage 76.0 (TID 797) in 14 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:22:54.285+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_19 locally
[2025-05-02T02:22:54.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 19.0 in stage 76.0 (TID 798). 4666 bytes result sent to driver
[2025-05-02T02:22:54.287+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 20.0 in stage 76.0 (TID 799) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.288+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 19.0 in stage 76.0 (TID 798) in 15 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:22:54.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 20.0 in stage 76.0 (TID 799)
[2025-05-02T02:22:54.299+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_20 locally
[2025-05-02T02:22:54.307+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 20.0 in stage 76.0 (TID 799). 4752 bytes result sent to driver
[2025-05-02T02:22:54.308+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 21.0 in stage 76.0 (TID 800) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.309+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 21.0 in stage 76.0 (TID 800)
[2025-05-02T02:22:54.310+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 20.0 in stage 76.0 (TID 799) in 21 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:22:54.319+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_21 locally
[2025-05-02T02:22:54.320+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 21.0 in stage 76.0 (TID 800). 4666 bytes result sent to driver
[2025-05-02T02:22:54.321+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 22.0 in stage 76.0 (TID 801) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.322+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 22.0 in stage 76.0 (TID 801)
[2025-05-02T02:22:54.323+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 21.0 in stage 76.0 (TID 800) in 14 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:22:54.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_22 locally
[2025-05-02T02:22:54.335+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 22.0 in stage 76.0 (TID 801). 4666 bytes result sent to driver
[2025-05-02T02:22:54.336+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 23.0 in stage 76.0 (TID 802) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.337+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 22.0 in stage 76.0 (TID 801) in 16 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:22:54.338+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 23.0 in stage 76.0 (TID 802)
[2025-05-02T02:22:54.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_23 locally
[2025-05-02T02:22:54.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 23.0 in stage 76.0 (TID 802). 4666 bytes result sent to driver
[2025-05-02T02:22:54.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 24.0 in stage 76.0 (TID 803) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 24.0 in stage 76.0 (TID 803)
[2025-05-02T02:22:54.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 23.0 in stage 76.0 (TID 802) in 16 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:22:54.364+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_24 locally
[2025-05-02T02:22:54.365+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 24.0 in stage 76.0 (TID 803). 4666 bytes result sent to driver
[2025-05-02T02:22:54.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 25.0 in stage 76.0 (TID 804) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 25.0 in stage 76.0 (TID 804)
[2025-05-02T02:22:54.367+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 24.0 in stage 76.0 (TID 803) in 14 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:22:54.381+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_25 locally
[2025-05-02T02:22:54.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 25.0 in stage 76.0 (TID 804). 4666 bytes result sent to driver
[2025-05-02T02:22:54.384+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 26.0 in stage 76.0 (TID 805) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.401+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 25.0 in stage 76.0 (TID 804) in 19 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:22:54.404+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 26.0 in stage 76.0 (TID 805)
[2025-05-02T02:22:54.405+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_26 locally
[2025-05-02T02:22:54.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 26.0 in stage 76.0 (TID 805). 4666 bytes result sent to driver
[2025-05-02T02:22:54.406+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 27.0 in stage 76.0 (TID 806) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.407+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 26.0 in stage 76.0 (TID 805) in 17 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:22:54.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 27.0 in stage 76.0 (TID 806)
[2025-05-02T02:22:54.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_27 locally
[2025-05-02T02:22:54.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 27.0 in stage 76.0 (TID 806). 4709 bytes result sent to driver
[2025-05-02T02:22:54.425+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 28.0 in stage 76.0 (TID 807) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 28.0 in stage 76.0 (TID 807)
[2025-05-02T02:22:54.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 27.0 in stage 76.0 (TID 806) in 26 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:22:54.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_28 locally
[2025-05-02T02:22:54.441+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 28.0 in stage 76.0 (TID 807). 4666 bytes result sent to driver
[2025-05-02T02:22:54.442+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 29.0 in stage 76.0 (TID 808) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.443+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 29.0 in stage 76.0 (TID 808)
[2025-05-02T02:22:54.444+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 28.0 in stage 76.0 (TID 807) in 18 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:22:54.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_29 locally
[2025-05-02T02:22:54.460+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 29.0 in stage 76.0 (TID 808). 4666 bytes result sent to driver
[2025-05-02T02:22:54.461+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 30.0 in stage 76.0 (TID 809) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.462+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 29.0 in stage 76.0 (TID 808) in 19 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:22:54.463+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 30.0 in stage 76.0 (TID 809)
[2025-05-02T02:22:54.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_30 locally
[2025-05-02T02:22:54.477+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 30.0 in stage 76.0 (TID 809). 4666 bytes result sent to driver
[2025-05-02T02:22:54.478+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 31.0 in stage 76.0 (TID 810) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.479+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 30.0 in stage 76.0 (TID 809) in 18 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:22:54.480+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 31.0 in stage 76.0 (TID 810)
[2025-05-02T02:22:54.492+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_31 locally
[2025-05-02T02:22:54.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 31.0 in stage 76.0 (TID 810). 4666 bytes result sent to driver
[2025-05-02T02:22:54.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 32.0 in stage 76.0 (TID 811) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 32.0 in stage 76.0 (TID 811)
[2025-05-02T02:22:54.496+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 31.0 in stage 76.0 (TID 810) in 18 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:22:54.509+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_32 locally
[2025-05-02T02:22:54.510+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 32.0 in stage 76.0 (TID 811). 4666 bytes result sent to driver
[2025-05-02T02:22:54.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 33.0 in stage 76.0 (TID 812) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.512+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 33.0 in stage 76.0 (TID 812)
[2025-05-02T02:22:54.513+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 32.0 in stage 76.0 (TID 811) in 17 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:22:54.524+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_33 locally
[2025-05-02T02:22:54.535+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 33.0 in stage 76.0 (TID 812). 4752 bytes result sent to driver
[2025-05-02T02:22:54.536+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 34.0 in stage 76.0 (TID 813) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 33.0 in stage 76.0 (TID 812) in 26 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:22:54.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 34.0 in stage 76.0 (TID 813)
[2025-05-02T02:22:54.549+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_34 locally
[2025-05-02T02:22:54.551+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 34.0 in stage 76.0 (TID 813). 4666 bytes result sent to driver
[2025-05-02T02:22:54.552+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 35.0 in stage 76.0 (TID 814) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 35.0 in stage 76.0 (TID 814)
[2025-05-02T02:22:54.553+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 34.0 in stage 76.0 (TID 813) in 17 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:22:54.564+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_35 locally
[2025-05-02T02:22:54.566+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 35.0 in stage 76.0 (TID 814). 4666 bytes result sent to driver
[2025-05-02T02:22:54.567+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 36.0 in stage 76.0 (TID 815) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 35.0 in stage 76.0 (TID 814) in 16 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:22:54.568+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 36.0 in stage 76.0 (TID 815)
[2025-05-02T02:22:54.585+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_36 locally
[2025-05-02T02:22:54.587+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 36.0 in stage 76.0 (TID 815). 4666 bytes result sent to driver
[2025-05-02T02:22:54.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 37.0 in stage 76.0 (TID 816) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 37.0 in stage 76.0 (TID 816)
[2025-05-02T02:22:54.589+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 36.0 in stage 76.0 (TID 815) in 22 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:22:54.602+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_37 locally
[2025-05-02T02:22:54.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 37.0 in stage 76.0 (TID 816). 4666 bytes result sent to driver
[2025-05-02T02:22:54.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 38.0 in stage 76.0 (TID 817) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 38.0 in stage 76.0 (TID 817)
[2025-05-02T02:22:54.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 37.0 in stage 76.0 (TID 816) in 20 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:22:54.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_38 locally
[2025-05-02T02:22:54.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 38.0 in stage 76.0 (TID 817). 4666 bytes result sent to driver
[2025-05-02T02:22:54.623+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 39.0 in stage 76.0 (TID 818) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 39.0 in stage 76.0 (TID 818)
[2025-05-02T02:22:54.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 38.0 in stage 76.0 (TID 817) in 17 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:22:54.637+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_39 locally
[2025-05-02T02:22:54.645+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 39.0 in stage 76.0 (TID 818). 4752 bytes result sent to driver
[2025-05-02T02:22:54.646+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 40.0 in stage 76.0 (TID 819) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.647+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 40.0 in stage 76.0 (TID 819)
[2025-05-02T02:22:54.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 39.0 in stage 76.0 (TID 818) in 23 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:22:54.658+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_40 locally
[2025-05-02T02:22:54.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 40.0 in stage 76.0 (TID 819). 4666 bytes result sent to driver
[2025-05-02T02:22:54.660+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 41.0 in stage 76.0 (TID 820) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.661+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 41.0 in stage 76.0 (TID 820)
[2025-05-02T02:22:54.663+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 40.0 in stage 76.0 (TID 819) in 15 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:22:54.673+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_41 locally
[2025-05-02T02:22:54.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 41.0 in stage 76.0 (TID 820). 4666 bytes result sent to driver
[2025-05-02T02:22:54.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 42.0 in stage 76.0 (TID 821) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.676+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 42.0 in stage 76.0 (TID 821)
[2025-05-02T02:22:54.677+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 41.0 in stage 76.0 (TID 820) in 15 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:22:54.687+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_42 locally
[2025-05-02T02:22:54.689+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 42.0 in stage 76.0 (TID 821). 4666 bytes result sent to driver
[2025-05-02T02:22:54.690+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 43.0 in stage 76.0 (TID 822) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.691+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 43.0 in stage 76.0 (TID 822)
[2025-05-02T02:22:54.692+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 42.0 in stage 76.0 (TID 821) in 15 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:22:54.703+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_43 locally
[2025-05-02T02:22:54.704+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 43.0 in stage 76.0 (TID 822). 4666 bytes result sent to driver
[2025-05-02T02:22:54.705+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 44.0 in stage 76.0 (TID 823) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 44.0 in stage 76.0 (TID 823)
[2025-05-02T02:22:54.707+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 43.0 in stage 76.0 (TID 822) in 17 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:22:54.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_44 locally
[2025-05-02T02:22:54.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 44.0 in stage 76.0 (TID 823). 4666 bytes result sent to driver
[2025-05-02T02:22:54.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 45.0 in stage 76.0 (TID 824) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 45.0 in stage 76.0 (TID 824)
[2025-05-02T02:22:54.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 44.0 in stage 76.0 (TID 823) in 16 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:22:54.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_45 locally
[2025-05-02T02:22:54.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 45.0 in stage 76.0 (TID 824). 4666 bytes result sent to driver
[2025-05-02T02:22:54.736+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 46.0 in stage 76.0 (TID 825) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 46.0 in stage 76.0 (TID 825)
[2025-05-02T02:22:54.738+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 45.0 in stage 76.0 (TID 824) in 15 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:22:54.756+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_46 locally
[2025-05-02T02:22:54.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 46.0 in stage 76.0 (TID 825). 4709 bytes result sent to driver
[2025-05-02T02:22:54.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 47.0 in stage 76.0 (TID 826) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.763+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 47.0 in stage 76.0 (TID 826)
[2025-05-02T02:22:54.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 46.0 in stage 76.0 (TID 825) in 24 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:22:54.772+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_47 locally
[2025-05-02T02:22:54.773+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 47.0 in stage 76.0 (TID 826). 4666 bytes result sent to driver
[2025-05-02T02:22:54.774+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 48.0 in stage 76.0 (TID 827) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.775+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 48.0 in stage 76.0 (TID 827)
[2025-05-02T02:22:54.776+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 47.0 in stage 76.0 (TID 826) in 16 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:22:54.786+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_48 locally
[2025-05-02T02:22:54.789+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 48.0 in stage 76.0 (TID 827). 4666 bytes result sent to driver
[2025-05-02T02:22:54.790+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 49.0 in stage 76.0 (TID 828) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:22:54.791+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 48.0 in stage 76.0 (TID 827) in 17 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:22:54.792+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 49.0 in stage 76.0 (TID 828)
[2025-05-02T02:22:54.802+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManager: Found block rdd_77_49 locally
[2025-05-02T02:22:54.804+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Finished task 49.0 in stage 76.0 (TID 828). 4666 bytes result sent to driver
[2025-05-02T02:22:54.805+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Finished task 49.0 in stage 76.0 (TID 828) in 15 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:22:54.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-05-02T02:22:54.806+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: ResultStage 76 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.830 s
[2025-05-02T02:22:54.808+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:54.809+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-05-02T02:22:54.810+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Job 41 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.836836 s
[2025-05-02T02:22:54.819+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:22:54.842+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:54.843+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:54.845+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:54.846+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:54.847+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ENCOUNTER)
[2025-05-02T02:22:54.848+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ENCOUNTER#2075)
[2025-05-02T02:22:54.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Allergy_Group_Key),IsNotNull(Allergy_Key)
[2025-05-02T02:22:54.850+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Allergy_Group_Key#2091),isnotnull(Allergy_Key#2092)
[2025-05-02T02:22:54.877+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:22:54.904+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 206.6 KiB, free 394.9 MiB)
[2025-05-02T02:22:54.911+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO CodeGenerator: Code generated in 10.852599 ms
[2025-05-02T02:22:54.915+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 206.8 KiB, free 394.7 MiB)
[2025-05-02T02:22:54.922+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 394.6 MiB)
[2025-05-02T02:22:54.924+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 432.7 MiB)
[2025-05-02T02:22:54.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO SparkContext: Created broadcast 65 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:54.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4206010 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:54.931+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 394.6 MiB)
[2025-05-02T02:22:54.932+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 432.7 MiB)
[2025-05-02T02:22:54.933+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO SparkContext: Created broadcast 66 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:54.948+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO CodeGenerator: Code generated in 43.132973 ms
[2025-05-02T02:22:54.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:54.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Got job 42 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-02T02:22:54.952+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Final stage: ResultStage 77 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:54.953+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:54.954+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:54.955+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[183] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:54.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 207.0 KiB, free 394.4 MiB)
[2025-05-02T02:22:54.956+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 18.6 KiB, free 394.4 MiB)
[2025-05-02T02:22:54.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 394.4 MiB)
[2025-05-02T02:22:54.976+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on ***-scheduler:33063 (size: 8.0 KiB, free: 432.7 MiB)
[2025-05-02T02:22:54.977+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManagerInfo: Removed broadcast_64_piece0 on ***-scheduler:33063 in memory (size: 170.6 KiB, free: 432.8 MiB)
[2025-05-02T02:22:54.979+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:54.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[183] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:54.981+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
[2025-05-02T02:22:54.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 829) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10919 bytes)
[2025-05-02T02:22:54.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO Executor: Running task 0.0 in stage 77.0 (TID 829)
[2025-05-02T02:22:54.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet, range: 0-11706, partition values: [empty row]
[2025-05-02T02:22:54.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 395.2 MiB)
[2025-05-02T02:22:54.988+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on ***-scheduler:33063 (size: 36.5 KiB, free: 432.8 MiB)
[2025-05-02T02:22:54.989+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO SparkContext: Created broadcast 67 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:54.991+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4206010 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:55.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Registering RDD 187 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 16
[2025-05-02T02:22:55.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Got map stage job 43 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:55.003+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Final stage: ShuffleMapStage 78 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:55.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:55.022+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:55.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[187] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:55.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 50.9 KiB, free 395.2 MiB)
[2025-05-02T02:22:55.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 395.1 MiB)
[2025-05-02T02:22:55.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on ***-scheduler:33063 (size: 21.4 KiB, free: 432.8 MiB)
[2025-05-02T02:22:55.027+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:55.028+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[187] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:55.029+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
[2025-05-02T02:22:55.030+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197879 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:55.031+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:55.032+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Got job 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-02T02:22:55.034+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Final stage: ResultStage 79 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-02T02:22:55.035+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:55.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:55.037+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-02T02:22:55.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 17.6 KiB, free 395.1 MiB)
[2025-05-02T02:22:55.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 395.1 MiB)
[2025-05-02T02:22:55.039+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on ***-scheduler:33063 (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-02T02:22:55.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:55.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:55.042+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
[2025-05-02T02:22:55.408+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:55.490+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FilterCompat: Filtering using predicate: noteq(ENCOUNTER, null)
[2025-05-02T02:22:55.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:55.570+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO Executor: Finished task 0.0 in stage 77.0 (TID 829). 2722 bytes result sent to driver
[2025-05-02T02:22:55.573+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 830) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10908 bytes)
[2025-05-02T02:22:55.575+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO Executor: Running task 0.0 in stage 78.0 (TID 830)
[2025-05-02T02:22:55.576+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 829) in 596 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:55.577+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-02T02:22:55.578+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: ResultStage 77 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.623 s
[2025-05-02T02:22:55.579+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:55.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
[2025-05-02T02:22:55.581+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Job 42 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.627314 s
[2025-05-02T02:22:55.582+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 16.0 MiB, free 379.1 MiB)
[2025-05-02T02:22:55.585+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 1814.0 B, free 379.1 MiB)
[2025-05-02T02:22:55.586+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on ***-scheduler:33063 (size: 1814.0 B, free: 432.8 MiB)
[2025-05-02T02:22:55.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO SparkContext: Created broadcast 71 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:55.596+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:22:55.598+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:22:55.634+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO CodeGenerator: Code generated in 53.113518 ms
[2025-05-02T02:22:55.666+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO BlockManagerInfo: Removed broadcast_68_piece0 on ***-scheduler:33063 in memory (size: 8.0 KiB, free: 432.8 MiB)
[2025-05-02T02:22:55.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_allergies/part-00000-d763f1ab-3051-4582-85dd-47211fe11093-c000.snappy.parquet, range: 0-11706, partition values: [empty row]
[2025-05-02T02:22:55.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO CodeGenerator: Code generated in 52.617336 ms
[2025-05-02T02:22:55.688+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 206.6 KiB, free 362.7 MiB)
[2025-05-02T02:22:55.705+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 362.7 MiB)
[2025-05-02T02:22:55.706+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 432.8 MiB)
[2025-05-02T02:22:55.708+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO SparkContext: Created broadcast 72 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:55.709+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5664674 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:22:55.721+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Registering RDD 195 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 17
[2025-05-02T02:22:55.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Got map stage job 45 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:55.725+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Final stage: ShuffleMapStage 80 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:55.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:22:55.727+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:55.729+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[195] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:55.730+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 54.9 KiB, free 362.6 MiB)
[2025-05-02T02:22:55.731+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 362.6 MiB)
[2025-05-02T02:22:55.732+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on ***-scheduler:33063 (size: 23.8 KiB, free: 432.7 MiB)
[2025-05-02T02:22:55.733+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:55.734+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[195] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:55.735+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
[2025-05-02T02:22:55.740+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:55.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO Executor: Finished task 0.0 in stage 78.0 (TID 830). 2978 bytes result sent to driver
[2025-05-02T02:22:55.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 831) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10920 bytes)
[2025-05-02T02:22:55.874+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO Executor: Running task 0.0 in stage 79.0 (TID 831)
[2025-05-02T02:22:55.875+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 830) in 302 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:55.876+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-02T02:22:55.877+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: ShuffleMapStage 78 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.872 s
[2025-05-02T02:22:55.878+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:55.879+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: running: Set(ResultStage 79, ShuffleMapStage 80)
[2025-05-02T02:22:55.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:55.881+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:55.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO CodeGenerator: Code generated in 14.016345 ms
[2025-05-02T02:22:55.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO FileScanRDD: Reading File path: s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet, range: 0-3575, partition values: [empty row]
[2025-05-02T02:22:55.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:55 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:56.008+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO FilterCompat: Filtering using predicate: and(noteq(Allergy_Group_Key, null), noteq(Allergy_Key, null))
[2025-05-02T02:22:56.032+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:56.115+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO Executor: Finished task 0.0 in stage 79.0 (TID 831). 4601 bytes result sent to driver
[2025-05-02T02:22:56.117+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManagerInfo: Removed broadcast_69_piece0 on ***-scheduler:33063 in memory (size: 21.4 KiB, free: 432.8 MiB)
[2025-05-02T02:22:56.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 832) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10909 bytes)
[2025-05-02T02:22:56.122+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 831) in 248 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:56.123+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-05-02T02:22:56.124+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO Executor: Running task 0.0 in stage 80.0 (TID 832)
[2025-05-02T02:22:56.125+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: ResultStage 79 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.088 s
[2025-05-02T02:22:56.126+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:56.127+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
[2025-05-02T02:22:56.128+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: Job 44 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.091489 s
[2025-05-02T02:22:56.150+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO CodeGenerator: Code generated in 24.705927 ms
[2025-05-02T02:22:56.153+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 16.0 MiB, free 362.9 MiB)
[2025-05-02T02:22:56.154+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 362.9 MiB)
[2025-05-02T02:22:56.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on ***-scheduler:33063 (size: 4.2 KiB, free: 432.7 MiB)
[2025-05-02T02:22:56.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO SparkContext: Created broadcast 74 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-02T02:22:56.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO CodeGenerator: Code generated in 45.006026 ms
[2025-05-02T02:22:56.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManagerInfo: Removed broadcast_70_piece0 on ***-scheduler:33063 in memory (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-02T02:22:56.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/part-00000-ea7425f2-9107-4d6c-bddb-e4d1ec24a4da-c000.snappy.parquet, range: 0-1470370, partition values: [empty row]
[2025-05-02T02:22:56.486+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:22:56.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO Executor: Finished task 0.0 in stage 80.0 (TID 832). 3875 bytes result sent to driver
[2025-05-02T02:22:56.891+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 832) in 770 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:56.893+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-05-02T02:22:56.894+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: ShuffleMapStage 80 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.165 s
[2025-05-02T02:22:56.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:56.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:56.897+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:56.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:56.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:56.910+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:56.974+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManagerInfo: Removed broadcast_20_piece0 on ***-scheduler:33063 in memory (size: 35.8 KiB, free: 432.8 MiB)
[2025-05-02T02:22:56.990+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManager: Removing RDD 67
[2025-05-02T02:22:56.995+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManagerInfo: Removed broadcast_39_piece0 on ***-scheduler:33063 in memory (size: 36.4 KiB, free: 432.8 MiB)
[2025-05-02T02:22:56.999+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:56 INFO BlockManager: Removing RDD 120
[2025-05-02T02:22:57.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_21_piece0 on ***-scheduler:33063 in memory (size: 35.9 KiB, free: 432.9 MiB)
[2025-05-02T02:22:57.005+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_41_piece0 on ***-scheduler:33063 in memory (size: 138.9 KiB, free: 433.0 MiB)
[2025-05-02T02:22:57.010+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManager: Removing RDD 71
[2025-05-02T02:22:57.014+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_29_piece0 on ***-scheduler:33063 in memory (size: 170.7 KiB, free: 433.2 MiB)
[2025-05-02T02:22:57.017+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_57_piece0 on ***-scheduler:33063 in memory (size: 139.0 KiB, free: 433.3 MiB)
[2025-05-02T02:22:57.020+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_30_piece0 on ***-scheduler:33063 in memory (size: 36.3 KiB, free: 433.3 MiB)
[2025-05-02T02:22:57.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_34_piece0 on ***-scheduler:33063 in memory (size: 1814.0 B, free: 433.3 MiB)
[2025-05-02T02:22:57.025+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_32_piece0 on ***-scheduler:33063 in memory (size: 36.5 KiB, free: 433.4 MiB)
[2025-05-02T02:22:57.031+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_35_piece0 on ***-scheduler:33063 in memory (size: 36.3 KiB, free: 433.4 MiB)
[2025-05-02T02:22:57.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Removed broadcast_38_piece0 on ***-scheduler:33063 in memory (size: 531.9 KiB, free: 433.9 MiB)
[2025-05-02T02:22:57.041+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 52.594478 ms
[2025-05-02T02:22:57.085+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 29.242122 ms
[2025-05-02T02:22:57.131+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 32.136232 ms
[2025-05-02T02:22:57.162+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:57.165+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Got job 46 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions
[2025-05-02T02:22:57.166+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Final stage: ResultStage 83 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:57.167+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81, ShuffleMapStage 82)
[2025-05-02T02:22:57.168+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:57.169+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[203] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:57.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 79.8 KiB, free 399.4 MiB)
[2025-05-02T02:22:57.183+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 399.3 MiB)
[2025-05-02T02:22:57.184+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on ***-scheduler:33063 (size: 34.1 KiB, free: 433.9 MiB)
[2025-05-02T02:22:57.185+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:57.186+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 83 (MapPartitionsRDD[203] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-02T02:22:57.187+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks resource profile 0
[2025-05-02T02:22:57.189+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 833) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10315 bytes)
[2025-05-02T02:22:57.190+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Running task 0.0 in stage 83.0 (TID 833)
[2025-05-02T02:22:57.201+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Getting 1 (17.1 KiB) non-empty blocks including 1 (17.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:57.203+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:57.241+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 37.61745 ms
[2025-05-02T02:22:57.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 7.33259 ms
[2025-05-02T02:22:57.268+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Finished task 0.0 in stage 83.0 (TID 833). 17704 bytes result sent to driver
[2025-05-02T02:22:57.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 834) (***-scheduler, executor driver, partition 1, NODE_LOCAL, 10315 bytes)
[2025-05-02T02:22:57.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 833) in 82 ms on ***-scheduler (executor driver) (1/2)
[2025-05-02T02:22:57.272+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Running task 1.0 in stage 83.0 (TID 834)
[2025-05-02T02:22:57.279+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Getting 1 (523.7 KiB) non-empty blocks including 1 (523.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:57.280+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:57.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 32.600752 ms
[2025-05-02T02:22:57.383+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Finished task 1.0 in stage 83.0 (TID 834). 694409 bytes result sent to driver
[2025-05-02T02:22:57.391+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 834) in 123 ms on ***-scheduler (executor driver) (2/2)
[2025-05-02T02:22:57.393+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool
[2025-05-02T02:22:57.394+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: ResultStage 83 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.220 s
[2025-05-02T02:22:57.395+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:57.397+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
[2025-05-02T02:22:57.398+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Job 46 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.231822 s
[2025-05-02T02:22:57.452+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Registering RDD 204 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 18
[2025-05-02T02:22:57.454+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Got map stage job 47 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions
[2025-05-02T02:22:57.455+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Final stage: ShuffleMapStage 86 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:57.456+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84, ShuffleMapStage 85)
[2025-05-02T02:22:57.457+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:57.458+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[204] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:57.464+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 98.6 KiB, free 399.3 MiB)
[2025-05-02T02:22:57.469+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 47.1 KiB, free 399.2 MiB)
[2025-05-02T02:22:57.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on ***-scheduler:33063 (size: 47.1 KiB, free: 433.8 MiB)
[2025-05-02T02:22:57.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:57.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[204] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-02T02:22:57.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks resource profile 0
[2025-05-02T02:22:57.475+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 835) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10304 bytes)
[2025-05-02T02:22:57.476+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Running task 0.0 in stage 86.0 (TID 835)
[2025-05-02T02:22:57.495+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 9.410535 ms
[2025-05-02T02:22:57.498+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Getting 1 (17.1 KiB) non-empty blocks including 1 (17.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:57.499+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:22:57.523+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Finished task 0.0 in stage 86.0 (TID 835). 8979 bytes result sent to driver
[2025-05-02T02:22:57.525+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 836) (***-scheduler, executor driver, partition 1, NODE_LOCAL, 10304 bytes)
[2025-05-02T02:22:57.526+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Running task 1.0 in stage 86.0 (TID 836)
[2025-05-02T02:22:57.527+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 835) in 52 ms on ***-scheduler (executor driver) (1/2)
[2025-05-02T02:22:57.537+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Getting 1 (523.7 KiB) non-empty blocks including 1 (523.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:57.538+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:57.674+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Finished task 1.0 in stage 86.0 (TID 836). 9022 bytes result sent to driver
[2025-05-02T02:22:57.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 836) in 151 ms on ***-scheduler (executor driver) (2/2)
[2025-05-02T02:22:57.681+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool
[2025-05-02T02:22:57.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: ShuffleMapStage 86 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.216 s
[2025-05-02T02:22:57.683+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:22:57.684+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: running: Set()
[2025-05-02T02:22:57.685+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:22:57.686+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: failed: Set()
[2025-05-02T02:22:57.689+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:22:57.755+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 47.350298 ms
[2025-05-02T02:22:57.815+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:22:57.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Got job 48 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions
[2025-05-02T02:22:57.819+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Final stage: ResultStage 90 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:22:57.820+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
[2025-05-02T02:22:57.821+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:22:57.823+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[206] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:22:57.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 392.6 KiB, free 398.8 MiB)
[2025-05-02T02:22:57.879+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 143.9 KiB, free 398.7 MiB)
[2025-05-02T02:22:57.880+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on ***-scheduler:33063 (size: 143.9 KiB, free: 433.7 MiB)
[2025-05-02T02:22:57.882+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:22:57.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[206] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:22:57.884+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
[2025-05-02T02:22:57.885+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 837) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:22:57.886+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO Executor: Running task 0.0 in stage 90.0 (TID 837)
[2025-05-02T02:22:57.934+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Getting 2 (530.2 KiB) non-empty blocks including 2 (530.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:22:57.936+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-05-02T02:22:57.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:57 INFO CodeGenerator: Code generated in 43.464267 ms
[2025-05-02T02:22:58.004+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:58 INFO CodeGenerator: Code generated in 12.890433 ms
[2025-05-02T02:22:58.030+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:58 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:22:58.032+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:58 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:22:58.036+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-05-02T02:22:58.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-05-02T02:22:58.040+0000] {spark_submit.py:649} INFO - {
[2025-05-02T02:22:58.041+0000] {spark_submit.py:649} INFO - "type" : "struct",
[2025-05-02T02:22:58.042+0000] {spark_submit.py:649} INFO - "fields" : [ {
[2025-05-02T02:22:58.043+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Group_Key",
[2025-05-02T02:22:58.044+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:58.045+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:58.046+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:58.047+0000] {spark_submit.py:649} INFO - }, {
[2025-05-02T02:22:58.048+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Key",
[2025-05-02T02:22:58.049+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:22:58.050+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:22:58.052+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:22:58.053+0000] {spark_submit.py:649} INFO - } ]
[2025-05-02T02:22:58.054+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:22:58.055+0000] {spark_submit.py:649} INFO - and corresponding Parquet message type:
[2025-05-02T02:22:58.056+0000] {spark_submit.py:649} INFO - message spark_schema {
[2025-05-02T02:22:58.057+0000] {spark_submit.py:649} INFO - optional binary Allergy_Group_Key (STRING);
[2025-05-02T02:22:58.058+0000] {spark_submit.py:649} INFO - optional binary Allergy_Key (STRING);
[2025-05-02T02:22:58.059+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:22:58.060+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:22:58.061+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:22:59.826+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO Executor: Finished task 0.0 in stage 90.0 (TID 837). 13264 bytes result sent to driver
[2025-05-02T02:22:59.844+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 837) in 1939 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:22:59.847+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-05-02T02:22:59.849+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO DAGScheduler: ResultStage 90 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.000 s
[2025-05-02T02:22:59.850+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:22:59.850+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
[2025-05-02T02:22:59.851+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO DAGScheduler: Job 48 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 2.010428 s
[2025-05-02T02:22:59.852+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO DeltaFileFormatWriter: Start to commit write Job 2b8136f0-60b8-4d7d-835d-55c405a47c2f.
[2025-05-02T02:22:59.853+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO DeltaFileFormatWriter: Write Job 2b8136f0-60b8-4d7d-835d-55c405a47c2f committed. Elapsed time: 0 ms.
[2025-05-02T02:22:59.854+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO DeltaFileFormatWriter: Finished processing stats for write job 2b8136f0-60b8-4d7d-835d-55c405a47c2f.
[2025-05-02T02:22:59.855+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO MergeIntoCommand: DELTA: Done
[2025-05-02T02:22:59.856+0000] {spark_submit.py:649} INFO - 25/05/02 02:22:59 INFO OptimisticTransaction: [tableId=0822c19b,txnId=893e01a0] Attempting to commit version 2 with 2 actions with Serializable isolation level
[2025-05-02T02:23:00.912+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO OptimisticTransaction: Incremental commit: starting with snapshot version 1
[2025-05-02T02:23:00.923+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO DeltaLog: Creating a new snapshot v2 for commit version 2
[2025-05-02T02:23:00.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO DeltaLog: Loading version 2.
[2025-05-02T02:23:00.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO Snapshot: [tableId=0822c19b-6cc0-4149-b022-d7dcd20fd2b6] Created snapshot Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=2, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,2,ArrayBuffer(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json; isDirectory=false; length=1896; replication=1; blocksize=33554432; modification_time=1746152560262; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c8bea37cd7c519106867602e55f00f0b versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000002.json; isDirectory=false; length=1696; replication=1; blocksize=33554432; modification_time=1746152580000; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=df00b5f3d1fb814d9458cbab9ff29bb1 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746152580000), checksumOpt=Some(VersionChecksum(Some(893e01a0-face-4234-8466-2dee87b0e34c),444166,2,None,None,1,1,None,Some(Stream()),Some(Stream()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(Stream(AddFile(part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet,Map(),3575,1746152559000,false,{"numRecords":92,"minValues":{"Allergy_Group_Key":"05b319200754a18a85d0d6c33e1949ea","Allergy_Key":"11f8b98734e642fcc35a6842475de9f6"},"maxValues":{"Allergy_Group_Key":"ee675f9cb730effe647251fabb7c8af8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None), AddFile(part-00000-efb14118-1c32-4466-8482-71262e79e048-c000.snappy.parquet,Map(),440591,1746152579000,false,{"numRecords":7034,"minValues":{"Allergy_Group_Key":"000574ab68a9589cb8a2dc1b07c26439","Allergy_Key":"00000000000000000000000000000000"},"maxValues":{"Allergy_Group_Key":"fffd2fd32ad5431dc6df8b048878a8d8","Allergy_Key":"00000000000000000000000000000000"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:23:00.927+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log, version=2, metadata=Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)), logSegment=LogSegment(s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log,2,ArrayBuffer(S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000000.json; isDirectory=false; length=1416; replication=1; blocksize=33554432; modification_time=1746151929961; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=408630ead739d877deebcf0b8b8d7b19 versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000001.json; isDirectory=false; length=1896; replication=1; blocksize=33554432; modification_time=1746152560262; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c8bea37cd7c519106867602e55f00f0b versionId=null, S3AFileStatus{path=s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000002.json; isDirectory=false; length=1696; replication=1; blocksize=33554432; modification_time=1746152580000; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=df00b5f3d1fb814d9458cbab9ff29bb1 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@5977923,1746152580000), checksumOpt=Some(VersionChecksum(Some(893e01a0-face-4234-8466-2dee87b0e34c),444166,2,None,None,1,1,None,Some(Stream()),Some(Stream()),Metadata(0822c19b-6cc0-4149-b022-d7dcd20fd2b6,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"Allergy_Group_Key","type":"string","nullable":true,"metadata":{}},{"name":"Allergy_Key","type":"string","nullable":true,"metadata":{}}]},List(),Map(),Some(1746151908308)),Protocol(1,2),None,None,Some(Stream(AddFile(part-00000-851a54aa-9ec9-4dbd-80cf-95e7a4d0c4b6-c000.snappy.parquet,Map(),3575,1746152559000,false,{"numRecords":92,"minValues":{"Allergy_Group_Key":"05b319200754a18a85d0d6c33e1949ea","Allergy_Key":"11f8b98734e642fcc35a6842475de9f6"},"maxValues":{"Allergy_Group_Key":"ee675f9cb730effe647251fabb7c8af8","Allergy_Key":"f987f55b75c0dd020567099859c75a82"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None), AddFile(part-00000-efb14118-1c32-4466-8482-71262e79e048-c000.snappy.parquet,Map(),440591,1746152579000,false,{"numRecords":7034,"minValues":{"Allergy_Group_Key":"000574ab68a9589cb8a2dc1b07c26439","Allergy_Key":"00000000000000000000000000000000"},"maxValues":{"Allergy_Group_Key":"fffd2fd32ad5431dc6df8b048878a8d8","Allergy_Key":"00000000000000000000000000000000"},"nullCount":{"Allergy_Group_Key":0,"Allergy_Key":0}},null,null,None,None,None))))))
[2025-05-02T02:23:00.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO MapPartitionsRDD: Removing RDD 159 from persistence list
[2025-05-02T02:23:00.929+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO BlockManager: Removing RDD 159
[2025-05-02T02:23:00.947+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 3, totalFileSize: 5008)
[2025-05-02T02:23:00.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO OptimisticTransaction: [tableId=0822c19b,txnId=893e01a0] Committed delta #2 to s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log
[2025-05-02T02:23:00.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO ChecksumHook: Writing checksum file for table path s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log version 2
[2025-05-02T02:23:00.975+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO BlockManagerInfo: Removed broadcast_73_piece0 on ***-scheduler:33063 in memory (size: 23.8 KiB, free: 433.7 MiB)
[2025-05-02T02:23:00.978+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO BlockManagerInfo: Removed broadcast_75_piece0 on ***-scheduler:33063 in memory (size: 34.1 KiB, free: 433.8 MiB)
[2025-05-02T02:23:00.980+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO BlockManagerInfo: Removed broadcast_77_piece0 on ***-scheduler:33063 in memory (size: 143.9 KiB, free: 433.9 MiB)
[2025-05-02T02:23:00.983+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:00 INFO BlockManagerInfo: Removed broadcast_76_piece0 on ***-scheduler:33063 in memory (size: 47.1 KiB, free: 434.0 MiB)
[2025-05-02T02:23:01.670+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:01 INFO CheckpointFileManager: Writing atomically to s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000002.crc using temp file s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/.00000000000000000002.crc.1c948b10-6b18-4b2c-bf6e-6818e7f9d93a.tmp
[2025-05-02T02:23:06.714+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:06 INFO CheckpointFileManager: Renamed temp file s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/.00000000000000000002.crc.1c948b10-6b18-4b2c-bf6e-6818e7f9d93a.tmp to s3a://medical-bucket/curated/transactional/medical-data-sample/bridge_allergy_group/_delta_log/00000000000000000002.crc
[2025-05-02T02:23:25.286+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:25 INFO InMemoryFileIndex: It took 836 ms to list leaf files for 1 paths.
[2025-05-02T02:23:33.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:33 INFO PrepareDeltaScan: DELTA: Filtering files for query
[2025-05-02T02:23:34.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2025-05-02T02:23:34.194+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO DAGScheduler: Got job 49 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2025-05-02T02:23:34.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO DAGScheduler: Final stage: ResultStage 92 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2025-05-02T02:23:34.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
[2025-05-02T02:23:34.197+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:23:34.199+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[208] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2025-05-02T02:23:34.200+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 687.2 KiB, free 398.9 MiB)
[2025-05-02T02:23:34.210+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 155.3 KiB, free 398.7 MiB)
[2025-05-02T02:23:34.211+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on ***-scheduler:33063 (size: 155.3 KiB, free: 433.8 MiB)
[2025-05-02T02:23:34.213+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:23:34.214+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 92 (MapPartitionsRDD[208] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-02T02:23:34.215+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSchedulerImpl: Adding task set 92.0 with 50 tasks resource profile 0
[2025-05-02T02:23:34.216+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 838) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.217+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 0.0 in stage 92.0 (TID 838)
[2025-05-02T02:23:34.235+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_0 locally
[2025-05-02T02:23:34.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 0.0 in stage 92.0 (TID 838). 4181 bytes result sent to driver
[2025-05-02T02:23:34.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 839) (***-scheduler, executor driver, partition 1, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.240+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 1.0 in stage 92.0 (TID 839)
[2025-05-02T02:23:34.241+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 838) in 25 ms on ***-scheduler (executor driver) (1/50)
[2025-05-02T02:23:34.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_1 locally
[2025-05-02T02:23:34.255+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 1.0 in stage 92.0 (TID 839). 4181 bytes result sent to driver
[2025-05-02T02:23:34.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 840) (***-scheduler, executor driver, partition 2, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.258+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 2.0 in stage 92.0 (TID 840)
[2025-05-02T02:23:34.259+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 839) in 19 ms on ***-scheduler (executor driver) (2/50)
[2025-05-02T02:23:34.270+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_2 locally
[2025-05-02T02:23:34.302+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 2.0 in stage 92.0 (TID 840). 4392 bytes result sent to driver
[2025-05-02T02:23:34.303+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 841) (***-scheduler, executor driver, partition 3, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.304+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 3.0 in stage 92.0 (TID 841)
[2025-05-02T02:23:34.305+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 840) in 47 ms on ***-scheduler (executor driver) (3/50)
[2025-05-02T02:23:34.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_3 locally
[2025-05-02T02:23:34.348+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 3.0 in stage 92.0 (TID 841). 4224 bytes result sent to driver
[2025-05-02T02:23:34.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 842) (***-scheduler, executor driver, partition 4, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.351+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 4.0 in stage 92.0 (TID 842)
[2025-05-02T02:23:34.353+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 841) in 29 ms on ***-scheduler (executor driver) (4/50)
[2025-05-02T02:23:34.354+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_4 locally
[2025-05-02T02:23:34.356+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 4.0 in stage 92.0 (TID 842). 4181 bytes result sent to driver
[2025-05-02T02:23:34.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 843) (***-scheduler, executor driver, partition 5, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.358+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 5.0 in stage 92.0 (TID 843)
[2025-05-02T02:23:34.359+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 842) in 23 ms on ***-scheduler (executor driver) (5/50)
[2025-05-02T02:23:34.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_5 locally
[2025-05-02T02:23:34.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 5.0 in stage 92.0 (TID 843). 4181 bytes result sent to driver
[2025-05-02T02:23:34.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 844) (***-scheduler, executor driver, partition 6, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 843) in 23 ms on ***-scheduler (executor driver) (6/50)
[2025-05-02T02:23:34.379+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 6.0 in stage 92.0 (TID 844)
[2025-05-02T02:23:34.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_6 locally
[2025-05-02T02:23:34.396+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 6.0 in stage 92.0 (TID 844). 4181 bytes result sent to driver
[2025-05-02T02:23:34.397+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 845) (***-scheduler, executor driver, partition 7, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 7.0 in stage 92.0 (TID 845)
[2025-05-02T02:23:34.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 844) in 24 ms on ***-scheduler (executor driver) (7/50)
[2025-05-02T02:23:34.413+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_7 locally
[2025-05-02T02:23:34.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 7.0 in stage 92.0 (TID 845). 4181 bytes result sent to driver
[2025-05-02T02:23:34.421+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 846) (***-scheduler, executor driver, partition 8, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.423+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 845) in 22 ms on ***-scheduler (executor driver) (8/50)
[2025-05-02T02:23:34.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 8.0 in stage 92.0 (TID 846)
[2025-05-02T02:23:34.445+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_8 locally
[2025-05-02T02:23:34.447+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 8.0 in stage 92.0 (TID 846). 4181 bytes result sent to driver
[2025-05-02T02:23:34.449+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 847) (***-scheduler, executor driver, partition 9, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.450+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 846) in 32 ms on ***-scheduler (executor driver) (9/50)
[2025-05-02T02:23:34.451+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 9.0 in stage 92.0 (TID 847)
[2025-05-02T02:23:34.467+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_9 locally
[2025-05-02T02:23:34.470+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 9.0 in stage 92.0 (TID 847). 4181 bytes result sent to driver
[2025-05-02T02:23:34.472+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 10.0 in stage 92.0 (TID 848) (***-scheduler, executor driver, partition 10, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.473+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 10.0 in stage 92.0 (TID 848)
[2025-05-02T02:23:34.474+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 847) in 23 ms on ***-scheduler (executor driver) (10/50)
[2025-05-02T02:23:34.487+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_10 locally
[2025-05-02T02:23:34.489+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 10.0 in stage 92.0 (TID 848). 4181 bytes result sent to driver
[2025-05-02T02:23:34.491+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 11.0 in stage 92.0 (TID 849) (***-scheduler, executor driver, partition 11, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.493+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 11.0 in stage 92.0 (TID 849)
[2025-05-02T02:23:34.494+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 10.0 in stage 92.0 (TID 848) in 20 ms on ***-scheduler (executor driver) (11/50)
[2025-05-02T02:23:34.507+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_11 locally
[2025-05-02T02:23:34.518+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 11.0 in stage 92.0 (TID 849). 4181 bytes result sent to driver
[2025-05-02T02:23:34.519+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 12.0 in stage 92.0 (TID 850) (***-scheduler, executor driver, partition 12, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.520+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 12.0 in stage 92.0 (TID 850)
[2025-05-02T02:23:34.522+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 11.0 in stage 92.0 (TID 849) in 22 ms on ***-scheduler (executor driver) (12/50)
[2025-05-02T02:23:34.580+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_12 locally
[2025-05-02T02:23:34.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 12.0 in stage 92.0 (TID 850). 4181 bytes result sent to driver
[2025-05-02T02:23:34.585+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 13.0 in stage 92.0 (TID 851) (***-scheduler, executor driver, partition 13, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.586+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 12.0 in stage 92.0 (TID 850) in 74 ms on ***-scheduler (executor driver) (13/50)
[2025-05-02T02:23:34.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 13.0 in stage 92.0 (TID 851)
[2025-05-02T02:23:34.603+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_13 locally
[2025-05-02T02:23:34.606+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 13.0 in stage 92.0 (TID 851). 4181 bytes result sent to driver
[2025-05-02T02:23:34.608+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 14.0 in stage 92.0 (TID 852) (***-scheduler, executor driver, partition 14, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 14.0 in stage 92.0 (TID 852)
[2025-05-02T02:23:34.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 13.0 in stage 92.0 (TID 851) in 25 ms on ***-scheduler (executor driver) (14/50)
[2025-05-02T02:23:34.625+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_14 locally
[2025-05-02T02:23:34.628+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 14.0 in stage 92.0 (TID 852). 4181 bytes result sent to driver
[2025-05-02T02:23:34.629+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 15.0 in stage 92.0 (TID 853) (***-scheduler, executor driver, partition 15, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.631+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 15.0 in stage 92.0 (TID 853)
[2025-05-02T02:23:34.632+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 14.0 in stage 92.0 (TID 852) in 22 ms on ***-scheduler (executor driver) (15/50)
[2025-05-02T02:23:34.648+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_15 locally
[2025-05-02T02:23:34.652+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 15.0 in stage 92.0 (TID 853). 4181 bytes result sent to driver
[2025-05-02T02:23:34.653+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 16.0 in stage 92.0 (TID 854) (***-scheduler, executor driver, partition 16, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.655+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 15.0 in stage 92.0 (TID 853) in 25 ms on ***-scheduler (executor driver) (16/50)
[2025-05-02T02:23:34.656+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 16.0 in stage 92.0 (TID 854)
[2025-05-02T02:23:34.671+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_16 locally
[2025-05-02T02:23:34.678+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 16.0 in stage 92.0 (TID 854). 4181 bytes result sent to driver
[2025-05-02T02:23:34.679+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 17.0 in stage 92.0 (TID 855) (***-scheduler, executor driver, partition 17, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.680+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 17.0 in stage 92.0 (TID 855)
[2025-05-02T02:23:34.682+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 16.0 in stage 92.0 (TID 854) in 24 ms on ***-scheduler (executor driver) (17/50)
[2025-05-02T02:23:34.694+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_17 locally
[2025-05-02T02:23:34.697+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 17.0 in stage 92.0 (TID 855). 4181 bytes result sent to driver
[2025-05-02T02:23:34.699+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 18.0 in stage 92.0 (TID 856) (***-scheduler, executor driver, partition 18, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.701+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 18.0 in stage 92.0 (TID 856)
[2025-05-02T02:23:34.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 17.0 in stage 92.0 (TID 855) in 24 ms on ***-scheduler (executor driver) (18/50)
[2025-05-02T02:23:34.720+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_18 locally
[2025-05-02T02:23:34.723+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 18.0 in stage 92.0 (TID 856). 4181 bytes result sent to driver
[2025-05-02T02:23:34.724+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 19.0 in stage 92.0 (TID 857) (***-scheduler, executor driver, partition 19, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.726+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 19.0 in stage 92.0 (TID 857)
[2025-05-02T02:23:34.727+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 18.0 in stage 92.0 (TID 856) in 26 ms on ***-scheduler (executor driver) (19/50)
[2025-05-02T02:23:34.745+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_19 locally
[2025-05-02T02:23:34.758+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 19.0 in stage 92.0 (TID 857). 4181 bytes result sent to driver
[2025-05-02T02:23:34.759+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 20.0 in stage 92.0 (TID 858) (***-scheduler, executor driver, partition 20, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.761+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 20.0 in stage 92.0 (TID 858)
[2025-05-02T02:23:34.762+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 19.0 in stage 92.0 (TID 857) in 26 ms on ***-scheduler (executor driver) (20/50)
[2025-05-02T02:23:34.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_20 locally
[2025-05-02T02:23:34.770+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 20.0 in stage 92.0 (TID 858). 4181 bytes result sent to driver
[2025-05-02T02:23:34.771+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 21.0 in stage 92.0 (TID 859) (***-scheduler, executor driver, partition 21, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.773+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 21.0 in stage 92.0 (TID 859)
[2025-05-02T02:23:34.774+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 20.0 in stage 92.0 (TID 858) in 24 ms on ***-scheduler (executor driver) (21/50)
[2025-05-02T02:23:34.790+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_21 locally
[2025-05-02T02:23:34.793+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 21.0 in stage 92.0 (TID 859). 4181 bytes result sent to driver
[2025-05-02T02:23:34.795+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 22.0 in stage 92.0 (TID 860) (***-scheduler, executor driver, partition 22, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.796+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 22.0 in stage 92.0 (TID 860)
[2025-05-02T02:23:34.798+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 21.0 in stage 92.0 (TID 859) in 24 ms on ***-scheduler (executor driver) (22/50)
[2025-05-02T02:23:34.813+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_22 locally
[2025-05-02T02:23:34.815+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 22.0 in stage 92.0 (TID 860). 4181 bytes result sent to driver
[2025-05-02T02:23:34.816+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 23.0 in stage 92.0 (TID 861) (***-scheduler, executor driver, partition 23, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.818+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 23.0 in stage 92.0 (TID 861)
[2025-05-02T02:23:34.819+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 22.0 in stage 92.0 (TID 860) in 23 ms on ***-scheduler (executor driver) (23/50)
[2025-05-02T02:23:34.837+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_23 locally
[2025-05-02T02:23:34.840+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 23.0 in stage 92.0 (TID 861). 4181 bytes result sent to driver
[2025-05-02T02:23:34.841+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 24.0 in stage 92.0 (TID 862) (***-scheduler, executor driver, partition 24, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.843+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 24.0 in stage 92.0 (TID 862)
[2025-05-02T02:23:34.844+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 23.0 in stage 92.0 (TID 861) in 26 ms on ***-scheduler (executor driver) (24/50)
[2025-05-02T02:23:34.865+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_24 locally
[2025-05-02T02:23:34.868+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 24.0 in stage 92.0 (TID 862). 4181 bytes result sent to driver
[2025-05-02T02:23:34.870+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 25.0 in stage 92.0 (TID 863) (***-scheduler, executor driver, partition 25, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.871+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 24.0 in stage 92.0 (TID 862) in 29 ms on ***-scheduler (executor driver) (25/50)
[2025-05-02T02:23:34.872+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 25.0 in stage 92.0 (TID 863)
[2025-05-02T02:23:34.892+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_25 locally
[2025-05-02T02:23:34.895+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 25.0 in stage 92.0 (TID 863). 4181 bytes result sent to driver
[2025-05-02T02:23:34.896+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 26.0 in stage 92.0 (TID 864) (***-scheduler, executor driver, partition 26, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.898+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 26.0 in stage 92.0 (TID 864)
[2025-05-02T02:23:34.899+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 25.0 in stage 92.0 (TID 863) in 28 ms on ***-scheduler (executor driver) (26/50)
[2025-05-02T02:23:34.920+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_26 locally
[2025-05-02T02:23:34.925+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 26.0 in stage 92.0 (TID 864). 4181 bytes result sent to driver
[2025-05-02T02:23:34.926+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 27.0 in stage 92.0 (TID 865) (***-scheduler, executor driver, partition 27, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.928+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 27.0 in stage 92.0 (TID 865)
[2025-05-02T02:23:34.930+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 26.0 in stage 92.0 (TID 864) in 32 ms on ***-scheduler (executor driver) (27/50)
[2025-05-02T02:23:34.944+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_27 locally
[2025-05-02T02:23:34.947+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 27.0 in stage 92.0 (TID 865). 4181 bytes result sent to driver
[2025-05-02T02:23:34.949+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 28.0 in stage 92.0 (TID 866) (***-scheduler, executor driver, partition 28, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.950+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 28.0 in stage 92.0 (TID 866)
[2025-05-02T02:23:34.951+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 27.0 in stage 92.0 (TID 865) in 24 ms on ***-scheduler (executor driver) (28/50)
[2025-05-02T02:23:34.964+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_28 locally
[2025-05-02T02:23:34.966+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 28.0 in stage 92.0 (TID 866). 4181 bytes result sent to driver
[2025-05-02T02:23:34.967+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 29.0 in stage 92.0 (TID 867) (***-scheduler, executor driver, partition 29, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.969+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 29.0 in stage 92.0 (TID 867)
[2025-05-02T02:23:34.970+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 28.0 in stage 92.0 (TID 866) in 19 ms on ***-scheduler (executor driver) (29/50)
[2025-05-02T02:23:34.982+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_29 locally
[2025-05-02T02:23:34.984+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Finished task 29.0 in stage 92.0 (TID 867). 4181 bytes result sent to driver
[2025-05-02T02:23:34.985+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Starting task 30.0 in stage 92.0 (TID 868) (***-scheduler, executor driver, partition 30, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:34.986+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO Executor: Running task 30.0 in stage 92.0 (TID 868)
[2025-05-02T02:23:34.987+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO TaskSetManager: Finished task 29.0 in stage 92.0 (TID 867) in 19 ms on ***-scheduler (executor driver) (30/50)
[2025-05-02T02:23:35.000+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:34 INFO BlockManager: Found block rdd_90_30 locally
[2025-05-02T02:23:35.002+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 30.0 in stage 92.0 (TID 868). 4181 bytes result sent to driver
[2025-05-02T02:23:35.003+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 31.0 in stage 92.0 (TID 869) (***-scheduler, executor driver, partition 31, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.005+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 31.0 in stage 92.0 (TID 869)
[2025-05-02T02:23:35.006+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 30.0 in stage 92.0 (TID 868) in 19 ms on ***-scheduler (executor driver) (31/50)
[2025-05-02T02:23:35.019+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_31 locally
[2025-05-02T02:23:35.021+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 31.0 in stage 92.0 (TID 869). 4181 bytes result sent to driver
[2025-05-02T02:23:35.023+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 32.0 in stage 92.0 (TID 870) (***-scheduler, executor driver, partition 32, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.024+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 32.0 in stage 92.0 (TID 870)
[2025-05-02T02:23:35.026+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 31.0 in stage 92.0 (TID 869) in 20 ms on ***-scheduler (executor driver) (32/50)
[2025-05-02T02:23:35.038+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_32 locally
[2025-05-02T02:23:35.040+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 32.0 in stage 92.0 (TID 870). 4181 bytes result sent to driver
[2025-05-02T02:23:35.042+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 33.0 in stage 92.0 (TID 871) (***-scheduler, executor driver, partition 33, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.043+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 33.0 in stage 92.0 (TID 871)
[2025-05-02T02:23:35.045+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 32.0 in stage 92.0 (TID 870) in 19 ms on ***-scheduler (executor driver) (33/50)
[2025-05-02T02:23:35.057+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_33 locally
[2025-05-02T02:23:35.060+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 33.0 in stage 92.0 (TID 871). 4181 bytes result sent to driver
[2025-05-02T02:23:35.061+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 34.0 in stage 92.0 (TID 872) (***-scheduler, executor driver, partition 34, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.063+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 34.0 in stage 92.0 (TID 872)
[2025-05-02T02:23:35.064+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 33.0 in stage 92.0 (TID 871) in 20 ms on ***-scheduler (executor driver) (34/50)
[2025-05-02T02:23:35.076+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_34 locally
[2025-05-02T02:23:35.078+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 34.0 in stage 92.0 (TID 872). 4181 bytes result sent to driver
[2025-05-02T02:23:35.080+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 35.0 in stage 92.0 (TID 873) (***-scheduler, executor driver, partition 35, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.081+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 35.0 in stage 92.0 (TID 873)
[2025-05-02T02:23:35.082+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 34.0 in stage 92.0 (TID 872) in 20 ms on ***-scheduler (executor driver) (35/50)
[2025-05-02T02:23:35.094+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_35 locally
[2025-05-02T02:23:35.096+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 35.0 in stage 92.0 (TID 873). 4181 bytes result sent to driver
[2025-05-02T02:23:35.098+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 36.0 in stage 92.0 (TID 874) (***-scheduler, executor driver, partition 36, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.100+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 36.0 in stage 92.0 (TID 874)
[2025-05-02T02:23:35.101+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 35.0 in stage 92.0 (TID 873) in 19 ms on ***-scheduler (executor driver) (36/50)
[2025-05-02T02:23:35.113+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_36 locally
[2025-05-02T02:23:35.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 36.0 in stage 92.0 (TID 874). 4181 bytes result sent to driver
[2025-05-02T02:23:35.118+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 37.0 in stage 92.0 (TID 875) (***-scheduler, executor driver, partition 37, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.119+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 37.0 in stage 92.0 (TID 875)
[2025-05-02T02:23:35.121+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 36.0 in stage 92.0 (TID 874) in 20 ms on ***-scheduler (executor driver) (37/50)
[2025-05-02T02:23:35.134+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_37 locally
[2025-05-02T02:23:35.137+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 37.0 in stage 92.0 (TID 875). 4181 bytes result sent to driver
[2025-05-02T02:23:35.138+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 38.0 in stage 92.0 (TID 876) (***-scheduler, executor driver, partition 38, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.139+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 37.0 in stage 92.0 (TID 875) in 22 ms on ***-scheduler (executor driver) (38/50)
[2025-05-02T02:23:35.141+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 38.0 in stage 92.0 (TID 876)
[2025-05-02T02:23:35.153+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_38 locally
[2025-05-02T02:23:35.156+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 38.0 in stage 92.0 (TID 876). 4181 bytes result sent to driver
[2025-05-02T02:23:35.157+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 39.0 in stage 92.0 (TID 877) (***-scheduler, executor driver, partition 39, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.159+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 39.0 in stage 92.0 (TID 877)
[2025-05-02T02:23:35.160+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 38.0 in stage 92.0 (TID 876) in 20 ms on ***-scheduler (executor driver) (39/50)
[2025-05-02T02:23:35.173+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_39 locally
[2025-05-02T02:23:35.176+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 39.0 in stage 92.0 (TID 877). 4181 bytes result sent to driver
[2025-05-02T02:23:35.177+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 40.0 in stage 92.0 (TID 878) (***-scheduler, executor driver, partition 40, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.179+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 40.0 in stage 92.0 (TID 878)
[2025-05-02T02:23:35.180+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 39.0 in stage 92.0 (TID 877) in 21 ms on ***-scheduler (executor driver) (40/50)
[2025-05-02T02:23:35.192+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_40 locally
[2025-05-02T02:23:35.195+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 40.0 in stage 92.0 (TID 878). 4181 bytes result sent to driver
[2025-05-02T02:23:35.196+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 41.0 in stage 92.0 (TID 879) (***-scheduler, executor driver, partition 41, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.198+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 41.0 in stage 92.0 (TID 879)
[2025-05-02T02:23:35.199+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 40.0 in stage 92.0 (TID 878) in 20 ms on ***-scheduler (executor driver) (41/50)
[2025-05-02T02:23:35.251+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_41 locally
[2025-05-02T02:23:35.253+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 41.0 in stage 92.0 (TID 879). 4224 bytes result sent to driver
[2025-05-02T02:23:35.254+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 42.0 in stage 92.0 (TID 880) (***-scheduler, executor driver, partition 42, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.256+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 42.0 in stage 92.0 (TID 880)
[2025-05-02T02:23:35.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 41.0 in stage 92.0 (TID 879) in 59 ms on ***-scheduler (executor driver) (42/50)
[2025-05-02T02:23:35.271+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_42 locally
[2025-05-02T02:23:35.273+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 42.0 in stage 92.0 (TID 880). 4224 bytes result sent to driver
[2025-05-02T02:23:35.275+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 43.0 in stage 92.0 (TID 881) (***-scheduler, executor driver, partition 43, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 43.0 in stage 92.0 (TID 881)
[2025-05-02T02:23:35.277+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 42.0 in stage 92.0 (TID 880) in 21 ms on ***-scheduler (executor driver) (43/50)
[2025-05-02T02:23:35.289+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_43 locally
[2025-05-02T02:23:35.292+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 43.0 in stage 92.0 (TID 881). 4181 bytes result sent to driver
[2025-05-02T02:23:35.293+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 44.0 in stage 92.0 (TID 882) (***-scheduler, executor driver, partition 44, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.295+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 44.0 in stage 92.0 (TID 882)
[2025-05-02T02:23:35.296+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 43.0 in stage 92.0 (TID 881) in 20 ms on ***-scheduler (executor driver) (44/50)
[2025-05-02T02:23:35.308+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_44 locally
[2025-05-02T02:23:35.311+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 44.0 in stage 92.0 (TID 882). 4181 bytes result sent to driver
[2025-05-02T02:23:35.313+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 45.0 in stage 92.0 (TID 883) (***-scheduler, executor driver, partition 45, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.314+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 45.0 in stage 92.0 (TID 883)
[2025-05-02T02:23:35.316+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 44.0 in stage 92.0 (TID 882) in 21 ms on ***-scheduler (executor driver) (45/50)
[2025-05-02T02:23:35.327+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_45 locally
[2025-05-02T02:23:35.330+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 45.0 in stage 92.0 (TID 883). 4181 bytes result sent to driver
[2025-05-02T02:23:35.331+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 46.0 in stage 92.0 (TID 884) (***-scheduler, executor driver, partition 46, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.332+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 46.0 in stage 92.0 (TID 884)
[2025-05-02T02:23:35.334+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 45.0 in stage 92.0 (TID 883) in 19 ms on ***-scheduler (executor driver) (46/50)
[2025-05-02T02:23:35.345+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_46 locally
[2025-05-02T02:23:35.347+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 46.0 in stage 92.0 (TID 884). 4181 bytes result sent to driver
[2025-05-02T02:23:35.349+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 47.0 in stage 92.0 (TID 885) (***-scheduler, executor driver, partition 47, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.350+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 47.0 in stage 92.0 (TID 885)
[2025-05-02T02:23:35.352+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 46.0 in stage 92.0 (TID 884) in 19 ms on ***-scheduler (executor driver) (47/50)
[2025-05-02T02:23:35.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_47 locally
[2025-05-02T02:23:35.368+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 47.0 in stage 92.0 (TID 885). 4181 bytes result sent to driver
[2025-05-02T02:23:35.370+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 48.0 in stage 92.0 (TID 886) (***-scheduler, executor driver, partition 48, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.371+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 48.0 in stage 92.0 (TID 886)
[2025-05-02T02:23:35.373+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 47.0 in stage 92.0 (TID 885) in 21 ms on ***-scheduler (executor driver) (48/50)
[2025-05-02T02:23:35.396+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_48 locally
[2025-05-02T02:23:35.399+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 48.0 in stage 92.0 (TID 886). 4224 bytes result sent to driver
[2025-05-02T02:23:35.400+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 49.0 in stage 92.0 (TID 887) (***-scheduler, executor driver, partition 49, PROCESS_LOCAL, 10206 bytes)
[2025-05-02T02:23:35.402+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 49.0 in stage 92.0 (TID 887)
[2025-05-02T02:23:35.403+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 48.0 in stage 92.0 (TID 886) in 32 ms on ***-scheduler (executor driver) (49/50)
[2025-05-02T02:23:35.416+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManager: Found block rdd_90_49 locally
[2025-05-02T02:23:35.419+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Finished task 49.0 in stage 92.0 (TID 887). 4181 bytes result sent to driver
[2025-05-02T02:23:35.420+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Finished task 49.0 in stage 92.0 (TID 887) in 21 ms on ***-scheduler (executor driver) (50/50)
[2025-05-02T02:23:35.422+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-05-02T02:23:35.424+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: ResultStage 92 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.234 s
[2025-05-02T02:23:35.425+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:23:35.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
[2025-05-02T02:23:35.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Job 49 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.247390 s
[2025-05-02T02:23:35.439+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO PrepareDeltaScan: DELTA: Done
[2025-05-02T02:23:35.483+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO FileSourceStrategy: Pushed Filters:
[2025-05-02T02:23:35.485+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-05-02T02:23:35.555+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO CodeGenerator: Code generated in 41.699432 ms
[2025-05-02T02:23:35.560+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 206.6 KiB, free 398.5 MiB)
[2025-05-02T02:23:35.583+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 398.5 MiB)
[2025-05-02T02:23:35.585+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on ***-scheduler:33063 (size: 36.4 KiB, free: 433.8 MiB)
[2025-05-02T02:23:35.588+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO SparkContext: Created broadcast 79 from saveAsTable at NativeMethodAccessorImpl.java:0
[2025-05-02T02:23:35.590+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5664674 bytes, open cost is considered as scanning 4194304 bytes.
[2025-05-02T02:23:35.605+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Registering RDD 212 (saveAsTable at NativeMethodAccessorImpl.java:0) as input to shuffle 19
[2025-05-02T02:23:35.607+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Got map stage job 50 (saveAsTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-02T02:23:35.609+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Final stage: ShuffleMapStage 93 (saveAsTable at NativeMethodAccessorImpl.java:0)
[2025-05-02T02:23:35.610+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Parents of final stage: List()
[2025-05-02T02:23:35.611+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:23:35.612+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[212] at saveAsTable at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-02T02:23:35.614+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 44.0 KiB, free 398.4 MiB)
[2025-05-02T02:23:35.615+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 398.4 MiB)
[2025-05-02T02:23:35.616+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on ***-scheduler:33063 (size: 19.5 KiB, free: 433.7 MiB)
[2025-05-02T02:23:35.618+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:23:35.619+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[212] at saveAsTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:23:35.621+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
[2025-05-02T02:23:35.622+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 888) (***-scheduler, executor driver, partition 0, PROCESS_LOCAL, 10909 bytes)
[2025-05-02T02:23:35.624+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO Executor: Running task 0.0 in stage 93.0 (TID 888)
[2025-05-02T02:23:35.675+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO CodeGenerator: Code generated in 42.846441 ms
[2025-05-02T02:23:35.693+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO CodeGenerator: Code generated in 10.726048 ms
[2025-05-02T02:23:35.702+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:35 INFO FileScanRDD: Reading File path: s3a://medical-bucket/enriched/transactional/medical-data-sample/enriched_encounters/part-00000-ea7425f2-9107-4d6c-bddb-e4d1ec24a4da-c000.snappy.parquet, range: 0-1470370, partition values: [empty row]
[2025-05-02T02:23:36.638+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:36 INFO S3AInputStream: Switching to Random IO seek policy
[2025-05-02T02:23:37.883+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO Executor: Finished task 0.0 in stage 93.0 (TID 888). 2978 bytes result sent to driver
[2025-05-02T02:23:37.901+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 888) in 2255 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:23:37.904+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-05-02T02:23:37.905+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO DAGScheduler: ShuffleMapStage 93 (saveAsTable at NativeMethodAccessorImpl.java:0) finished in 2.269 s
[2025-05-02T02:23:37.906+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-02T02:23:37.907+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO DAGScheduler: running: Set()
[2025-05-02T02:23:37.908+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO DAGScheduler: waiting: Set()
[2025-05-02T02:23:37.909+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO DAGScheduler: failed: Set()
[2025-05-02T02:23:37.910+0000] {spark_submit.py:649} INFO - 25/05/02 02:23:37 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-02T02:23:46.838+0000] {job.py:229} INFO - Heartbeat recovered after 50.63 seconds
[2025-05-02T02:24:04.511+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:24:04.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-05-02T02:24:04.515+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-05-02T02:24:04.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:24:04.516+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-05-02T02:24:04.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-05-02T02:24:04.517+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:24:04.571+0000] {job.py:229} INFO - Heartbeat recovered after 17.76 seconds
[2025-05-02T02:24:04.710+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO CodeGenerator: Code generated in 9.591613 ms
[2025-05-02T02:24:04.716+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO SparkContext: Starting job: saveAsTable at NativeMethodAccessorImpl.java:0
[2025-05-02T02:24:04.717+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO DAGScheduler: Got job 51 (saveAsTable at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-02T02:24:04.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO DAGScheduler: Final stage: ResultStage 95 (saveAsTable at NativeMethodAccessorImpl.java:0)
[2025-05-02T02:24:04.718+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
[2025-05-02T02:24:04.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO DAGScheduler: Missing parents: List()
[2025-05-02T02:24:04.719+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[215] at saveAsTable at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-02T02:24:04.731+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 255.3 KiB, free 398.2 MiB)
[2025-05-02T02:24:04.737+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 94.2 KiB, free 398.1 MiB)
[2025-05-02T02:24:04.738+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on ***-scheduler:33063 (size: 94.2 KiB, free: 433.7 MiB)
[2025-05-02T02:24:04.739+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
[2025-05-02T02:24:04.740+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[215] at saveAsTable at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-02T02:24:04.740+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0
[2025-05-02T02:24:04.741+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 889) (***-scheduler, executor driver, partition 0, NODE_LOCAL, 10206 bytes)
[2025-05-02T02:24:04.742+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO Executor: Running task 0.0 in stage 95.0 (TID 889)
[2025-05-02T02:24:04.753+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO ShuffleBlockFetcherIterator: Getting 1 (501.6 KiB) non-empty blocks including 1 (501.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-02T02:24:04.754+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-05-02T02:24:04.764+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO CodeGenerator: Code generated in 10.371853 ms
[2025-05-02T02:24:04.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-05-02T02:24:04.767+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-05-02T02:24:04.768+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:24:04.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-05-02T02:24:04.769+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-05-02T02:24:04.770+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-05-02T02:24:04.771+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:24:04.771+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO CodecConfig: Compression: SNAPPY
[2025-05-02T02:24:04.772+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-05-02T02:24:04.773+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-05-02T02:24:04.773+0000] {spark_submit.py:649} INFO - {
[2025-05-02T02:24:04.774+0000] {spark_submit.py:649} INFO - "type" : "struct",
[2025-05-02T02:24:04.774+0000] {spark_submit.py:649} INFO - "fields" : [ {
[2025-05-02T02:24:04.775+0000] {spark_submit.py:649} INFO - "name" : "Allergy_Group_Key",
[2025-05-02T02:24:04.775+0000] {spark_submit.py:649} INFO - "type" : "string",
[2025-05-02T02:24:04.776+0000] {spark_submit.py:649} INFO - "nullable" : true,
[2025-05-02T02:24:04.776+0000] {spark_submit.py:649} INFO - "metadata" : { }
[2025-05-02T02:24:04.776+0000] {spark_submit.py:649} INFO - } ]
[2025-05-02T02:24:04.777+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:24:04.777+0000] {spark_submit.py:649} INFO - and corresponding Parquet message type:
[2025-05-02T02:24:04.778+0000] {spark_submit.py:649} INFO - message spark_schema {
[2025-05-02T02:24:04.778+0000] {spark_submit.py:649} INFO - optional binary Allergy_Group_Key (STRING);
[2025-05-02T02:24:04.779+0000] {spark_submit.py:649} INFO - }
[2025-05-02T02:24:04.779+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:24:04.780+0000] {spark_submit.py:649} INFO - 
[2025-05-02T02:24:05.426+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505020224043840333226664201402_0095_m_000000_889' to s3a://medical-bucket/curated/transactional/medical-data-sample/dim_allergy_group/_temporary/0/task_202505020224043840333226664201402_0095_m_000000
[2025-05-02T02:24:05.427+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO SparkHadoopMapRedUtil: attempt_202505020224043840333226664201402_0095_m_000000_889: Committed. Elapsed time: 378 ms.
[2025-05-02T02:24:05.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO Executor: Finished task 0.0 in stage 95.0 (TID 889). 6302 bytes result sent to driver
[2025-05-02T02:24:05.428+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 889) in 689 ms on ***-scheduler (executor driver) (1/1)
[2025-05-02T02:24:05.429+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool
[2025-05-02T02:24:05.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO DAGScheduler: ResultStage 95 (saveAsTable at NativeMethodAccessorImpl.java:0) finished in 0.711 s
[2025-05-02T02:24:05.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-02T02:24:05.430+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
[2025-05-02T02:24:05.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO DAGScheduler: Job 51 finished: saveAsTable at NativeMethodAccessorImpl.java:0, took 0.712695 s
[2025-05-02T02:24:05.431+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:05 INFO FileFormatWriter: Start to commit write Job b1a89431-57bf-47e2-9a1f-409ce6130c66.
[2025-05-02T02:24:06.116+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:06 INFO FileFormatWriter: Write Job b1a89431-57bf-47e2-9a1f-409ce6130c66 committed. Elapsed time: 684 ms.
[2025-05-02T02:24:06.118+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:06 INFO FileFormatWriter: Finished processing stats for write job b1a89431-57bf-47e2-9a1f-409ce6130c66.
[2025-05-02T02:24:06.223+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:06 INFO InMemoryFileIndex: It took 22 ms to list leaf files for 1 paths.
[2025-05-02T02:24:06.294+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:06 INFO HiveExternalCatalog: Persisting file based data source table `spark_catalog`.`curated`.`dim_allergy_group` into Hive metastore in Hive compatible format.
[2025-05-02T02:24:06.547+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:06 WARN HiveExternalCatalog: Could not persist `spark_catalog`.`curated`.`dim_allergy_group` in a Hive compatible way. Persisting it into Hive metastore in Spark SQL specific format.
[2025-05-02T02:24:06.548+0000] {spark_submit.py:649} INFO - org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
[2025-05-02T02:24:06.548+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:939)
[2025-05-02T02:24:06.549+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:944)
[2025-05-02T02:24:06.549+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.Shim_v0_12.createTable(HiveShim.scala:614)
[2025-05-02T02:24:06.550+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$createTable$1(HiveClientImpl.scala:573)
[2025-05-02T02:24:06.551+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-02T02:24:06.551+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:303)
[2025-05-02T02:24:06.552+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:234)
[2025-05-02T02:24:06.552+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:233)
[2025-05-02T02:24:06.553+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:283)
[2025-05-02T02:24:06.554+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.client.HiveClientImpl.createTable(HiveClientImpl.scala:571)
[2025-05-02T02:24:06.554+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.HiveExternalCatalog.saveTableIntoHive(HiveExternalCatalog.scala:526)
[2025-05-02T02:24:06.555+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.HiveExternalCatalog.createDataSourceTable(HiveExternalCatalog.scala:415)
[2025-05-02T02:24:06.555+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$createTable$1(HiveExternalCatalog.scala:274)
[2025-05-02T02:24:06.556+0000] {spark_submit.py:649} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-02T02:24:06.557+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-05-02T02:24:06.557+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.hive.HiveExternalCatalog.createTable(HiveExternalCatalog.scala:245)
[2025-05-02T02:24:06.558+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.createTable(ExternalCatalogWithListener.scala:94)
[2025-05-02T02:24:06.559+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.catalog.SessionCatalog.createTable(SessionCatalog.scala:408)
[2025-05-02T02:24:06.560+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.run(createDataSourceTables.scala:193)
[2025-05-02T02:24:06.560+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
[2025-05-02T02:24:06.561+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
[2025-05-02T02:24:06.562+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
[2025-05-02T02:24:06.562+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
[2025-05-02T02:24:06.563+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
[2025-05-02T02:24:06.564+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
[2025-05-02T02:24:06.564+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
[2025-05-02T02:24:06.565+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-05-02T02:24:06.565+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
[2025-05-02T02:24:06.566+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
[2025-05-02T02:24:06.567+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
[2025-05-02T02:24:06.567+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
[2025-05-02T02:24:06.568+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-05-02T02:24:06.568+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
[2025-05-02T02:24:06.569+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
[2025-05-02T02:24:06.570+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
[2025-05-02T02:24:06.570+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
[2025-05-02T02:24:06.571+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
[2025-05-02T02:24:06.571+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
[2025-05-02T02:24:06.572+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
[2025-05-02T02:24:06.572+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
[2025-05-02T02:24:06.573+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
[2025-05-02T02:24:06.573+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
[2025-05-02T02:24:06.574+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
[2025-05-02T02:24:06.574+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
[2025-05-02T02:24:06.574+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.DataFrameWriter.createTable(DataFrameWriter.scala:710)
[2025-05-02T02:24:06.575+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:684)
[2025-05-02T02:24:06.575+0000] {spark_submit.py:649} INFO - at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:582)
[2025-05-02T02:24:06.576+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-05-02T02:24:06.576+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
[2025-05-02T02:24:06.577+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2025-05-02T02:24:06.577+0000] {spark_submit.py:649} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:569)
[2025-05-02T02:24:06.577+0000] {spark_submit.py:649} INFO - at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-05-02T02:24:06.578+0000] {spark_submit.py:649} INFO - at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-05-02T02:24:06.578+0000] {spark_submit.py:649} INFO - at py4j.Gateway.invoke(Gateway.java:282)
[2025-05-02T02:24:06.579+0000] {spark_submit.py:649} INFO - at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-05-02T02:24:06.579+0000] {spark_submit.py:649} INFO - at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-05-02T02:24:06.579+0000] {spark_submit.py:649} INFO - at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-05-02T02:24:06.580+0000] {spark_submit.py:649} INFO - at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-05-02T02:24:06.580+0000] {spark_submit.py:649} INFO - at java.base/java.lang.Thread.run(Thread.java:840)
[2025-05-02T02:24:06.581+0000] {spark_submit.py:649} INFO - Caused by: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
[2025-05-02T02:24:06.581+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:54908)
[2025-05-02T02:24:06.582+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:54876)
[2025-05-02T02:24:06.582+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result.read(ThriftHiveMetastore.java:54802)
[2025-05-02T02:24:06.583+0000] {spark_submit.py:649} INFO - at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:86)
[2025-05-02T02:24:06.583+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_table_with_environment_context(ThriftHiveMetastore.java:1556)
[2025-05-02T02:24:06.583+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_with_environment_context(ThriftHiveMetastore.java:1542)
[2025-05-02T02:24:06.584+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table_with_environment_context(HiveMetaStoreClient.java:2867)
[2025-05-02T02:24:06.584+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.create_table_with_environment_context(SessionHiveMetaStoreClient.java:121)
[2025-05-02T02:24:06.585+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:837)
[2025-05-02T02:24:06.585+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:822)
[2025-05-02T02:24:06.585+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-05-02T02:24:06.586+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
[2025-05-02T02:24:06.586+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2025-05-02T02:24:06.587+0000] {spark_submit.py:649} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:569)
[2025-05-02T02:24:06.587+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212)
[2025-05-02T02:24:06.588+0000] {spark_submit.py:649} INFO - at jdk.proxy3/jdk.proxy3.$Proxy31.createTable(Unknown Source)
[2025-05-02T02:24:06.588+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-05-02T02:24:06.589+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
[2025-05-02T02:24:06.589+0000] {spark_submit.py:649} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2025-05-02T02:24:06.590+0000] {spark_submit.py:649} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:569)
[2025-05-02T02:24:06.590+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2773)
[2025-05-02T02:24:06.591+0000] {spark_submit.py:649} INFO - at jdk.proxy3/jdk.proxy3.$Proxy31.createTable(Unknown Source)
[2025-05-02T02:24:06.591+0000] {spark_submit.py:649} INFO - at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:928)
[2025-05-02T02:24:06.591+0000] {spark_submit.py:649} INFO - ... 58 more
[2025-05-02T02:24:07.237+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO SparkContext: Invoking stop() from shutdown hook
[2025-05-02T02:24:07.239+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-05-02T02:24:07.257+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO SparkUI: Stopped Spark web UI at http://***-scheduler:4040
[2025-05-02T02:24:07.276+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-02T02:24:07.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO MemoryStore: MemoryStore cleared
[2025-05-02T02:24:07.357+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO BlockManager: BlockManager stopped
[2025-05-02T02:24:07.362+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-02T02:24:07.366+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-02T02:24:07.375+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO SparkContext: Successfully stopped SparkContext
[2025-05-02T02:24:07.376+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO ShutdownHookManager: Shutdown hook called
[2025-05-02T02:24:07.377+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab/pyspark-19a17e8d-b402-44a6-829a-2476856d98cb
[2025-05-02T02:24:07.382+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO ShutdownHookManager: Deleting directory /tmp/hive-v3_1-74880417-547d-45d1-8446-2e60c5c3d219
[2025-05-02T02:24:07.392+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3eb11ca-09c2-4160-a389-4832d30bddab
[2025-05-02T02:24:07.398+0000] {spark_submit.py:649} INFO - 25/05/02 02:24:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-d3e7e35a-76ba-4564-b180-551c330c43c0
[2025-05-02T02:24:07.649+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-05-02T02:24:07.650+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=medical_dag_v17, task_id=dim_group.creating_dim_allergies, run_id=manual__2025-05-02T02:18:00.042814+00:00, execution_date=20250502T021800, start_date=20250502T022114, end_date=20250502T022407
[2025-05-02T02:24:07.720+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-05-02T02:24:07.738+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-02T02:24:07.740+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
